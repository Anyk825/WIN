{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU count: 1\n",
      "[0] NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU count:\", torch.cuda.device_count())\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"[{i}] {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optional: for dataset loading\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:23.608069Z",
     "iopub.status.busy": "2025-11-06T05:00:23.607298Z",
     "iopub.status.idle": "2025-11-06T05:00:25.424033Z",
     "shell.execute_reply": "2025-11-06T05:00:25.423326Z",
     "shell.execute_reply.started": "2025-11-06T05:00:23.608033Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Optional (nice for shapes):\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    HAS_TORCHINFO = True\n",
    "except Exception:\n",
    "    HAS_TORCHINFO = False\n",
    "\n",
    "\n",
    "# ------------------ Simple config you can edit ------------------ #\n",
    "# import os\n",
    "import math\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optional: for dataset loading\n",
    "import torchaudio\n",
    "\n",
    "# Optional (nice for shapes):\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    HAS_TORCHINFO = True\n",
    "except Exception:\n",
    "    HAS_TORCHINFO = False\n",
    "\n",
    "\n",
    "# ------------------ Configurable Paths ------------------ #\n",
    "class SysConfig:\n",
    "    \"\"\"\n",
    "    Folder-based dataset structure.\n",
    "    Each split (train/dev/test) contains two subfolders: bonafide and spoof.\n",
    "    \"\"\"\n",
    "    path_train =r\"G:\\INTERSPEECH_26\\LA\\ASV19\\train\"\n",
    "    path_dev   = r\"G:\\INTERSPEECH_26\\LA\\ASV19\\dev\"\n",
    "    path_test  =r\"G:\\INTERSPEECH_26\\LA\\ASV19\\dev\"\n",
    "\n",
    "\n",
    "\n",
    "# ------------------ Experiment Hyperparameters ------------------ #\n",
    "class ExpConfig:\n",
    "    # Audio processing\n",
    "    sample_rate = 16000\n",
    "    pre_emphasis = 0.97\n",
    "    train_duration_sec = 4\n",
    "    test_duration_sec = 4\n",
    "\n",
    "    # Model\n",
    "    transformer_hidden = 660\n",
    "\n",
    "    # Training hyperparameters\n",
    "    batch_size = 32\n",
    "    lr = 8*1e-4\n",
    "    epochs = 50  # increase as needed\n",
    "\n",
    "\n",
    "# ------------------ Device Selection ------------------ #\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"✅ Using device: {DEVICE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.425507Z",
     "iopub.status.busy": "2025-11-06T05:00:25.425228Z",
     "iopub.status.idle": "2025-11-06T05:00:25.433624Z",
     "shell.execute_reply": "2025-11-06T05:00:25.433064Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.425491Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "\n",
    "class ASVspoofFolderDataset(Dataset):\n",
    "    def __init__(self, root_dir, sample_rate=16000, duration_sec=4, augment=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration_sec = duration_sec\n",
    "        self.augment = augment\n",
    "\n",
    "        self.audio_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # 1 = bonafide, 0 = spoof\n",
    "        for label_name, label_value in [(\"bonafide\", 1), (\"spoof\", 0)]:\n",
    "            class_dir = os.path.join(root_dir, label_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for file in os.listdir(class_dir):\n",
    "                    if file.endswith(\".flac\") or file.endswith(\".wav\"):\n",
    "                        self.audio_paths.append(os.path.join(class_dir, file))\n",
    "                        self.labels.append(label_value)\n",
    "\n",
    "        print(f\"Loaded {len(self.audio_paths)} files from {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.audio_paths[idx]\n",
    "        label = torch.tensor([self.labels[idx]], dtype=torch.float32)\n",
    "\n",
    "        wav, sr = torchaudio.load(path)\n",
    "        if sr != self.sample_rate:\n",
    "            wav = torchaudio.functional.resample(wav, sr, self.sample_rate)\n",
    "\n",
    "        # Random cropping or padding to fixed duration\n",
    "        num_samples = self.sample_rate * self.duration_sec\n",
    "        if wav.size(1) > num_samples:\n",
    "            start = random.randint(0, wav.size(1) - num_samples)\n",
    "            wav = wav[:, start:start + num_samples]\n",
    "        elif wav.size(1) < num_samples:\n",
    "            wav = torch.nn.functional.pad(wav, (0, num_samples - wav.size(1)))\n",
    "\n",
    "        return wav.squeeze(0), label.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.434415Z",
     "iopub.status.busy": "2025-11-06T05:00:25.434213Z",
     "iopub.status.idle": "2025-11-06T05:00:25.456671Z",
     "shell.execute_reply": "2025-11-06T05:00:25.455975Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.434400Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Self-contained augmentation cell (safe if torch_audiomentations isn't installed) ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "try:\n",
    "    from torch_audiomentations import (\n",
    "        Compose, AddColoredNoise, HighPassFilter, LowPassFilter, Gain\n",
    "    )\n",
    "    HAS_TA = True\n",
    "except Exception:\n",
    "    HAS_TA = False\n",
    "    Compose = AddColoredNoise = HighPassFilter = LowPassFilter = Gain = None\n",
    "\n",
    "class WaveformAugmentation(nn.Module):\n",
    "    def __init__(self, aug_list=('ACN', 'HPF', 'LPF', 'GAN'), sr=16000):\n",
    "        super().__init__()\n",
    "        self.sr = sr\n",
    "        if HAS_TA:\n",
    "            transforms = []\n",
    "            if 'ACN' in aug_list:\n",
    "                transforms.append(AddColoredNoise(10, 40, -2.0, 2.0, p=0.5))\n",
    "            if 'HPF' in aug_list:\n",
    "                transforms.append(HighPassFilter(20.0, 2400.0, p=0.5))\n",
    "            if 'LPF' in aug_list:\n",
    "                transforms.append(LowPassFilter(150.0, 7500.0, p=0.5))\n",
    "            if 'GAN' in aug_list:\n",
    "                transforms.append(Gain(-15.0, 5.0, p=0.5))\n",
    "            self.apply_augmentation = Compose(transforms) if transforms else None\n",
    "        else:\n",
    "            # No-op if torch_audiomentations isn't available\n",
    "            self.apply_augmentation = None\n",
    "\n",
    "    def forward(self, wav: torch.Tensor) -> torch.Tensor:\n",
    "        # wav: (B, T)\n",
    "        if self.apply_augmentation is None:\n",
    "            return wav\n",
    "        return self.apply_augmentation(wav.unsqueeze(1), self.sr).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.458646Z",
     "iopub.status.busy": "2025-11-06T05:00:25.458458Z",
     "iopub.status.idle": "2025-11-06T05:00:25.474685Z",
     "shell.execute_reply": "2025-11-06T05:00:25.473907Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.458632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PreEmphasis(nn.Module):\n",
    "    def __init__(self, pre_emphasis: float = 0.97):\n",
    "        super().__init__()\n",
    "        # Conv1D filter shape: (out_channels=1, in_channels=1, kernel_size=2)\n",
    "        filt = torch.tensor([[-pre_emphasis, 1.0]], dtype=torch.float32).unsqueeze(0)\n",
    "        self.register_buffer(\"filter\", filt)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, T)\n",
    "        x = x.unsqueeze(1)  # (B,1,T)\n",
    "        x = F.pad(x, (1, 0), mode=\"reflect\")\n",
    "        x = F.conv1d(x, self.filter)\n",
    "        return x.squeeze(1)  # (B,T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.475956Z",
     "iopub.status.busy": "2025-11-06T05:00:25.475716Z",
     "iopub.status.idle": "2025-11-06T05:00:25.502748Z",
     "shell.execute_reply": "2025-11-06T05:00:25.502230Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.475940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SincConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from AASIST. One input channel only.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def to_mel(hz): return 2595 * np.log10(1 + hz / 700)\n",
    "    @staticmethod\n",
    "    def to_hz(mel): return 700 * (10**(mel / 2595) - 1)\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1, stride=1, padding=0, dilation=1):\n",
    "        super().__init__()\n",
    "        if in_channels != 1:\n",
    "            raise ValueError(\"SincConv supports only one input channel.\")\n",
    "        self.out_channels = out_channels\n",
    "        self.sample_rate = sample_rate\n",
    "        self.kernel_size = kernel_size + (kernel_size % 2 == 0)\n",
    "\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        NFFT = 512\n",
    "        f = int(sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        fmel = self.to_mel(f)\n",
    "        filbandwidthsmel = np.linspace(fmel.min(), fmel.max(), out_channels + 1)\n",
    "        filbandwidthsf = self.to_hz(filbandwidthsmel)\n",
    "\n",
    "        self.hsupp = torch.arange(-(self.kernel_size - 1) / 2,\n",
    "                                  (self.kernel_size - 1) / 2 + 1)\n",
    "\n",
    "        band_pass = torch.zeros(out_channels, self.kernel_size)\n",
    "        for i in range(out_channels):\n",
    "            fmin, fmax = filbandwidthsf[i], filbandwidthsf[i + 1]\n",
    "            hHigh = (2 * fmax / sample_rate) * np.sinc(2 * fmax * self.hsupp / sample_rate)\n",
    "            hLow  = (2 * fmin / sample_rate) * np.sinc(2 * fmin * self.hsupp / sample_rate)\n",
    "            hideal = hHigh - hLow\n",
    "            band_pass[i, :] = torch.tensor(np.hamming(self.kernel_size)) * torch.tensor(hideal)\n",
    "        self.register_buffer(\"band_pass\", band_pass)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,1,T)\n",
    "        filt = self.band_pass.to(x.device).view(self.out_channels, 1, self.kernel_size)\n",
    "        return F.conv1d(x, filt, stride=self.stride, padding=self.padding, dilation=self.dilation, groups=1)\n",
    "\n",
    "\n",
    "class Conv2DBlock_S(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, is_first_block: bool=False):\n",
    "        super().__init__()\n",
    "        self.normalizer = None if is_first_block else nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.SELU(inplace=True)\n",
    "        )\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(2,5), padding=(1,2), stride=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(2,3), padding=(0,1), stride=1),\n",
    "        )\n",
    "        self.downsampler = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsampler = nn.Conv2d(in_channels, out_channels, kernel_size=(1,3), padding=(0,1), stride=1)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(1,6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.downsampler is None else self.downsampler(x)\n",
    "        if self.normalizer is not None:\n",
    "            x = self.normalizer(x)\n",
    "        x = self.layers(x)\n",
    "        x = x + identity\n",
    "        return self.pooling(x)\n",
    "\n",
    "\n",
    "class Conv2DBlock_L(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, is_first_block: bool=False):\n",
    "        super().__init__()\n",
    "        self.normalizer = None if is_first_block else nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.SELU(inplace=True)\n",
    "        )\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(2,3), padding=(1,1), stride=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(2,3), padding=(0,1), stride=1),\n",
    "        )\n",
    "        self.downsampler = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsampler = nn.Conv2d(in_channels, out_channels, kernel_size=(1,3), padding=(0,1), stride=1)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(1,3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.downsampler is None else self.downsampler(x)\n",
    "        if self.normalizer is not None:\n",
    "            x = self.normalizer(x)\n",
    "        x = self.layers(x)\n",
    "        x = x + identity\n",
    "        return self.pooling(x)\n",
    "\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channels, channel_reduction=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // channel_reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // channel_reduction, channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "\n",
    "class Conv2DBlock_SE(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, scale: int = 8, channel_reduction: int = 8):\n",
    "        super().__init__()\n",
    "        self.scale = scale\n",
    "        self.sub_channels = out_channels // scale\n",
    "        self.hidden_channels = self.sub_channels * scale\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.normalizer = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.SELU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.hidden_channels, kernel_size=(1,7), padding=(0,3)),\n",
    "            nn.BatchNorm2d(self.hidden_channels),\n",
    "            relu\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(self.sub_channels, self.sub_channels, kernel_size=(3,9), padding=(1,4)),\n",
    "                nn.BatchNorm2d(self.sub_channels),\n",
    "                relu\n",
    "            ) for _ in range(1, scale)\n",
    "        ])\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(self.hidden_channels, out_channels, kernel_size=(1,7), padding=(0,3)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            relu\n",
    "        )\n",
    "\n",
    "        self.se_module = SELayer(out_channels, channel_reduction)\n",
    "\n",
    "        self.downsampler = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsampler = nn.Conv2d(in_channels, out_channels, kernel_size=(1,7), padding=(0,3), stride=1)\n",
    "\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(1,6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.downsampler is None else self.downsampler(x)\n",
    "        x = self.normalizer(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x_split = torch.split(x, self.sub_channels, dim=1)\n",
    "        y_list = [x_split[0]]\n",
    "        for i in range(1, self.scale):\n",
    "            inp = x_split[i] if i == 1 else x_split[i] + y_list[i-1]\n",
    "            y_list.append(self.conv2[i-1](inp))\n",
    "\n",
    "        y = torch.cat(y_list, dim=1)\n",
    "        y = self.conv3(y)\n",
    "        y = self.se_module(y)\n",
    "        y = y + identity\n",
    "        return self.pooling(y)\n",
    "\n",
    "\n",
    "class Frontend_S(nn.Module):\n",
    "    def __init__(self, sinc_kernel_size=128, sample_rate=16000):\n",
    "        super().__init__()\n",
    "        self.sinc = SincConv(70, sinc_kernel_size, sample_rate)\n",
    "        self.bn = nn.BatchNorm2d(1)\n",
    "        self.act = nn.SELU(inplace=True)\n",
    "        self.blocks = nn.Sequential(\n",
    "            Conv2DBlock_S(1, 32, is_first_block=True),\n",
    "            Conv2DBlock_S(32, 32),\n",
    "            Conv2DBlock_S(32, 64),\n",
    "            Conv2DBlock_S(64, 64),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,T) -> (B,1,T) -> sinc -> (B,70,T') -> (B,1,70,T')\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.sinc(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.max_pool2d(torch.abs(x), (3,3))\n",
    "        x = self.bn(x)\n",
    "        lfm = self.act(x)\n",
    "        return self.blocks(lfm)   # HFM: (B,C=64, f≈23, t≈16)\n",
    "\n",
    "\n",
    "class Frontend_L(nn.Module):\n",
    "    def __init__(self, sinc_kernel_size=128, sample_rate=16000):\n",
    "        super().__init__()\n",
    "        self.sinc = SincConv(70, sinc_kernel_size, sample_rate)\n",
    "        self.bn = nn.BatchNorm2d(1)\n",
    "        self.act = nn.SELU(inplace=True)\n",
    "        self.blocks = nn.Sequential(\n",
    "            Conv2DBlock_L(1, 32, is_first_block=True),\n",
    "            Conv2DBlock_L(32, 32),\n",
    "            Conv2DBlock_L(32, 64),\n",
    "            Conv2DBlock_L(64, 64),\n",
    "            Conv2DBlock_L(64, 64),\n",
    "            Conv2DBlock_L(64, 64),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.sinc(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.max_pool2d(torch.abs(x), (3,3))\n",
    "        x = self.bn(x)\n",
    "        lfm = self.act(x)\n",
    "        return self.blocks(lfm)   # (B,64, f≈23, t≈29 for 4s @16kHz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.503729Z",
     "iopub.status.busy": "2025-11-06T05:00:25.503496Z",
     "iopub.status.idle": "2025-11-06T05:00:25.527199Z",
     "shell.execute_reply": "2025-11-06T05:00:25.526587Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.503715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Master imports cell (run first) ---\n",
    "import os, math, random\n",
    "from typing import Optional, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Nice-to-have (optional)\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    HAS_TORCHINFO = True\n",
    "except Exception:\n",
    "    HAS_TORCHINFO = False\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Expects Q,K,V: (B, H, S, D). Optional mask: (B,1,1,S) or broadcastable.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, Q, K, V, mask: Optional[torch.Tensor] = None):\n",
    "        assert Q.dim() == K.dim() == V.dim() == 4  # (B,H,S,D)\n",
    "        d_k = K.size(-1)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)  # (B,H,S_q,S_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "        attn = self.softmax(scores)\n",
    "        out = torch.matmul(attn, V)  # (B,H,S_q,D)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, n_head: int):\n",
    "        super().__init__()\n",
    "        assert d_model % n_head == 0, \"d_model must be divisible by n_head\"\n",
    "        self.n_head = n_head\n",
    "        self.d_head = d_model // n_head\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_model)\n",
    "        self.W_K = nn.Linear(d_model, d_model)\n",
    "        self.W_V = nn.Linear(d_model, d_model)\n",
    "        self.attn = ScaledDotProductAttention()\n",
    "        self.W_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def _split_heads(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,S,D) -> (B,H,S,Dh)\n",
    "        B, S, D = x.size()\n",
    "        x = x.view(B, S, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
    "        return x\n",
    "\n",
    "    def _merge_heads(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,H,S,Dh) -> (B,S,D)\n",
    "        B, H, S, Dh = x.size()\n",
    "        return x.permute(0, 2, 1, 3).contiguous().view(B, S, H * Dh)\n",
    "\n",
    "    def forward(self, Q, K, V, mask: Optional[torch.Tensor] = None):\n",
    "        assert Q.dim() == K.dim() == V.dim() == 3  # (B,S,D)\n",
    "        q = self._split_heads(self.W_Q(Q))\n",
    "        k = self._split_heads(self.W_K(K))\n",
    "        v = self._split_heads(self.W_V(V))\n",
    "        if mask is not None:\n",
    "            # make mask broadcastable to (B,H,S_q,S_k)\n",
    "            mask = mask.unsqueeze(1)\n",
    "        context = self.attn(q, k, v, mask=mask)\n",
    "        context = self._merge_heads(context)\n",
    "        return self.W_out(context)\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-12):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, unbiased=False, keepdim=True)\n",
    "        xhat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.gamma * xhat + self.beta\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, ffn_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Linear(ffn_hidden, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model=64, n_head=8, ffn_hidden=2048, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, n_head)\n",
    "        self.dropout1 = nn.Dropout(drop_prob)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.ffn = FFN(d_model, ffn_hidden, drop_prob)\n",
    "        self.dropout2 = nn.Dropout(drop_prob)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, attn_mask: Optional[torch.Tensor] = None):\n",
    "        # x: (B,S,D)\n",
    "        residual = x\n",
    "        x = self.attn(x, x, x, mask=attn_mask)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + residual)\n",
    "\n",
    "        residual = x\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + residual)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.528165Z",
     "iopub.status.busy": "2025-11-06T05:00:25.527829Z",
     "iopub.status.idle": "2025-11-06T05:00:25.547436Z",
     "shell.execute_reply": "2025-11-06T05:00:25.546736Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.528143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PositionalAggregator1D(nn.Module):\n",
    "    \n",
    "    def __init__(self, max_C:int, max_ft:int, device):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            max_channels (int): for HFM, max size of C\n",
    "            max_ft (int): for HFM, max size of f*t\n",
    "        \"\"\"\n",
    "        super(PositionalAggregator1D, self).__init__()\n",
    "        \n",
    "        self.flattener = nn.Flatten(start_dim=-2, end_dim=-1)\n",
    "        \n",
    "        # ------------------ positional encoding -------------------- #        \n",
    "        x = torch.arange(1, max_ft-1, device=device).float()\n",
    "        x = x.float().unsqueeze(1)\n",
    "        _2i = torch.arange(0, max_C, step=2, device=device).float().unsqueeze(0)\n",
    "        \n",
    "        self.encoding = torch.zeros(max_ft, max_C, device=device, requires_grad=False)\n",
    "        self.encoding[1:-1, 0::2] = torch.sin(x / (10000 ** (_2i / max_C)))\n",
    "        self.encoding[1:-1, 1::2] = torch.cos(x / (10000 ** (_2i / max_C)))\n",
    "        \n",
    "    def forward(self, HFM):\n",
    "        batch, C, f, t = HFM.shape\n",
    "        out = self.flattener(HFM).transpose(1, 2)# [batch, f*t, C]\n",
    "        out = out + self.encoding[:f*t, :C].unsqueeze(0)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.548727Z",
     "iopub.status.busy": "2025-11-06T05:00:25.548481Z",
     "iopub.status.idle": "2025-11-06T05:00:25.566675Z",
     "shell.execute_reply": "2025-11-06T05:00:25.566051Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.548690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PositionalAggregator2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Adds 2D sinusoidal PE over (f, t) before flattening to sequence.\n",
    "    Input HFM: (B, C, F, T). Output: (B, F*T, C)\n",
    "    \"\"\"\n",
    "    def __init__(self, max_C: int, max_F: int, max_T: int):\n",
    "        super().__init__()\n",
    "        self.max_C = max_C\n",
    "        self.max_F = max_F\n",
    "        self.max_T = max_T\n",
    "\n",
    "        # Create 1D sin/cos for F and T, then combine\n",
    "        pe_f = torch.zeros(max_F, max_C)\n",
    "        pe_t = torch.zeros(max_T, max_C)\n",
    "\n",
    "        pos_f = torch.arange(0, max_F, dtype=torch.float).unsqueeze(1)\n",
    "        pos_t = torch.arange(0, max_T, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        div_term = torch.exp(torch.arange(0, max_C, 2).float() * (-math.log(10000.0) / max_C))\n",
    "        pe_f[:, 0::2] = torch.sin(pos_f * div_term)\n",
    "        pe_f[:, 1::2] = torch.cos(pos_f * div_term)\n",
    "\n",
    "        pe_t[:, 0::2] = torch.sin(pos_t * div_term)\n",
    "        pe_t[:, 1::2] = torch.cos(pos_t * div_term)\n",
    "\n",
    "        # Combine as a simple sum of broadcasted (f and t) encodings\n",
    "        # resulting PE shape for each (f,t): (C,)\n",
    "        pe_2d = pe_f.unsqueeze(1) + pe_t.unsqueeze(0)  # (F,1,C) + (1,T,C) -> (F,T,C)\n",
    "        self.register_buffer(\"pe_2d\", pe_2d)  # (F,T,C)\n",
    "\n",
    "    def forward(self, HFM: torch.Tensor) -> torch.Tensor:\n",
    "        # HFM: (B, C, F, T)\n",
    "        B, C, F, T = HFM.shape\n",
    "        assert F <= self.max_F and T <= self.max_T and C <= self.max_C\n",
    "\n",
    "        # permute to (B,F,T,C)\n",
    "        x = HFM.permute(0, 2, 3, 1).contiguous()\n",
    "        # add PE (F,T,C) -> broadcast to (B,F,T,C)\n",
    "        x = x + self.pe_2d[:F, :T, :C]\n",
    "        # flatten to (B, F*T, C)\n",
    "        x = x.view(B, F * T, C)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.567686Z",
     "iopub.status.busy": "2025-11-06T05:00:25.567427Z",
     "iopub.status.idle": "2025-11-06T05:00:25.590345Z",
     "shell.execute_reply": "2025-11-06T05:00:25.589703Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.567670Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Conv2DBlock_S(nn.Module):\n",
    "    \"\"\"__summary__\n",
    "    This is Conv2DBlock of Rawformer-S.\\\\\n",
    "    This block is same as ResNet block of AASIST with some different parameters.\n",
    "    (https://github.com/clovaai/aasist/blob/a04c9863f63d44471dde8a6abcb3b082b07cd1d1/models/AASIST.py#L413)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels: int, out_channels: int, is_first_block: bool=False):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): num of input channels\n",
    "            out_channels (int): num of output channels\n",
    "            se_reduction (int, optional): reduction factor for squeeze and excitation of channels. Defaults to 8.\n",
    "            is_first_block (bool, optional): if this is the first block must be True. Defaults to False.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Conv2DBlock_S, self).__init__()\n",
    "        \n",
    "        self.normalizer = None\n",
    "        if not is_first_block:\n",
    "            self.normalizer = nn.Sequential(\n",
    "                nn.BatchNorm2d(num_features=in_channels),\n",
    "                nn.SELU(inplace=True)\n",
    "            )\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(2, 5), padding=(1, 2), stride=1),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(2, 3), padding=(0, 1), stride=1),\n",
    "        )        \n",
    "        \n",
    "        self.downsampler = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsampler = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, padding=(0, 1), kernel_size=(1, 3), stride=1)\n",
    "            )\n",
    "        \n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(1, 6))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        identity = x\n",
    "        if self.downsampler is not None:\n",
    "            identity = self.downsampler(identity)\n",
    "        \n",
    "        if self.normalizer is not None:\n",
    "            x = self.normalizer(x)\n",
    "            \n",
    "        x = self.layers(x)\n",
    "        x = x + identity\n",
    "        \n",
    "        x = self.pooling(x)\n",
    "        return x\n",
    "\n",
    "class Conv2DBlock_L(nn.Module):\n",
    "    \"\"\"__summary__\n",
    "    This is Conv2DBlock of Rawformer-L.\\\\\n",
    "    This block is same as ResNet block of AASIST.\n",
    "    (https://github.com/clovaai/aasist/blob/a04c9863f63d44471dde8a6abcb3b082b07cd1d1/models/AASIST.py#L413)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels: int, out_channels: int, is_first_block: bool=False):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): num of input channels\n",
    "            out_channels (int): num of output channels\n",
    "            se_reduction (int, optional): reduction factor for squeeze and excitation of channels. Defaults to 8.\n",
    "            is_first_block (bool, optional): if this is the first block must be True. Defaults to False.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Conv2DBlock_L, self).__init__()\n",
    "        \n",
    "        self.normalizer = None\n",
    "        if not is_first_block:\n",
    "            self.normalizer = nn.Sequential(\n",
    "                nn.BatchNorm2d(num_features=in_channels),\n",
    "                nn.SELU(inplace=True)\n",
    "            )\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(2, 3), padding=(1, 1), stride=1),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(2, 3), padding=(0, 1), stride=1),\n",
    "        )        \n",
    "        \n",
    "        self.downsampler = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsampler = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, padding=(0, 1), kernel_size=(1, 3), stride=1)\n",
    "            )\n",
    "        \n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(1, 3))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        identity = x\n",
    "        if self.downsampler is not None:\n",
    "            identity = self.downsampler(identity)\n",
    "        \n",
    "        if self.normalizer is not None:\n",
    "            x = self.normalizer(x)\n",
    "            \n",
    "        x = self.layers(x)\n",
    "        x = x + identity\n",
    "        \n",
    "        x = self.pooling(x)\n",
    "        return x\n",
    "    \n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channels, channel_reduction=8):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(channels, channels // channel_reduction),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(channels // channel_reduction, channels),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "        \n",
    "class Conv2DBlock_SE(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels: int, out_channels: int, scale:int = 8, channel_reduction:int=8):\n",
    "        super(Conv2DBlock_SE, self).__init__()\n",
    "        \n",
    "        self.scale = scale\n",
    "        self.sub_channels = out_channels // scale\n",
    "        self.hidden_channels = self.sub_channels * scale\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        \n",
    "        self.normalizer = nn.Sequential(\n",
    "            nn.BatchNorm2d(num_features=in_channels),\n",
    "            nn.SELU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=self.hidden_channels, kernel_size=(1, 7), padding=(0, 3)),\n",
    "            nn.BatchNorm2d(num_features=self.hidden_channels),\n",
    "            relu\n",
    "        )\n",
    "        \n",
    "        self.conv2 = []\n",
    "        for i in range(2, scale+1):\n",
    "            self.conv2.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels=self.sub_channels, out_channels=self.sub_channels, kernel_size=(3, 9), padding=(1, 4)),\n",
    "                nn.BatchNorm2d(num_features=self.sub_channels),\n",
    "                relu\n",
    "            ))\n",
    "        self.conv2 = nn.ModuleList(self.conv2)\n",
    "            \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.hidden_channels, out_channels=out_channels, kernel_size=(1, 7), padding=(0, 3)),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            relu\n",
    "        )\n",
    "        \n",
    "        self.se_module = SELayer(channels=out_channels, channel_reduction=channel_reduction)\n",
    "        \n",
    "        self.downsampler = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsampler = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, padding=(0, 3), kernel_size=(1, 7), stride=1)\n",
    "            )\n",
    "            \n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(1, 6))\n",
    "        #self.pooling = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(1, 6), padding=(0, 0), )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        identity = x\n",
    "        if self.downsampler is not None:\n",
    "            identity = self.downsampler(identity)\n",
    "            \n",
    "        x = self.normalizer(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x_sub = torch.split(x, split_size_or_sections=self.sub_channels, dim = 1)\n",
    "        y_sub = [x_sub[0]]\n",
    "        \n",
    "        for i in range(1, self.scale):\n",
    "            y_i = None\n",
    "            if i == 1:\n",
    "                y_i = self.conv2[i - 1](x_sub[i])\n",
    "            else:\n",
    "                y_i = self.conv2[i - 1](x_sub[i] + y_sub[i-1])\n",
    "                \n",
    "            y_sub.append(y_i)\n",
    "        \n",
    "        y = torch.cat(y_sub, dim = 1)\n",
    "        y = self.conv3(y)\n",
    "        y = self.se_module(y)\n",
    "        \n",
    "        y = y + identity\n",
    "        y = self.pooling(y)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "class Frontend_S(nn.Module):\n",
    "    \"\"\"_summary_\n",
    "    This is frontend of Rawformer-S\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, device, sinc_kernel_size=128, sample_rate=16000):\n",
    "        \"\"\"_summary_\n",
    "        frontend of Rawformer-S\\\\\n",
    "            \n",
    "        N: number of conv2D-based blocks\\\\\n",
    "        N is fixed to 4.\n",
    "        \n",
    "        C: output channel of front-end\\\\\n",
    "        C is fixed to 64\n",
    "        \n",
    "        f: frequency \\\\\n",
    "        f is fixed to 23\n",
    "        \n",
    "        t: number of temporal bins\\\\\n",
    "        for 4 sec, t is 16. for 10 sec, t is 73\\\\\n",
    "        \n",
    "        Args:\n",
    "            sinc_kernel_size (int, optional): kernel size of sinc layer. Defaults to 128.\n",
    "            sample_rate (int, optional): _description_. Defaults to 16000.\n",
    "        \"\"\"\n",
    "        super(Frontend_S, self).__init__()\n",
    "        \n",
    "        self.sinc_layer = SincConv(in_channels=1, out_channels=70, kernel_size=sinc_kernel_size, sample_rate=sample_rate)\n",
    "        self.bn = nn.BatchNorm2d(num_features=1) \n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            Conv2DBlock_S(in_channels=1, out_channels=32, is_first_block=True),\n",
    "            Conv2DBlock_S(in_channels=32, out_channels=32),\n",
    "            Conv2DBlock_S(in_channels=32, out_channels=64),\n",
    "            Conv2DBlock_S(in_channels=64, out_channels=64),            \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.unsqueeze(dim=1)\n",
    "        x = self.sinc_layer(x)\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        x = F.max_pool2d(torch.abs(x), (3, 3))\n",
    "        x = self.bn(x)\n",
    "        LFM = self.selu(x)\n",
    "        \n",
    "        HFM = self.conv_blocks(LFM)\n",
    "        \n",
    "        return HFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.592924Z",
     "iopub.status.busy": "2025-11-06T05:00:25.592699Z",
     "iopub.status.idle": "2025-11-06T05:00:25.612377Z",
     "shell.execute_reply": "2025-11-06T05:00:25.611664Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.592910Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Frontend_S\n",
    "# ----------------------------------------------------------------------\n",
    "class Frontend_S(nn.Module):\n",
    "    def __init__(self, device, sinc_kernel_size=128, sample_rate=16000):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---- Sinc layer (no parameters → safe on any device) ----\n",
    "        self.sinc_layer = SincConv(\n",
    "            in_channels=1,\n",
    "            out_channels=70,\n",
    "            kernel_size=sinc_kernel_size,\n",
    "            sample_rate=sample_rate,\n",
    "        )\n",
    "\n",
    "        # ---- BatchNorm that must live on the target device ----\n",
    "        self.bn = nn.BatchNorm2d(num_features=1).to(device)\n",
    "\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "\n",
    "        # ---- Conv blocks (they also contain BatchNorms) ----\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            Conv2DBlock_S(in_channels=1,  out_channels=32, is_first_block=True),\n",
    "            Conv2DBlock_S(in_channels=32, out_channels=32),\n",
    "            Conv2DBlock_S(in_channels=32, out_channels=64),\n",
    "            Conv2DBlock_S(in_channels=64, out_channels=64),\n",
    "        ).to(device)                     # <-- move the whole Sequential\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : [B, T]  (raw waveform)\n",
    "        x = x.unsqueeze(1)                     # [B,1,T]\n",
    "        x = self.sinc_layer(x)                 # [B,70,T']\n",
    "        x = x.unsqueeze(1)                     # [B,1,70,T']\n",
    "        x = F.max_pool2d(torch.abs(x), (3, 3)) # [B,1,F,T]\n",
    "        x = self.bn(x)\n",
    "        LFM = self.selu(x)\n",
    "\n",
    "        HFM = self.conv_blocks(LFM)            # [B,64,f,t]\n",
    "        return HFM\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Conv2DBlock_S\n",
    "# ----------------------------------------------------------------------\n",
    "class Conv2DBlock_S(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, is_first_block: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---- optional normaliser (BN+SELU) ----\n",
    "        self.normalizer = None\n",
    "        if not is_first_block:\n",
    "            self.normalizer = nn.Sequential(\n",
    "                nn.BatchNorm2d(in_channels),\n",
    "                nn.SELU(inplace=True),\n",
    "            )\n",
    "\n",
    "        # ---- two conv layers + BN+SELU ----\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(2, 5), padding=(1, 2)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(2, 3), padding=(0, 1)),\n",
    "        )\n",
    "\n",
    "        # ---- residual connection when channel count changes ----\n",
    "        self.downsampler = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsampler = nn.Conv2d(in_channels, out_channels,\n",
    "                                        kernel_size=(1, 3), padding=(0, 1))\n",
    "\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(1, 6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsampler is not None:\n",
    "            identity = self.downsampler(identity)\n",
    "\n",
    "        if self.normalizer is not None:\n",
    "            x = self.normalizer(x)\n",
    "\n",
    "        x = self.layers(x) + identity\n",
    "        x = self.pooling(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. PositionalAggregator1D\n",
    "# ----------------------------------------------------------------------\n",
    "class PositionalAggregator1D(nn.Module):\n",
    "    def __init__(self, max_C: int, max_ft: int, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.flattener = nn.Flatten(start_dim=-2, end_dim=-1)\n",
    "\n",
    "        # ----- sinusoidal positional encoding (no trainable params) -----\n",
    "        pos = torch.arange(1, max_ft - 1, device=device).float().unsqueeze(1)   # (L-2,1)\n",
    "        dim = torch.arange(0, max_C, step=2, device=device).float().unsqueeze(0)  # (1,D/2)\n",
    "\n",
    "        enc = torch.zeros(max_ft, max_C, device=device)\n",
    "        enc[1:-1, 0::2] = torch.sin(pos / (10000 ** (dim / max_C)))\n",
    "        enc[1:-1, 1::2] = torch.cos(pos / (10000 ** (dim / max_C)))\n",
    "        self.register_buffer('encoding', enc)   # stored on the correct device automatically\n",
    "\n",
    "    def forward(self, HFM):\n",
    "        \"\"\"\n",
    "        HFM : [B, C, f, t]\n",
    "        out : [B, f*t, C]  with added positional encoding\n",
    "        \"\"\"\n",
    "        B, C, f, t = HFM.shape\n",
    "        ft = f * t\n",
    "        out = self.flattener(HFM).transpose(1, 2)               # [B, f*t, C]\n",
    "        out = out + self.encoding[:ft, :C]                      # broadcast\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.613498Z",
     "iopub.status.busy": "2025-11-06T05:00:25.613115Z",
     "iopub.status.idle": "2025-11-06T05:00:25.631285Z",
     "shell.execute_reply": "2025-11-06T05:00:25.630764Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.613477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# class Rawformer_S(nn.Module):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, device, transformer_hidden=64, sample_rate: int = 16000):\n",
    "#         super(Rawformer_S, self).__init__()\n",
    "#         self.front_end = Frontend_S(sinc_kernel_size=128, sample_rate=sample_rate)\n",
    "        \n",
    "#         self.positional_embedding = PositionalAggregator1D(max_C = 64, max_ft=23*16, device=device)# this max_ft is for input of 4-sec and 16000 sample-rate\n",
    "        \n",
    "#         self.classifier = RawformerClassifier(C = 64, n_encoder = 2, transformer_hidden=transformer_hidden)# output: [batch, C]\n",
    "        \n",
    "#     def forward(self, x):        \n",
    "#         x = self.front_end(x)\n",
    "#         x = self.positional_embedding(x)        \n",
    "#         x = self.classifier(x)        \n",
    "#         return x\n",
    "class Rawformer_S(nn.Module):\n",
    "    def __init__(self, device, transformer_hidden=64, sample_rate: int = 16000):\n",
    "        super().__init__()\n",
    "        # ---- 1. give the front-end the device ----\n",
    "        self.front_end = Frontend_S(sinc_kernel_size=128,\n",
    "                                    sample_rate=sample_rate,\n",
    "                                    device=device)          # <-- add this\n",
    "\n",
    "        self.positional_embedding = PositionalAggregator1D(\n",
    "            max_C=64, max_ft=23*16, device=device)\n",
    "\n",
    "        self.classifier = RawformerClassifier(C=64, n_encoder=2, transformer_hidden=transformer_hidden)\n",
    "\n",
    "        # ---- 2. move *everything* to the target device in one go ----\n",
    "        self.to(device)                     # <-- important!\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.front_end(x)               # now on correct device\n",
    "        x = self.positional_embedding(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.632219Z",
     "iopub.status.busy": "2025-11-06T05:00:25.631974Z",
     "iopub.status.idle": "2025-11-06T05:00:25.651681Z",
     "shell.execute_reply": "2025-11-06T05:00:25.651003Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.632196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SequencePooling(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention-style weighted pooling over sequence.\n",
    "    Input: (B,S,C) -> Output: (B,C)\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,S,C)\n",
    "        w = self.linear(x)               # (B,S,1)\n",
    "        w = F.softmax(w.transpose(1, 2), dim=-1)  # (B,1,S)\n",
    "        out = torch.matmul(w, x)         # (B,1,C)\n",
    "        return out.squeeze(1)            # (B,C)\n",
    "\n",
    "\n",
    "class RawformerClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoders (N layers) + SeqPool + Linear + Sigmoid\n",
    "    Input: sequence (B,S,C)  Output: (B,) score in [0,1]\n",
    "    \"\"\"\n",
    "    def __init__(self, C: int, n_encoder: int, transformer_hidden: int):\n",
    "        super().__init__()\n",
    "        self.encoders = nn.Sequential(OrderedDict([\n",
    "            (f\"encoder{i}\", TransformerEncoderLayer(d_model=C, n_head=8, ffn_hidden=transformer_hidden))\n",
    "            for i in range(n_encoder)\n",
    "        ]))\n",
    "        self.seq_pool = SequencePooling(d_model=C)\n",
    "        self.fc = nn.Linear(C, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,S,C)\n",
    "        x = self.encoders(x)\n",
    "        x = self.seq_pool(x)\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x).squeeze(-1)   # (B,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.652537Z",
     "iopub.status.busy": "2025-11-06T05:00:25.652339Z",
     "iopub.status.idle": "2025-11-06T05:00:25.669563Z",
     "shell.execute_reply": "2025-11-06T05:00:25.669042Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.652516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Rawformer_S_2DPE(nn.Module):\n",
    "    def __init__(self, transformer_hidden=64, sample_rate: int = 16000):\n",
    "        super().__init__()\n",
    "        self.front_end = Frontend_S(sinc_kernel_size=128, sample_rate=sample_rate)\n",
    "        # For 4s @ 16kHz, Frontend_S -> approx F=23, T=16 (as in your notes)\n",
    "        self.pos_emb = PositionalAggregator2D(max_C=64, max_F=23, max_T=16)\n",
    "        self.classifier = RawformerClassifier(C=64, n_encoder=2, transformer_hidden=transformer_hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,T)\n",
    "        hfm = self.front_end(x)         # (B,64,F,T)\n",
    "        seq = self.pos_emb(hfm)         # (B,F*T,64)\n",
    "        return self.classifier(seq)     # (B,)\n",
    "\n",
    "\n",
    "class Rawformer_L_2DPE(nn.Module):\n",
    "    def __init__(self, transformer_hidden=80, sample_rate: int = 16000):\n",
    "        super().__init__()\n",
    "        self.front_end = Frontend_L(sinc_kernel_size=128, sample_rate=sample_rate)\n",
    "        # For 4s @ 16kHz, Frontend_L -> approx F=23, T=29\n",
    "        self.pos_emb = PositionalAggregator2D(max_C=64, max_F=23, max_T=29)\n",
    "        self.classifier = RawformerClassifier(C=64, n_encoder=3, transformer_hidden=transformer_hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hfm = self.front_end(x)         # (B,64,F,T)\n",
    "        seq = self.pos_emb(hfm)         # (B,F*T,64)\n",
    "        return self.classifier(seq)     # (B,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.670549Z",
     "iopub.status.busy": "2025-11-06T05:00:25.670320Z",
     "iopub.status.idle": "2025-11-06T05:00:25.689407Z",
     "shell.execute_reply": "2025-11-06T05:00:25.688805Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.670534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Rawformer_S_2DPE(nn.Module):\n",
    "    def __init__(self, transformer_hidden=64, sample_rate: int = 16000):\n",
    "        super().__init__()\n",
    "        self.front_end = Frontend_S(sinc_kernel_size=128, sample_rate=sample_rate)\n",
    "        # For 4s @ 16kHz, Frontend_S -> approx F=23, T=16 (as in your notes)\n",
    "        self.pos_emb = PositionalAggregator2D(max_C=64, max_F=23, max_T=16)\n",
    "        self.classifier = RawformerClassifier(C=64, n_encoder=2, transformer_hidden=transformer_hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,T)\n",
    "        hfm = self.front_end(x)         # (B,64,F,T)\n",
    "        seq = self.pos_emb(hfm)         # (B,F*T,64)\n",
    "        return self.classifier(seq)     # (B,)\n",
    "\n",
    "\n",
    "class Rawformer_L_2DPE(nn.Module):\n",
    "    def __init__(self, transformer_hidden=80, sample_rate: int = 16000):\n",
    "        super().__init__()\n",
    "        self.front_end = Frontend_L(sinc_kernel_size=128, sample_rate=sample_rate)\n",
    "        # For 4s @ 16kHz, Frontend_L -> approx F=23, T=29\n",
    "        self.pos_emb = PositionalAggregator2D(max_C=64, max_F=23, max_T=29)\n",
    "        self.classifier = RawformerClassifier(C=64, n_encoder=3, transformer_hidden=transformer_hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hfm = self.front_end(x)         # (B,64,F,T)\n",
    "        seq = self.pos_emb(hfm)         # (B,F*T,64)\n",
    "        return self.classifier(seq)     # (B,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.690236Z",
     "iopub.status.busy": "2025-11-06T05:00:25.689996Z",
     "iopub.status.idle": "2025-11-06T05:00:25.706718Z",
     "shell.execute_reply": "2025-11-06T05:00:25.706058Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.690221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ASVspoof2021LA_eval(torch.utils.data.Dataset):\n",
    "    def __init__(self, sys_config=SysConfig(), exp_config=ExpConfig()):\n",
    "        super().__init__()\n",
    "        self.duration = int(exp_config.test_duration_sec * exp_config.sample_rate)\n",
    "        path_label = sys_config.path_label_asv_spoof_2021_la_eval\n",
    "        path_eval  = sys_config.path_asv_spoof_2021_la_eval\n",
    "\n",
    "        self.data_list = []\n",
    "        if os.path.exists(path_label):\n",
    "            for line in open(path_label, \"r\").readlines():\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 8 or parts[7] != \"eval\":\n",
    "                    continue\n",
    "                file_id, attack_type = parts[1], parts[4]\n",
    "                label = 0 if attack_type == \"bonafide\" else 1\n",
    "                wav_path = os.path.join(path_eval, f\"{file_id}.flac\")\n",
    "                self.data_list.append((wav_path, attack_type, label))\n",
    "        else:\n",
    "            print(f\"[WARN] Label file missing: {path_label}\")\n",
    "\n",
    "    def __len__(self): return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        wav_path, _, label = self.data_list[idx]\n",
    "        wav, _ = torchaudio.load(wav_path)  # (C,T)\n",
    "        wav = self._fix_duration(wav)\n",
    "        return wav, label\n",
    "\n",
    "    def _fix_duration(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.squeeze(0) if x.dim() == 2 else x\n",
    "        need = self.duration\n",
    "        if x.numel() < need:\n",
    "            reps = need // x.numel()\n",
    "            rem  = need %  x.numel()\n",
    "            x = torch.cat([x] * reps + ([x[:rem]] if rem > 0 else []))\n",
    "        return x[:need]\n",
    "\n",
    "\n",
    "class ASVspoof2019LA(torch.utils.data.Dataset):\n",
    "    def __init__(self, sys_config=SysConfig(), exp_config=ExpConfig(), augment: bool = False):\n",
    "        super().__init__()\n",
    "        self.duration = int(exp_config.train_duration_sec * exp_config.sample_rate)\n",
    "        self.aug = WaveformAugmentation(sr=exp_config.sample_rate) if augment else None\n",
    "\n",
    "        train_label = sys_config.path_label_asv_spoof_2019_la_train\n",
    "        dev_label   = sys_config.path_label_asv_spoof_2019_la_dev\n",
    "        path_train  = sys_config.path_asv_spoof_2019_la_train\n",
    "        path_dev    = sys_config.path_asv_spoof_2019_la_dev\n",
    "\n",
    "        self.data_list = []\n",
    "        if os.path.exists(train_label):\n",
    "            for line in open(train_label, \"r\").readlines():\n",
    "                parts = line.strip().split()\n",
    "                file_id, attack_type = parts[1], parts[3]\n",
    "                label = 0 if parts[4] == \"bonafide\" else 1\n",
    "                wav_path = os.path.join(path_train, f\"{file_id}.flac\")\n",
    "                self.data_list.append((wav_path, attack_type, label))\n",
    "        if os.path.exists(dev_label):\n",
    "            for line in open(dev_label, \"r\").readlines():\n",
    "                parts = line.strip().split()\n",
    "                file_id, attack_type = parts[1], parts[3]\n",
    "                label = 0 if parts[4] == \"bonafide\" else 1\n",
    "                wav_path = os.path.join(path_dev, f\"{file_id}.flac\")\n",
    "                self.data_list.append((wav_path, attack_type, label))\n",
    "        if not self.data_list:\n",
    "            print(\"[WARN] No 2019 LA data found. Check your paths in SysConfig.\")\n",
    "\n",
    "    def __len__(self): return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        wav_path, _, label = self.data_list[idx]\n",
    "        wav, _ = torchaudio.load(wav_path)\n",
    "        wav = self._random_duration(wav)\n",
    "        if self.aug is not None:\n",
    "            wav = self.aug(wav)\n",
    "        return wav, label\n",
    "\n",
    "    def _random_duration(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.squeeze(0) if x.dim() == 2 else x\n",
    "        L = x.numel()\n",
    "        need = self.duration\n",
    "        if L < need:\n",
    "            reps = need // L\n",
    "            rem  = need %  L\n",
    "            x = torch.cat([x] * reps + ([x[:rem]] if rem > 0 else []))\n",
    "            L = x.numel()\n",
    "        start = random.randint(0, L - need)\n",
    "        return x[start:start+need]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.707704Z",
     "iopub.status.busy": "2025-11-06T05:00:25.707430Z",
     "iopub.status.idle": "2025-11-06T05:00:25.727869Z",
     "shell.execute_reply": "2025-11-06T05:00:25.727339Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.707686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_pad(batch):\n",
    "    # Here all items are same length already; just stack.\n",
    "    wavs, labels = zip(*batch)\n",
    "    wavs = torch.stack(wavs, dim=0)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return wavs, labels\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, preemph=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for wav, label in loader:\n",
    "        wav = wav.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        if preemph is not None:\n",
    "            wav = preemph(wav)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(wav)              # (B,)\n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * wav.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, preemph=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    for wav, label in loader:\n",
    "        wav = wav.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        if preemph is not None:\n",
    "            wav = preemph(wav)\n",
    "        pred = model(wav)\n",
    "        loss = criterion(pred, label)\n",
    "        total_loss += loss.item() * wav.size(0)\n",
    "        total_correct += ((pred > 0.5).float() == label).sum().item()\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = total_correct / len(loader.dataset)\n",
    "    return avg_loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:00:25.728789Z",
     "iopub.status.busy": "2025-11-06T05:00:25.728608Z",
     "iopub.status.idle": "2025-11-06T05:00:26.310681Z",
     "shell.execute_reply": "2025-11-06T05:00:26.310055Z",
     "shell.execute_reply.started": "2025-11-06T05:00:25.728771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([2]) | values ~ (0.49742913246154785, 0.49765050411224365)\n"
     ]
    }
   ],
   "source": [
    "# Build model and run a forward pass with dummy audio\n",
    "exp_cfg = ExpConfig()\n",
    "model = Rawformer_S(device=DEVICE, transformer_hidden=exp_cfg.transformer_hidden,\n",
    "                          sample_rate=exp_cfg.sample_rate)\n",
    "\n",
    "B = 2\n",
    "dummy_audio = torch.randn(B, exp_cfg.sample_rate * exp_cfg.train_duration_sec).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    out = model(dummy_audio)\n",
    "print(\"Model output shape:\", out.shape, \"| values ~\", (out.min().item(), out.max().item()))\n",
    "\n",
    "if HAS_TORCHINFO:\n",
    "    try:\n",
    "        summary(model, input_size=(B, exp_cfg.sample_rate * exp_cfg.train_duration_sec))\n",
    "    except Exception as e:\n",
    "        print(\"torchinfo summary error (safe to ignore):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchaudio\n",
    "# torchaudio.set_audio_backend(\"ffmpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T06:08:48.930214Z",
     "iopub.status.busy": "2025-11-06T06:08:48.929653Z",
     "iopub.status.idle": "2025-11-06T06:28:26.524048Z",
     "shell.execute_reply": "2025-11-06T06:28:26.522968Z",
     "shell.execute_reply.started": "2025-11-06T06:08:48.930187Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cuda\n",
      "📁 Loaded 25380 files from G:\\INTERSPEECH_26\\LA\\ASV19\\train\n",
      "📁 Loaded 24844 files from G:\\INTERSPEECH_26\\LA\\ASV19\\dev\n",
      "📁 Loaded 24844 files from G:\\INTERSPEECH_26\\LA\\ASV19\\dev\n",
      "🚀 Starting training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196a2c6a29054a7bb4bb505d13d46c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e17f9e6fa94e77a8a39822eb4ce895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 1 Summary:\n",
      "   Train Loss: 0.2469\n",
      "   Val Loss:   0.1918\n",
      "   Val EER:    13.47%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=13.47%) to best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031827be6f38427fb048b753dfc5aff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d320c3415258424686a0777e725a2774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 2 Summary:\n",
      "   Train Loss: 0.1579\n",
      "   Val Loss:   0.0964\n",
      "   Val EER:    6.24%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=6.24%) to best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bc489a223e44fe985ae1a1139fa9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342899795dc54990afdf0d672d30ee24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 3 Summary:\n",
      "   Train Loss: 0.0852\n",
      "   Val Loss:   0.0784\n",
      "   Val EER:    5.27%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=5.27%) to best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ab9d05771e405ca3f00fc66379c3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7734dff7f147487f8ba3056e1cd0cdc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 4 Summary:\n",
      "   Train Loss: 0.0557\n",
      "   Val Loss:   0.0320\n",
      "   Val EER:    2.28%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=2.28%) to best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90f797b0ea044c398c76a4e82ebfab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8b7812ecf54197b53848baa7db3e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 5 Summary:\n",
      "   Train Loss: 0.0374\n",
      "   Val Loss:   0.0353\n",
      "   Val EER:    2.35%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae72e785efb54ecb9008556ba6a4306c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6d590a3c074b7c9bba59eca9fd81a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 6 Summary:\n",
      "   Train Loss: 0.0373\n",
      "   Val Loss:   0.0266\n",
      "   Val EER:    1.97%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=1.97%) to best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c167ce9f34498ca38e9f7fe87fd864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae8900f6a26456081ec4732faae46b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 7 Summary:\n",
      "   Train Loss: 0.0355\n",
      "   Val Loss:   0.0394\n",
      "   Val EER:    2.43%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8846ba6d06496b95f882f6e505bcda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ab06ff568b4753b3216e7d56215c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 8 Summary:\n",
      "   Train Loss: 0.0433\n",
      "   Val Loss:   0.0645\n",
      "   Val EER:    2.55%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6022e2da647546c9adf98b2260c53025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac8348f127e4c8dbe557554a70744f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 9 Summary:\n",
      "   Train Loss: 0.0284\n",
      "   Val Loss:   0.0716\n",
      "   Val EER:    2.16%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a7d4bf767549158cbc82b864d73038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af1c8b85262469492ba36b575d5b668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 10 Summary:\n",
      "   Train Loss: 0.0354\n",
      "   Val Loss:   0.0523\n",
      "   Val EER:    2.02%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11eaefc432984b60b3457b8566b425dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1b6e1f08794a688ff3c7aeb376caa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 11 Summary:\n",
      "   Train Loss: 0.0279\n",
      "   Val Loss:   0.0206\n",
      "   Val EER:    1.37%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=1.37%) to best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e56051bbfb34769b3c7c8dfc60b5215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae28be4c843b438dbf1fb1bf5319d9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 12 Summary:\n",
      "   Train Loss: 0.0248\n",
      "   Val Loss:   0.0482\n",
      "   Val EER:    2.24%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07eb6bdef764d3a9cd56be984840318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3bdcf67f3b4f2a94a51f9076bebfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 13 Summary:\n",
      "   Train Loss: 0.0312\n",
      "   Val Loss:   0.0613\n",
      "   Val EER:    2.35%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e94f5a73654467bf454ebb656f33e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f472275014814bd69f491786c2e01f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 14 Summary:\n",
      "   Train Loss: 0.0327\n",
      "   Val Loss:   0.0537\n",
      "   Val EER:    1.26%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=1.26%) to best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1e4636ead04c3c8fe414f1efb78bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4583ba5e594480ea516b001c15d2bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 15 Summary:\n",
      "   Train Loss: 0.0245\n",
      "   Val Loss:   0.0182\n",
      "   Val EER:    1.02%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=1.02%) to best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671a7547349f4e22b2ed9d402c150309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9b3366a52b462c80fbe311955ce311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 16 Summary:\n",
      "   Train Loss: 0.0209\n",
      "   Val Loss:   0.0225\n",
      "   Val EER:    1.30%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ef15a640314ef988be4dd6848038b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd5f834e87845418dcd6ba135dbd368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 17 Summary:\n",
      "   Train Loss: 0.0376\n",
      "   Val Loss:   0.0205\n",
      "   Val EER:    1.22%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee83217a626411a8707fca6b997b330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25be2e9fedb49ae92952967650479ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 18 Summary:\n",
      "   Train Loss: 0.0398\n",
      "   Val Loss:   0.0558\n",
      "   Val EER:    1.54%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391acb118e8c4a86aeac4abd58c906f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc80a9aeed74efcaae43f8fe0c11ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 19 Summary:\n",
      "   Train Loss: 0.0292\n",
      "   Val Loss:   0.5847\n",
      "   Val EER:    8.47%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4bf793622940b58e3569de23fde0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4a24424a4f46d0af55697bded3842e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 20 Summary:\n",
      "   Train Loss: 0.0319\n",
      "   Val Loss:   0.0322\n",
      "   Val EER:    1.45%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599ee2941c6b4a77b6982fcda8104346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4d6c65470246b39b7480a430b98bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 21 Summary:\n",
      "   Train Loss: 0.0206\n",
      "   Val Loss:   0.0146\n",
      "   Val EER:    1.06%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30006fe06ca4f5f81584edca05ddac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c47ff47996648428d0e2fd288c76bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 22 Summary:\n",
      "   Train Loss: 0.0193\n",
      "   Val Loss:   0.0222\n",
      "   Val EER:    1.14%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fa3109ac474dd2b5e05d3904d29ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed8e5a0ebb24118b3b6f49b65894aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 23 Summary:\n",
      "   Train Loss: 0.0225\n",
      "   Val Loss:   0.0275\n",
      "   Val EER:    1.84%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525fed9b5fa443c3b3bf7c2225bf0711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48483a085d49430587d542e92b71316c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 24 Summary:\n",
      "   Train Loss: 0.0282\n",
      "   Val Loss:   0.0382\n",
      "   Val EER:    1.69%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bfb4054e394cd1abf27e5b60b9e3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4844c30f92b4494b9c1b78ab2bd07ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 25 Summary:\n",
      "   Train Loss: 0.0239\n",
      "   Val Loss:   0.0192\n",
      "   Val EER:    1.02%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb4476d77a54f92a1d8f97f2ec1f140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc00367fd1f54b1aa058c73e95412be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 26 Summary:\n",
      "   Train Loss: 0.0237\n",
      "   Val Loss:   0.0166\n",
      "   Val EER:    0.99%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=0.99%) to best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687c2f9ddf6940169f6dbcf388103708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986d9dd849874dae81933afbd2be7531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 27 Summary:\n",
      "   Train Loss: 0.0229\n",
      "   Val Loss:   0.0188\n",
      "   Val EER:    1.30%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb8c5c7e9fd443fafef3942f9a75df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8560295698e544018d8c4812ed8ddd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 28 Summary:\n",
      "   Train Loss: 0.0166\n",
      "   Val Loss:   0.0143\n",
      "   Val EER:    1.02%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766e4ed9d6944531a729d0d9aa92ef7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9465685fe92f4bddbd673d188604abfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 29 Summary:\n",
      "   Train Loss: 0.0191\n",
      "   Val Loss:   0.0208\n",
      "   Val EER:    1.53%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd61cbba37641b5bb3eb58e77a89a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f676b70c694845a3726e0f538eac2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 30 Summary:\n",
      "   Train Loss: 0.0253\n",
      "   Val Loss:   0.0247\n",
      "   Val EER:    1.66%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0045f20c24a4e0795276e9cfa3b9f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e9e745bf8d4c7aab4e453375a0bf11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 31 Summary:\n",
      "   Train Loss: 0.0195\n",
      "   Val Loss:   0.0205\n",
      "   Val EER:    1.06%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09290a65458435bafc357d7f15c2f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903e6de6904b4d5c8dd28895830fd7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 32 Summary:\n",
      "   Train Loss: 0.0184\n",
      "   Val Loss:   0.0115\n",
      "   Val EER:    0.78%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=0.78%) to best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa112bc9d4ce479693abc7aa54745784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370088b502cf4530bf8f904327e65a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 33 Summary:\n",
      "   Train Loss: 0.0141\n",
      "   Val Loss:   0.0284\n",
      "   Val EER:    2.00%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743fd88a8eb44cd58018d9462679bd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9798739965734ab69749a411294a21ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 34 Summary:\n",
      "   Train Loss: 0.0175\n",
      "   Val Loss:   0.0275\n",
      "   Val EER:    1.20%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd6466f9bc8427db89761ad3d7f286d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58811027f17e40858160a1859663fb4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 35 Summary:\n",
      "   Train Loss: 0.0190\n",
      "   Val Loss:   0.0204\n",
      "   Val EER:    1.02%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7772b8e2b994fe1aecf93412939fde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a188b02dfa7d42afb88b7722f7e678aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 36 Summary:\n",
      "   Train Loss: 0.0163\n",
      "   Val Loss:   0.0234\n",
      "   Val EER:    0.90%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb0e2ccaf7a47608eb8c9400bfde40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2c1078a1f146878e5a385ab9fbc40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 37 Summary:\n",
      "   Train Loss: 0.0236\n",
      "   Val Loss:   0.0180\n",
      "   Val EER:    1.26%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787b871db7854c61994611dfe8da4439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a27b3013db467c9f7b64f25b257847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 38 Summary:\n",
      "   Train Loss: 0.0172\n",
      "   Val Loss:   0.0163\n",
      "   Val EER:    1.02%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb89e4390d2549f7bb6749f6e4b2b32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1373fa62e5e4561a6cf234898684a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 39 Summary:\n",
      "   Train Loss: 0.0139\n",
      "   Val Loss:   0.0194\n",
      "   Val EER:    0.97%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687135bb02024549a3c6625edabd4f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f2818de1c948a6b042775b17c3a510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 40 Summary:\n",
      "   Train Loss: 0.0119\n",
      "   Val Loss:   0.0122\n",
      "   Val EER:    0.67%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=0.67%) to best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9055f8ad5d1a45ae875dea1c63509009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259ebe7ca5c5497481729596bd84dc14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 41 Summary:\n",
      "   Train Loss: 0.0133\n",
      "   Val Loss:   0.0184\n",
      "   Val EER:    1.33%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea27b26c0ee64005bb0fade37e7fd52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e635c0138444a686fcf6f1d605bd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 42 Summary:\n",
      "   Train Loss: 0.0165\n",
      "   Val Loss:   0.0221\n",
      "   Val EER:    1.31%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59ca68a5700488abe57a4393843dfee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6433f73f6644488b55a2419f655b201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 43 Summary:\n",
      "   Train Loss: 0.0154\n",
      "   Val Loss:   0.0111\n",
      "   Val EER:    0.90%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a755cab4a74dd3b4ad964ed57f8560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ffedd546244f14a8c72b7072ca5798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 44 Summary:\n",
      "   Train Loss: 0.0213\n",
      "   Val Loss:   0.0907\n",
      "   Val EER:    5.58%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdd55437aca4a26a30ed2984ce22cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33765bcf9704f7ba20288949f2b0011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 45 Summary:\n",
      "   Train Loss: 0.0296\n",
      "   Val Loss:   0.0168\n",
      "   Val EER:    1.14%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a161a088764488c8f7b08a9da0295e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9573116d88ae4224997e7050f821910e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 46 Summary:\n",
      "   Train Loss: 0.0207\n",
      "   Val Loss:   0.0906\n",
      "   Val EER:    6.27%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a8e1e1d5a24636bc5a51a55439c0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2ca686fc314673a797744f63871d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 47 Summary:\n",
      "   Train Loss: 0.0230\n",
      "   Val Loss:   0.0188\n",
      "   Val EER:    1.10%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1587c73ff6c4f53ac4e281ad46e5a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ab8a3e458648a4a70adbf189151388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 48 Summary:\n",
      "   Train Loss: 0.0185\n",
      "   Val Loss:   0.0340\n",
      "   Val EER:    1.39%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6baae9510aee43f9a6b163dd9353f01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f28adef39f4be8b2f36f18707b5805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 49 Summary:\n",
      "   Train Loss: 0.0224\n",
      "   Val Loss:   0.0212\n",
      "   Val EER:    1.33%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27911bc818934b52b5099d5d8d89151c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16027ba624d04617ac3f36cca35bfb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 50 Summary:\n",
      "   Train Loss: 0.0200\n",
      "   Val Loss:   0.0217\n",
      "   Val EER:    1.26%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "🏁 Starting final testing...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15924\\898445770.py:258: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model = torch.load(save_path, map_location=DEVICE)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4a496cf6c8449da6da6fb185bc02b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Final Test EER:  0.70%\n",
      "📊 Final min-tDCF: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import os\n",
    "import random\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn import metrics\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "class SysConfig:\n",
    "    path_train = r\"G:\\INTERSPEECH_26\\LA\\ASV19\\train\"\n",
    "    path_dev   = r\"G:\\INTERSPEECH_26\\LA\\ASV19\\dev\"\n",
    "    path_test  =r\"G:\\INTERSPEECH_26\\LA\\ASV19\\dev\"\n",
    "\n",
    "class ExpConfig:\n",
    "    # Audio processing\n",
    "    sample_rate = 16000\n",
    "    pre_emphasis = 0.97\n",
    "    train_duration_sec = 4\n",
    "    test_duration_sec = 4\n",
    "\n",
    "    # Model\n",
    "    transformer_hidden = 660\n",
    "\n",
    "    # Training hyperparameters\n",
    "    batch_size = 32\n",
    "    lr = 8*1e-4\n",
    "    epochs = 50  # increase as needed\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"✅ Using device: {DEVICE}\")\n",
    "\n",
    "# ============================================================\n",
    "# SIMPLE DATASET\n",
    "# ============================================================\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "class ASVspoofFolderDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, sample_rate=16000, duration_sec=4):\n",
    "        self.root_dir = root_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration_sec = duration_sec\n",
    "        self.audio_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label_name, label_value in [(\"bonafide\", 1), (\"spoof\", 0)]:\n",
    "            class_dir = os.path.join(root_dir, label_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for file in os.listdir(class_dir):\n",
    "                    if file.endswith(\".flac\") or file.endswith(\".wav\"):\n",
    "                        self.audio_paths.append(os.path.join(class_dir, file))\n",
    "                        self.labels.append(label_value)\n",
    "\n",
    "        print(f\"📁 Loaded {len(self.audio_paths)} files from {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.audio_paths[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "        # --- Use soundfile for FLAC ---\n",
    "        if path.lower().endswith(\".flac\"):\n",
    "            wav_np, sr = sf.read(path)         # numpy array (T,) or (T, C)\n",
    "            if wav_np.ndim > 1:                # convert stereo → mono\n",
    "                wav_np = wav_np.mean(axis=1)\n",
    "            wav = torch.tensor(wav_np, dtype=torch.float32).unsqueeze(0)  # [1, T]\n",
    "\n",
    "        # --- Use torchaudio for WAV ---\n",
    "        else:\n",
    "            wav, sr = torchaudio.load(path)\n",
    "\n",
    "        # --- Resample if needed ---\n",
    "        if sr != self.sample_rate:\n",
    "            wav = torchaudio.functional.resample(wav, sr, self.sample_rate)\n",
    "\n",
    "        # --- Crop/pad ---\n",
    "        num_samples = int(self.sample_rate * self.duration_sec)\n",
    "\n",
    "        if wav.size(1) > num_samples:\n",
    "            start = random.randint(0, wav.size(1) - num_samples)\n",
    "            wav = wav[:, start:start + num_samples]\n",
    "        elif wav.size(1) < num_samples:\n",
    "            wav = F.pad(wav, (0, num_samples - wav.size(1)))\n",
    "\n",
    "        return wav.squeeze(0), label\n",
    "\n",
    "# ============================================================\n",
    "# EER FUNCTION (FOR CM SYSTEM)\n",
    "# ============================================================\n",
    "\n",
    "def calculate_EER(labels, scores):\n",
    "    \"\"\"Equal Error Rate for Countermeasure system (bonafide=1, spoof=0).\"\"\"\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, scores, pos_label=1)\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    return eer\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# t-DCF FUNCTION (CM-only version using reference ASV parameters)\n",
    "# ============================================================\n",
    "\n",
    "def compute_tDCF(bonafide_score_cm, spoof_score_cm, Pfa_asv, Pmiss_asv, Pfa_spoof_asv, cost_model):\n",
    "    # 1. Compute CM miss/false-alarm rates for thresholds\n",
    "    cm_scores = np.concatenate([bonafide_score_cm, spoof_score_cm])\n",
    "    labels = np.concatenate([np.ones_like(bonafide_score_cm), np.zeros_like(spoof_score_cm)])\n",
    "    sorted_idx = np.argsort(cm_scores)[::-1]\n",
    "    sorted_labels = labels[sorted_idx]\n",
    "\n",
    "    tar = np.sum(sorted_labels)\n",
    "    non = len(sorted_labels) - tar\n",
    "\n",
    "    cm_miss = np.cumsum(sorted_labels == 1) / tar\n",
    "    cm_fa = np.cumsum(sorted_labels == 0) / non\n",
    "\n",
    "    # 2. Compute t-DCF per threshold\n",
    "    Cmiss, Cfa, Cfa_spoof = cost_model['Cmiss'], cost_model['Cfa'], cost_model['Cfa_spoof']\n",
    "    Ptar, Pnon, Pspoof = cost_model['Ptar'], cost_model['Pnon'], cost_model['Pspoof']\n",
    "\n",
    "    tDCF = (Cmiss * Ptar * Pmiss_asv * (1 - cm_miss) +\n",
    "            Cfa * Pnon * Pfa_asv * cm_fa +\n",
    "            Cfa_spoof * Pspoof * Pfa_spoof_asv * (1 - cm_miss)) / (\n",
    "            Cmiss * Ptar * Pmiss_asv + Cfa * Pnon * Pfa_asv)\n",
    "\n",
    "    tDCF_norm = tDCF / np.min(tDCF)\n",
    "    thresholds = cm_scores[sorted_idx]\n",
    "\n",
    "    return tDCF_norm, thresholds\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN + VALIDATE + TEST LOOP\n",
    "# ============================================================\n",
    "\n",
    "sys_cfg = SysConfig()\n",
    "exp_cfg = ExpConfig()\n",
    "\n",
    "train_ds = ASVspoofFolderDataset(sys_cfg.path_train, exp_cfg.sample_rate, exp_cfg.train_duration_sec)\n",
    "val_ds   = ASVspoofFolderDataset(sys_cfg.path_dev, exp_cfg.sample_rate, exp_cfg.test_duration_sec)\n",
    "test_ds  = ASVspoofFolderDataset(sys_cfg.path_test, exp_cfg.sample_rate, exp_cfg.test_duration_sec)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=exp_cfg.batch_size, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds, batch_size=exp_cfg.batch_size, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds, batch_size=exp_cfg.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# --- your modules ---\n",
    "pre = PreEmphasis(exp_cfg.pre_emphasis).to(DEVICE)\n",
    "model = Rawformer_S(device=DEVICE, transformer_hidden=exp_cfg.transformer_hidden, sample_rate=exp_cfg.sample_rate).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=exp_cfg.lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "best_val_eer = 1.0  # initialize high value\n",
    "save_path = \"best_cm_model.pth\"\n",
    "\n",
    "print(\"🚀 Starting training...\\n\")\n",
    "\n",
    "# Reference ASV parameters (official ASVspoof setup)\n",
    "Pfa_asv = 0.0005\n",
    "Pmiss_asv = 0.05\n",
    "Pmiss_spoof_asv = 0.95\n",
    "Pfa_spoof_asv = 1.0 - Pmiss_spoof_asv\n",
    "cost_model = {\n",
    "    'Ptar': 0.9801,\n",
    "    'Pnon': 0.0099,\n",
    "    'Pspoof': 0.0100,\n",
    "    'Cmiss': 1,\n",
    "    'Cfa': 10,\n",
    "    'Cfa_spoof': 10\n",
    "}\n",
    "\n",
    "for epoch in range(1, exp_cfg.epochs + 1):\n",
    "    # === TRAIN ===\n",
    "    model.train()\n",
    "    total_loss, total_samples = 0.0, 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{exp_cfg.epochs} [Train]\", leave=True)\n",
    "\n",
    "    for wav, label in pbar:\n",
    "        wav, label = wav.to(DEVICE), label.to(DEVICE)\n",
    "        wav = pre(wav)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        pred = model(wav).squeeze(-1)\n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        bs = wav.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_samples += bs\n",
    "        pbar.set_postfix(loss=f\"{total_loss / total_samples:.4f}\")\n",
    "\n",
    "    avg_train_loss = total_loss / total_samples\n",
    "\n",
    "    # === VALIDATE ===\n",
    "    model.eval()\n",
    "    val_loss, val_samples = 0.0, 0\n",
    "    all_scores, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=f\"Epoch {epoch}/{exp_cfg.epochs} [Val]\", leave=True)\n",
    "        for wav, label in pbar:\n",
    "            wav, label = wav.to(DEVICE), label.to(DEVICE)\n",
    "            wav = pre(wav)\n",
    "            pred = model(wav).squeeze(-1)\n",
    "            loss = criterion(pred, label)\n",
    "\n",
    "            bs = wav.size(0)\n",
    "            val_loss += loss.item() * bs\n",
    "            val_samples += bs\n",
    "\n",
    "            all_scores.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / val_samples\n",
    "    eer = calculate_EER(all_labels, all_scores)\n",
    "\n",
    "    # --- Compute t-DCF ---\n",
    "    bona_cm = np.array(all_scores)[np.array(all_labels) == 1]\n",
    "    spoof_cm = np.array(all_scores)[np.array(all_labels) == 0]\n",
    "    tDCF_curve, thr = compute_tDCF(bona_cm, spoof_cm, Pfa_asv, Pmiss_asv, Pfa_spoof_asv, cost_model)\n",
    "    min_tDCF = np.min(tDCF_curve)\n",
    "\n",
    "    print(f\"🧾 Epoch {epoch} Summary:\")\n",
    "    print(f\"   Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"   Val Loss:   {avg_val_loss:.4f}\")\n",
    "    print(f\"   Val EER:    {eer * 100:.2f}%\")\n",
    "    print(f\"   min-tDCF:   {min_tDCF:.4f}\")\n",
    "\n",
    "    # === SAVE BEST MODEL ===\n",
    "    if eer < best_val_eer:\n",
    "        best_val_eer = eer\n",
    "        torch.save(model, save_path)\n",
    "        print(f\"💾 Saved new best model (EER={eer*100:.2f}%) to {save_path}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FINAL TEST PHASE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🏁 Starting final testing...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load best model\n",
    "best_model = torch.load(save_path, map_location=DEVICE)\n",
    "best_model.eval()\n",
    "\n",
    "test_scores, test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(test_loader, desc=\"Testing\", leave=True)\n",
    "    for wav, label in pbar:\n",
    "        wav, label = wav.to(DEVICE), label.to(DEVICE)\n",
    "        wav = pre(wav)\n",
    "        pred = best_model(wav).squeeze(-1)\n",
    "        test_scores.extend(pred.cpu().numpy())\n",
    "        test_labels.extend(label.cpu().numpy())\n",
    "\n",
    "test_eer = calculate_EER(test_labels, test_scores)\n",
    "\n",
    "bona_cm = np.array(test_scores)[np.array(test_labels) == 1]\n",
    "spoof_cm = np.array(test_scores)[np.array(test_labels) == 0]\n",
    "tDCF_curve, thr = compute_tDCF(bona_cm, spoof_cm, Pfa_asv, Pmiss_asv, Pfa_spoof_asv, cost_model)\n",
    "min_tDCF = np.min(tDCF_curve)\n",
    "\n",
    "print(f\"🎯 Final Test EER:  {test_eer * 100:.2f}%\")\n",
    "print(f\"📊 Final min-tDCF: {min_tDCF:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting fvcore\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from fvcore) (1.26.4)\n",
      "Collecting yacs>=0.1.6 (from fvcore)\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from fvcore) (6.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (from fvcore) (4.66.5)\n",
      "Collecting termcolor>=1.1 (from fvcore)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\admin\\anaconda3\\lib\\site-packages (from fvcore) (10.4.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\admin\\anaconda3\\lib\\site-packages (from fvcore) (0.9.0)\n",
      "Collecting iopath>=0.1.7 (from fvcore)\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\admin\\anaconda3\\lib\\site-packages (from iopath>=0.1.7->fvcore) (4.15.0)\n",
      "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm->fvcore) (0.4.6)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from portalocker->iopath>=0.1.7->fvcore) (305.1)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Building wheels for collected packages: fvcore, iopath\n",
      "  Building wheel for fvcore (setup.py): started\n",
      "  Building wheel for fvcore (setup.py): finished with status 'done'\n",
      "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61412 sha256=e127e40b537d17dbd66a4433fa87376970dc0560cab9b62ff484eeb9370aa27d\n",
      "  Stored in directory: C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-i1rlkt53\\wheels\\ed\\9f\\a5\\e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
      "  Building wheel for iopath (setup.py): started\n",
      "  Building wheel for iopath (setup.py): finished with status 'done'\n",
      "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31543 sha256=2710395c5b47e588433265a4e740c65122b8c9de682479c99fa1f73bc2c8a03d\n",
      "  Stored in directory: C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-i1rlkt53\\wheels\\7c\\96\\04\\4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n",
      "Successfully built fvcore iopath\n",
      "Installing collected packages: yacs, torchinfo, termcolor, portalocker, iopath, fvcore\n",
      "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.2.0 termcolor-3.2.0 torchinfo-1.8.0 yacs-0.1.8\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-06T05:57:41.191354Z",
     "iopub.status.idle": "2025-11-06T05:57:41.191578Z",
     "shell.execute_reply": "2025-11-06T05:57:41.191483Z",
     "shell.execute_reply.started": "2025-11-06T05:57:41.191473Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::abs encountered 1 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 5 time(s)\n",
      "Unsupported operator aten::selu_ encountered 8 time(s)\n",
      "Unsupported operator aten::add encountered 17 time(s)\n",
      "Unsupported operator aten::mul encountered 7 time(s)\n",
      "Unsupported operator aten::div encountered 6 time(s)\n",
      "Unsupported operator aten::softmax encountered 3 time(s)\n",
      "Unsupported operator aten::mean encountered 4 time(s)\n",
      "Unsupported operator aten::var encountered 4 time(s)\n",
      "Unsupported operator aten::sub encountered 4 time(s)\n",
      "Unsupported operator aten::sqrt encountered 4 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 1 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL PARAMETER SUMMARY\n",
      "============================================================\n",
      "Trainable params         : 345,132\n",
      "Total params             : 345,132\n",
      "Model size (MiB)         : 1.32\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "FLOPs / MACs (per forward pass)\n",
      "============================================================\n",
      "Input shape              : [1, 64000]\n",
      "MACs                     : 6.186 G\n",
      "FLOPs                    : 12.371 G\n",
      "============================================================\n",
      "\n",
      "Detailed layer-wise breakdown (torchinfo):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================================================================================================================================================================\n",
       "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "================================================================================================================================================================\n",
       "Rawformer_S                                                  [1, 64000]                [1]                       --                        --\n",
       "├─Frontend_S: 1-1                                            [1, 64000]                [1, 64, 23, 16]           --                        --\n",
       "│    └─SincConv: 2-1                                         [1, 1, 64000]             [1, 70, 63872]            --                        --\n",
       "│    └─BatchNorm2d: 2-2                                      [1, 1, 23, 21290]         [1, 1, 23, 21290]         2                         2\n",
       "│    └─SELU: 2-3                                             [1, 1, 23, 21290]         [1, 1, 23, 21290]         --                        --\n",
       "│    └─Sequential: 2-4                                       [1, 1, 23, 21290]         [1, 64, 23, 16]           --                        --\n",
       "│    │    └─Conv2DBlock_S: 3-1                               [1, 1, 23, 21290]         [1, 32, 23, 3548]         --                        --\n",
       "│    │    │    └─Conv2d: 4-1                                 [1, 1, 23, 21290]         [1, 32, 23, 21290]        128                       62,677,760\n",
       "│    │    │    └─Sequential: 4-2                             [1, 1, 23, 21290]         [1, 32, 23, 21290]        6,592                     3,204,059,904\n",
       "│    │    │    └─MaxPool2d: 4-3                              [1, 32, 23, 21290]        [1, 32, 23, 3548]         --                        --\n",
       "│    │    └─Conv2DBlock_S: 3-2                               [1, 32, 23, 3548]         [1, 32, 23, 591]          --                        --\n",
       "│    │    │    └─Sequential: 4-4                             [1, 32, 23, 3548]         [1, 32, 23, 3548]         64                        64\n",
       "│    │    │    └─Sequential: 4-5                             [1, 32, 23, 3548]         [1, 32, 23, 3548]         16,512                    1,378,667,712\n",
       "│    │    │    └─MaxPool2d: 4-6                              [1, 32, 23, 3548]         [1, 32, 23, 591]          --                        --\n",
       "│    │    └─Conv2DBlock_S: 3-3                               [1, 32, 23, 591]          [1, 64, 23, 98]           --                        --\n",
       "│    │    │    └─Conv2d: 4-7                                 [1, 32, 23, 591]          [1, 64, 23, 591]          6,208                     84,385,344\n",
       "│    │    │    └─Sequential: 4-8                             [1, 32, 23, 591]          [1, 32, 23, 591]          64                        64\n",
       "│    │    │    └─Sequential: 4-9                             [1, 32, 23, 591]          [1, 64, 23, 591]          45,312                    626,327,744\n",
       "│    │    │    └─MaxPool2d: 4-10                             [1, 64, 23, 591]          [1, 64, 23, 98]           --                        --\n",
       "│    │    └─Conv2DBlock_S: 3-4                               [1, 64, 23, 98]           [1, 64, 23, 16]           --                        --\n",
       "│    │    │    └─Sequential: 4-11                            [1, 64, 23, 98]           [1, 64, 23, 98]           128                       128\n",
       "│    │    │    └─Sequential: 4-12                            [1, 64, 23, 98]           [1, 64, 23, 98]           65,792                    152,027,136\n",
       "│    │    │    └─MaxPool2d: 4-13                             [1, 64, 23, 98]           [1, 64, 23, 16]           --                        --\n",
       "├─PositionalAggregator1D: 1-2                                [1, 64, 23, 16]           [1, 368, 64]              --                        --\n",
       "│    └─Flatten: 2-5                                          [1, 64, 23, 16]           [1, 64, 368]              --                        --\n",
       "├─RawformerClassifier: 1-3                                   [1, 368, 64]              [1]                       --                        --\n",
       "│    └─Sequential: 2-6                                       [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    └─TransformerEncoderLayer: 3-5                     [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    │    └─MultiHeadAttention: 4-14                    [1, 368, 64]              [1, 368, 64]              16,640                    16,640\n",
       "│    │    │    └─Dropout: 4-15                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    │    └─LayerNorm: 4-16                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "│    │    │    └─FFN: 4-17                                   [1, 368, 64]              [1, 368, 64]              85,204                    85,204\n",
       "│    │    │    └─Dropout: 4-18                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    │    └─LayerNorm: 4-19                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "│    │    └─TransformerEncoderLayer: 3-6                     [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    │    └─MultiHeadAttention: 4-20                    [1, 368, 64]              [1, 368, 64]              16,640                    16,640\n",
       "│    │    │    └─Dropout: 4-21                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    │    └─LayerNorm: 4-22                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "│    │    │    └─FFN: 4-23                                   [1, 368, 64]              [1, 368, 64]              85,204                    85,204\n",
       "│    │    │    └─Dropout: 4-24                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    │    └─LayerNorm: 4-25                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "│    └─SequencePooling: 2-7                                  [1, 368, 64]              [1, 64]                   --                        --\n",
       "│    │    └─Linear: 3-7                                      [1, 368, 64]              [1, 368, 1]               65                        65\n",
       "│    └─Linear: 2-8                                           [1, 64]                   [1, 1]                    65                        65\n",
       "================================================================================================================================================================\n",
       "Total params: 345,132\n",
       "Trainable params: 345,132\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.51\n",
       "================================================================================================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 644.79\n",
       "Params size (MB): 1.38\n",
       "Estimated Total Size (MB): 646.42\n",
       "================================================================================================================================================================"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "#  Model size & FLOPs (place this right after model creation)\n",
    "# --------------------------------------------------------------\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1. Parameter count (trainable + non-trainable) + size in MiB\n",
    "# --------------------------------------------------------------\n",
    "def print_model_params(model):\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total     = sum(p.numel() for p in model.parameters())\n",
    "    size_mb   = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024**2)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL PARAMETER SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Trainable params':<25}: {trainable:,}\")\n",
    "    print(f\"{'Total params'    :<25}: {total:,}\")\n",
    "    print(f\"{'Model size (MiB)':<25}: {size_mb:.2f}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "print_model_params(model)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2. FLOPs / MACs\n",
    "# --------------------------------------------------------------\n",
    "# We need a dummy waveform that matches the shape expected by the model.\n",
    "#   - Rawformer_S expects raw audio: (batch, time)\n",
    "#   - Use the maximum length defined in the config (or a typical 4-second clip)\n",
    "max_len_sec = getattr(exp_cfg, \"max_len_sec\", 4.0)          # fallback 4 s\n",
    "max_samples = int(exp_cfg.sample_rate * max_len_sec)\n",
    "\n",
    "dummy_wav = torch.randn(1, max_samples, device=DEVICE)     # (B, T)\n",
    "\n",
    "# Apply pre-emphasis if it is used in training/validation\n",
    "if pre is not None:\n",
    "    dummy_wav = pre(dummy_wav)\n",
    "\n",
    "# ---- fvcore (very accurate) ----\n",
    "flops = FlopCountAnalysis(model, dummy_wav)\n",
    "macs  = flops.total()                # MACs = multiply-adds\n",
    "flops_2 = macs * 2                   # FLOPs = 2 × MACs (standard convention)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FLOPs / MACs (per forward pass)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Input shape'   :<25}: {list(dummy_wav.shape)}\")\n",
    "print(f\"{'MACs'          :<25}: {macs/1e9:.3f} G\")\n",
    "print(f\"{'FLOPs'         :<25}: {flops_2/1e9:.3f} G\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# ---- torchinfo (nice table, optional) ----\n",
    "print(\"Detailed layer-wise breakdown (torchinfo):\")\n",
    "summary(model,\n",
    "        input_data=dummy_wav,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n",
    "        depth=4,\n",
    "        verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-06T05:57:09.284524Z",
     "iopub.status.idle": "2025-11-06T05:57:09.284726Z",
     "shell.execute_reply": "2025-11-06T05:57:09.284638Z",
     "shell.execute_reply.started": "2025-11-06T05:57:09.284629Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFLOPs per second of audio : 3.093\n"
     ]
    }
   ],
   "source": [
    "seconds = max_samples / exp_cfg.sample_rate\n",
    "print(f\"GFLOPs per second of audio : {flops_2/1e9/seconds:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2286778,
     "sourceId": 3842332,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8621024,
     "sourceId": 13570789,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
