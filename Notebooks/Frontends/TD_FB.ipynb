{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.249141Z",
     "iopub.status.busy": "2025-11-25T05:39:06.248208Z",
     "iopub.status.idle": "2025-11-25T05:39:06.254138Z",
     "shell.execute_reply": "2025-11-25T05:39:06.253422Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.249113Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU count: 1\n",
      "[0] NVIDIA GeForce RTX 4090\n",
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU count:\", torch.cuda.device_count())\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"[{i}] {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.255498Z",
     "iopub.status.busy": "2025-11-25T05:39:06.255272Z",
     "iopub.status.idle": "2025-11-25T05:39:06.269640Z",
     "shell.execute_reply": "2025-11-25T05:39:06.268912Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.255482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Optional, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.270636Z",
     "iopub.status.busy": "2025-11-25T05:39:06.270399Z",
     "iopub.status.idle": "2025-11-25T05:39:06.283470Z",
     "shell.execute_reply": "2025-11-25T05:39:06.282660Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.270619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Optional (nice for shapes):\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    HAS_TORCHINFO = True\n",
    "except Exception:\n",
    "    HAS_TORCHINFO = False\n",
    "\n",
    "save_path = r\"C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\"\n",
    "# ------------------ Configurable Paths ------------------ #\n",
    "class SysConfig:\n",
    "    \"\"\"\n",
    "    Folder-based dataset structure.\n",
    "    Each split (train/dev/test) contains two subfolders: bonafide and spoof.\n",
    "    \"\"\"\n",
    "    path_train =r\"G:\\INTERSPEECH_26\\LA\\ASV19\\train\"\n",
    "    path_dev   = r\"G:\\INTERSPEECH_26\\LA\\ASV19\\dev\"\n",
    "    path_test  =r\"G:\\INTERSPEECH_26\\LA\\ASV19\\dev\"\n",
    "\n",
    "\n",
    "# ------------------ Experiment Hyperparameters ------------------ #\n",
    "class ExpConfig:\n",
    "    # Audio processing\n",
    "    sample_rate = 16000\n",
    "    pre_emphasis = 0.97\n",
    "    train_duration_sec = 4\n",
    "    test_duration_sec = 4\n",
    "\n",
    "    # Model\n",
    "    transformer_hidden = 660\n",
    "\n",
    "    # Training hyperparameters\n",
    "    batch_size = 32\n",
    "    lr = 8*1e-4\n",
    "    epochs = 50  # increase as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.285135Z",
     "iopub.status.busy": "2025-11-25T05:39:06.284848Z",
     "iopub.status.idle": "2025-11-25T05:39:06.297266Z",
     "shell.execute_reply": "2025-11-25T05:39:06.296506Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.285118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch_audiomentations import (\n",
    "        Compose, AddColoredNoise, HighPassFilter, LowPassFilter, Gain\n",
    "    )\n",
    "    HAS_TA = True\n",
    "except Exception:\n",
    "    HAS_TA = False\n",
    "    Compose = AddColoredNoise = HighPassFilter = LowPassFilter = Gain = None\n",
    "\n",
    "class WaveformAugmentation(nn.Module):\n",
    "    def __init__(self, aug_list=('ACN', 'HPF', 'LPF', 'GAN'), sr=16000):\n",
    "        super().__init__()\n",
    "        self.sr = sr\n",
    "        if HAS_TA:\n",
    "            transforms = []\n",
    "            if 'ACN' in aug_list:\n",
    "                transforms.append(AddColoredNoise(10, 40, -2.0, 2.0, p=0.5))\n",
    "            if 'HPF' in aug_list:\n",
    "                transforms.append(HighPassFilter(20.0, 2400.0, p=0.5))\n",
    "            if 'LPF' in aug_list:\n",
    "                transforms.append(LowPassFilter(150.0, 7500.0, p=0.5))\n",
    "            if 'GAN' in aug_list:\n",
    "                transforms.append(Gain(-15.0, 5.0, p=0.5))\n",
    "            self.apply_augmentation = Compose(transforms) if transforms else None\n",
    "        else:\n",
    "            # No-op if torch_audiomentations isn't available\n",
    "            self.apply_augmentation = None\n",
    "\n",
    "    def forward(self, wav: torch.Tensor) -> torch.Tensor:\n",
    "        # wav: (B, T)\n",
    "        if self.apply_augmentation is None:\n",
    "            return wav\n",
    "        return self.apply_augmentation(wav.unsqueeze(1), self.sr).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.298208Z",
     "iopub.status.busy": "2025-11-25T05:39:06.298026Z",
     "iopub.status.idle": "2025-11-25T05:39:06.313209Z",
     "shell.execute_reply": "2025-11-25T05:39:06.312551Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.298194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PreEmphasis(nn.Module):\n",
    "    def __init__(self, pre_emphasis: float = 0.97):\n",
    "        super().__init__()\n",
    "        # Conv1D filter shape: (out_channels=1, in_channels=1, kernel_size=2)\n",
    "        filt = torch.tensor([[-pre_emphasis, 1.0]], dtype=torch.float32).unsqueeze(0)\n",
    "        self.register_buffer(\"filter\", filt)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, T)\n",
    "        x = x.unsqueeze(1)  # (B,1,T)\n",
    "        x = F.pad(x, (1, 0), mode=\"reflect\")\n",
    "        x = F.conv1d(x, self.filter)\n",
    "        return x.squeeze(1)  # (B,T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.367527Z",
     "iopub.status.busy": "2025-11-25T05:39:06.366858Z",
     "iopub.status.idle": "2025-11-25T05:39:06.383374Z",
     "shell.execute_reply": "2025-11-25T05:39:06.382605Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.367502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SincConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from AASIST. One input channel only.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def to_mel(hz): return 2595 * np.log10(1 + hz / 700)\n",
    "    @staticmethod\n",
    "    def to_hz(mel): return 700 * (10**(mel / 2595) - 1)\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1, stride=1, padding=0, dilation=1):\n",
    "        super().__init__()\n",
    "        if in_channels != 1:\n",
    "            raise ValueError(\"SincConv supports only one input channel.\")\n",
    "        self.out_channels = out_channels\n",
    "        self.sample_rate = sample_rate\n",
    "        self.kernel_size = kernel_size + (kernel_size % 2 == 0)\n",
    "\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        NFFT = 512\n",
    "        f = int(sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        fmel = self.to_mel(f)\n",
    "        filbandwidthsmel = np.linspace(fmel.min(), fmel.max(), out_channels + 1)\n",
    "        filbandwidthsf = self.to_hz(filbandwidthsmel)\n",
    "\n",
    "        self.hsupp = torch.arange(-(self.kernel_size - 1) / 2,\n",
    "                                  (self.kernel_size - 1) / 2 + 1)\n",
    "\n",
    "        band_pass = torch.zeros(out_channels, self.kernel_size)\n",
    "        for i in range(out_channels):\n",
    "            fmin, fmax = filbandwidthsf[i], filbandwidthsf[i + 1]\n",
    "            hHigh = (2 * fmax / sample_rate) * np.sinc(2 * fmax * self.hsupp / sample_rate)\n",
    "            hLow  = (2 * fmin / sample_rate) * np.sinc(2 * fmin * self.hsupp / sample_rate)\n",
    "            hideal = hHigh - hLow\n",
    "            band_pass[i, :] = torch.tensor(np.hamming(self.kernel_size)) * torch.tensor(hideal)\n",
    "        self.register_buffer(\"band_pass\", band_pass)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,1,T)\n",
    "        filt = self.band_pass.to(x.device).view(self.out_channels, 1, self.kernel_size)\n",
    "        return F.conv1d(x, filt, stride=self.stride, padding=self.padding, dilation=self.dilation, groups=1)\n",
    "\n",
    "class LearnableSincConv(nn.Module):\n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10**(mel / 2595) - 1)\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1,\n",
    "                 stride=1, padding=0, dilation=1, bias=False, min_low_hz=50, min_band_hz=50):\n",
    "        super().__init__()\n",
    "        if in_channels != 1:\n",
    "            raise ValueError(f\"SincConv only supports one input channel, got {in_channels}\")\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.min_low_hz = min_low_hz\n",
    "        self.min_band_hz = min_band_hz\n",
    "\n",
    "        # Mel-scale initialization\n",
    "        NFFT = 512\n",
    "        f = np.linspace(0, sample_rate / 2, int(NFFT / 2) + 1)\n",
    "        fmel = self.to_mel(f)\n",
    "        mel_points = np.linspace(fmel.min(), fmel.max(), out_channels + 1)\n",
    "        hz_points = self.to_hz(mel_points)\n",
    "\n",
    "        # Initialize learnable parameters for low cutoff and bandwidth\n",
    "        low_hz = hz_points[:-1]\n",
    "        band_hz = np.diff(hz_points)\n",
    "\n",
    "        self.low_hz_ = nn.Parameter(torch.tensor(low_hz, dtype=torch.float32))\n",
    "        self.band_hz_ = nn.Parameter(torch.tensor(band_hz, dtype=torch.float32))\n",
    "\n",
    "        # Time axis for filter generation\n",
    "        n = torch.arange(-(kernel_size - 1) / 2, (kernel_size - 1) / 2 + 1)\n",
    "        self.register_buffer('n', n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        n = self.n.to(device)\n",
    "\n",
    "        # Enforce positive frequency constraints\n",
    "        low = self.min_low_hz + torch.abs(self.low_hz_)\n",
    "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_), self.min_low_hz, self.sample_rate / 2 - 1)\n",
    "\n",
    "        band = (high - low)[:, None]\n",
    "        f_times_t_low = 2 * np.pi * low[:, None] * n / self.sample_rate\n",
    "        f_times_t_high = 2 * np.pi * high[:, None] * n / self.sample_rate\n",
    "\n",
    "        # Compute filters using sinc functions\n",
    "        sinc_high = torch.sin(f_times_t_high) / (n / self.sample_rate + 1e-8)\n",
    "        sinc_low = torch.sin(f_times_t_low) / (n / self.sample_rate + 1e-8)\n",
    "        filters = sinc_high - sinc_low\n",
    "\n",
    "        # Apply window (Hamming)\n",
    "        window = 0.54 - 0.46 * torch.cos(2 * np.pi * (torch.arange(self.kernel_size).to(device)) / self.kernel_size)\n",
    "        filters = filters * window\n",
    "\n",
    "        # Normalize\n",
    "        filters = filters / (2 * band)\n",
    "\n",
    "        filters = filters.view(self.out_channels, 1, self.kernel_size)\n",
    "        return F.conv1d(x, filters, stride=self.stride, padding=self.padding)\n",
    "\n",
    "class AdaptiveGaborConv(nn.Module):\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1):\n",
    "        super().__init__()\n",
    "        if in_channels != 1:\n",
    "            raise ValueError(\"GaborConv only supports 1 input channel\")\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1  # ensure odd kernel size\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        # Time support\n",
    "        self.t = torch.arange(-(kernel_size - 1) / 2, (kernel_size - 1) / 2 + 1, dtype=torch.float32) / sample_rate  # [kernel_size]\n",
    "\n",
    "        # Mel-scale initialization for center frequencies\n",
    "        NFFT = 512\n",
    "        f = np.linspace(0, sample_rate / 2, int(NFFT / 2) + 1)\n",
    "        mel = 2595 * np.log10(1 + f / 700)\n",
    "        mel_centers = np.linspace(mel.min(), mel.max(), out_channels)\n",
    "        hz_centers = 700 * (10 ** (mel_centers / 2595) - 1)\n",
    "        eta_init = hz_centers / sample_rate  # normalized center freqs [0‚Äì0.5]\n",
    "        self.eta = nn.Parameter(torch.tensor(eta_init, dtype=torch.float32))\n",
    "\n",
    "        # Adaptive bandwidths inversely proportional to frequency\n",
    "        base_sigma = (kernel_size / sample_rate) / 4  # base scale\n",
    "        sigma_init = base_sigma / (self.eta + 1e-4)   # inverse proportionality\n",
    "        sigma_init = torch.clamp(torch.tensor(sigma_init, dtype=torch.float32), 1e-4, 0.05)\n",
    "        self.sigma_scale = nn.Parameter(torch.ones(out_channels))  # learnable global scaling\n",
    "        self.register_buffer(\"sigma_init\", sigma_init)\n",
    "\n",
    "    def _create_filters(self, device):\n",
    "        t = self.t.to(device)                         # [kernel_size]\n",
    "        eta = torch.clamp(self.eta, 1e-4, 0.5)        # [out_channels]\n",
    "        sigma = (self.sigma_init.to(device) * self.sigma_scale).unsqueeze(1)  # [out_channels, 1]\n",
    "        eta = eta.unsqueeze(1)                        # [out_channels, 1]\n",
    "\n",
    "        # Gaussian window ‚Äî broadcast over time\n",
    "        gaussian = torch.exp(-t[None, :]**2 / (2 * sigma**2)) / (np.sqrt(2 * np.pi) * sigma)\n",
    "\n",
    "        # Cosine/sine modulations\n",
    "        cos_component = torch.cos(2 * np.pi * eta * t[None, :])\n",
    "        sin_component = torch.sin(2 * np.pi * eta * t[None, :])\n",
    "\n",
    "        filters_real = gaussian * cos_component\n",
    "        filters_imag = gaussian * sin_component\n",
    "\n",
    "        filters = torch.cat([filters_real, filters_imag], dim=0)  # [2*out_channels, kernel_size]\n",
    "        filters = filters / (filters.abs().max(dim=1, keepdim=True)[0] + 1e-8)\n",
    "        return filters\n",
    "\n",
    "    def forward(self, x):\n",
    "        filters = self._create_filters(x.device)\n",
    "        filters = filters.view(2 * self.out_channels, 1, self.kernel_size)\n",
    "        padding = self.kernel_size // 2\n",
    "        out = F.conv1d(x, filters, stride=1, padding=padding)\n",
    "        real, imag = out[:, :self.out_channels, :], out[:, self.out_channels:, :]\n",
    "        magnitude = torch.sqrt(real**2 + imag**2 + 1e-8)\n",
    "        return magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.384721Z",
     "iopub.status.busy": "2025-11-25T05:39:06.384504Z",
     "iopub.status.idle": "2025-11-25T05:39:06.401701Z",
     "shell.execute_reply": "2025-11-25T05:39:06.400961Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.384705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Nice-to-have (optional)\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    HAS_TORCHINFO = True\n",
    "except Exception:\n",
    "    HAS_TORCHINFO = False\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Expects Q,K,V: (B, H, S, D). Optional mask: (B,1,1,S) or broadcastable.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, Q, K, V, mask: Optional[torch.Tensor] = None):\n",
    "        assert Q.dim() == K.dim() == V.dim() == 4  # (B,H,S,D)\n",
    "        d_k = K.size(-1)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)  # (B,H,S_q,S_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "        attn = self.softmax(scores)\n",
    "        out = torch.matmul(attn, V)  # (B,H,S_q,D)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, n_head: int):\n",
    "        super().__init__()\n",
    "        assert d_model % n_head == 0, \"d_model must be divisible by n_head\"\n",
    "        self.n_head = n_head\n",
    "        self.d_head = d_model // n_head\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_model)\n",
    "        self.W_K = nn.Linear(d_model, d_model)\n",
    "        self.W_V = nn.Linear(d_model, d_model)\n",
    "        self.attn = ScaledDotProductAttention()\n",
    "        self.W_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def _split_heads(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,S,D) -> (B,H,S,Dh)\n",
    "        B, S, D = x.size()\n",
    "        x = x.view(B, S, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
    "        return x\n",
    "\n",
    "    def _merge_heads(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,H,S,Dh) -> (B,S,D)\n",
    "        B, H, S, Dh = x.size()\n",
    "        return x.permute(0, 2, 1, 3).contiguous().view(B, S, H * Dh)\n",
    "\n",
    "    def forward(self, Q, K, V, mask: Optional[torch.Tensor] = None):\n",
    "        assert Q.dim() == K.dim() == V.dim() == 3  # (B,S,D)\n",
    "        q = self._split_heads(self.W_Q(Q))\n",
    "        k = self._split_heads(self.W_K(K))\n",
    "        v = self._split_heads(self.W_V(V))\n",
    "        if mask is not None:\n",
    "            # make mask broadcastable to (B,H,S_q,S_k)\n",
    "            mask = mask.unsqueeze(1)\n",
    "        context = self.attn(q, k, v, mask=mask)\n",
    "        context = self._merge_heads(context)\n",
    "        return self.W_out(context)\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-12):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, unbiased=False, keepdim=True)\n",
    "        xhat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.gamma * xhat + self.beta\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, ffn_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Linear(ffn_hidden, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model=64, n_head=8, ffn_hidden=2048, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, n_head)\n",
    "        self.dropout1 = nn.Dropout(drop_prob)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.ffn = FFN(d_model, ffn_hidden, drop_prob)\n",
    "        self.dropout2 = nn.Dropout(drop_prob)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, attn_mask: Optional[torch.Tensor] = None):\n",
    "        # x: (B,S,D)\n",
    "        residual = x\n",
    "        x = self.attn(x, x, x, mask=attn_mask)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + residual)\n",
    "\n",
    "        residual = x\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + residual)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TD (Time-Domain) Filterbank and Learnable Gammatone Filterbank\n",
    "PyTorch implementations intended as drop-in replacements for the SincConv layer.\n",
    "\n",
    "Both modules accept (B,1,T) raw waveform and return (B, out_channels, T').\n",
    "They are made fully drop-in compatible with a SincConv-style constructor\n",
    "(i.e. accept `in_channels=1`, `out_channels=...`, `kernel_size=...`, `sample_rate=...`).\n",
    "\"\"\"\n",
    "\n",
    "from typing import Optional\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# -------------------- helpers --------------------\n",
    "\n",
    "def hz_to_mel(hz: np.ndarray) -> np.ndarray:\n",
    "    return 2595.0 * np.log10(1.0 + hz / 700.0)\n",
    "\n",
    "\n",
    "def mel_to_hz(mel: np.ndarray) -> np.ndarray:\n",
    "    return 700.0 * (10 ** (mel / 2595.0) - 1.0)\n",
    "\n",
    "\n",
    "def windowed_sinc_impulse(kernel_size: int, sr: int, fmin: float, fmax: float) -> np.ndarray:\n",
    "    \"\"\"Return a single band-pass windowed-sinc impulse response (numpy array).\n",
    "    kernel_size must be odd.\n",
    "    \"\"\"\n",
    "    assert kernel_size % 2 == 1, \"kernel_size should be odd\"\n",
    "    t = np.arange(-(kernel_size - 1) / 2.0, (kernel_size - 1) / 2.0 + 1.0)\n",
    "    h_high = (2 * fmax / sr) * np.sinc(2 * fmax * t / sr)\n",
    "    h_low = (2 * fmin / sr) * np.sinc(2 * fmin * t / sr)\n",
    "    hideal = h_high - h_low\n",
    "    w = np.hamming(kernel_size)\n",
    "    return hideal * w\n",
    "\n",
    "\n",
    "# -------------------- TDFilterbank --------------------\n",
    "\n",
    "class TDFilterbank(nn.Module):\n",
    "    \"\"\"Time-Domain Filterbank (drop-in replacement for SincConv).\n",
    "\n",
    "    Accepts `in_channels` argument for API compatibility but only supports mono input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 1,          # dummy for compatibility (ignored)\n",
    "                 out_channels: int = 70,\n",
    "                 kernel_size: int = 129,\n",
    "                 sample_rate: int = 16000,\n",
    "                 learnable: bool = True,\n",
    "                 learnable_f: bool = True,\n",
    "                 min_low_hz: float = 30.0,\n",
    "                 min_band_hz: float = 50.0,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.learnable = learnable\n",
    "        self.learnable_f = learnable_f\n",
    "\n",
    "        # mel-spaced boundaries (numpy)\n",
    "        NFFT = 512\n",
    "        f = int(sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        fmel = hz_to_mel(f)\n",
    "        mel_bins = np.linspace(fmel.min(), fmel.max(), out_channels + 1)\n",
    "        hz_bins = mel_to_hz(mel_bins)\n",
    "\n",
    "        fmins = hz_bins[:-1].copy()\n",
    "        fmaxs = hz_bins[1:].copy()\n",
    "\n",
    "        # ensure minimum band\n",
    "        fmins = np.maximum(fmins, min_low_hz)\n",
    "        fmaxs = np.maximum(fmaxs, fmins + min_band_hz)\n",
    "\n",
    "        # init kernels (numpy) shape (out_channels, kernel_size)\n",
    "        init_kernels = np.zeros((out_channels, kernel_size), dtype=np.float32)\n",
    "        for i in range(out_channels):\n",
    "            init_kernels[i, :] = windowed_sinc_impulse(kernel_size, sample_rate, fmins[i], fmaxs[i])\n",
    "\n",
    "        # normalize\n",
    "        init_kernels /= np.maximum(np.abs(init_kernels).sum(axis=1, keepdims=True), 1e-8)\n",
    "\n",
    "        # store initial kernels or params depending on mode\n",
    "        if not learnable:\n",
    "            # fixed kernel bank (register buffer for zero-parameter behavior)\n",
    "            self.register_buffer('kernels', torch.tensor(init_kernels, dtype=torch.float32).unsqueeze(1))\n",
    "            return\n",
    "\n",
    "        if learnable_f:\n",
    "            centres = (fmins + fmaxs) / 2.0\n",
    "            bws = (fmaxs - fmins)\n",
    "\n",
    "            self.log_centres = nn.Parameter(torch.log(torch.tensor(centres + 1.0, dtype=torch.float32)))\n",
    "            self.log_bws = nn.Parameter(torch.log(torch.tensor(bws + 1.0, dtype=torch.float32)))\n",
    "            self.register_buffer('kernel_window_ref', torch.tensor(init_kernels, dtype=torch.float32))\n",
    "        else:\n",
    "            # learn full kernels (Conv1d-like)\n",
    "            self.kernels_param = nn.Parameter(torch.tensor(init_kernels, dtype=torch.float32).unsqueeze(1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B,1,T)\n",
    "        returns: (B, out_channels, T')\n",
    "        \"\"\"\n",
    "        if not self.learnable:\n",
    "            return F.conv1d(x, self.kernels.to(x.device), stride=1, padding=(self.kernel_size - 1) // 2)\n",
    "\n",
    "        if self.learnable_f:\n",
    "            device = x.device\n",
    "            centres = torch.exp(self.log_centres).to(device) - 1.0\n",
    "            bws = torch.exp(self.log_bws).to(device) - 1.0\n",
    "\n",
    "            fmin = centres - 0.5 * bws\n",
    "            fmax = centres + 0.5 * bws\n",
    "\n",
    "            # clamp ranges safely using tensor ops (avoid mixing tensor/scalar in positional args)\n",
    "            max_freq_tensor = (self.sample_rate / 2.0) * torch.ones_like(fmax, device=device)\n",
    "            fmin = torch.clamp(fmin, min=1.0)\n",
    "            fmin = torch.min(fmin, max_freq_tensor - 2.0)\n",
    "            fmax = torch.max(fmax, fmin + 1.0)\n",
    "            fmax = torch.min(fmax, max_freq_tensor)\n",
    "\n",
    "            # time vector (device)\n",
    "            t = torch.linspace(\n",
    "                -(self.kernel_size - 1) / 2.0,\n",
    "                (self.kernel_size - 1) / 2.0,\n",
    "                steps=self.kernel_size,\n",
    "                device=device,\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "\n",
    "            kernels = []\n",
    "            # build each kernel on-device\n",
    "            for i in range(self.out_channels):\n",
    "                hi = (2.0 * fmax[i] / self.sample_rate) * torch.sinc(2.0 * fmax[i] * t / self.sample_rate)\n",
    "                lo = (2.0 * fmin[i] / self.sample_rate) * torch.sinc(2.0 * fmin[i] * t / self.sample_rate)\n",
    "\n",
    "                h = hi - lo\n",
    "                h = h * torch.hamming_window(self.kernel_size, periodic=False, device=device, dtype=torch.float32)\n",
    "                h = h / (h.abs().sum() + 1e-8)\n",
    "                kernels.append(h)\n",
    "\n",
    "            kernels = torch.stack(kernels, dim=0).unsqueeze(1)  # (out,1,k)\n",
    "            return F.conv1d(x, kernels, stride=1, padding=(self.kernel_size - 1) // 2)\n",
    "\n",
    "        # learn full kernels branch\n",
    "        return F.conv1d(x, self.kernels_param.to(x.device), stride=1, padding=(self.kernel_size - 1) // 2)\n",
    "\n",
    "\n",
    "# -------------------- Learnable Gammatone Filterbank --------------------\n",
    "\n",
    "class LearnableGammatone(nn.Module):\n",
    "    \"\"\"Learnable Gammatone Filterbank (drop-in compatible).\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 1,         # dummy for compatibility (ignored)\n",
    "                 out_channels: int = 70,\n",
    "                 kernel_size: int = 129,\n",
    "                 sample_rate: int = 16000,\n",
    "                 n: int = 4,\n",
    "                 min_freq: float = 30.0,\n",
    "                 max_freq: Optional[float] = None,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n = n\n",
    "        self.max_freq = max_freq or sample_rate / 2.0\n",
    "\n",
    "        # mel spaced centres (numpy)\n",
    "        NFFT = 512\n",
    "        f = int(sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        mel = hz_to_mel(f)\n",
    "        mel_bins = np.linspace(mel.min(), mel.max(), out_channels)\n",
    "        centres = mel_to_hz(mel_bins)\n",
    "        centres = np.clip(centres, min_freq, self.max_freq - 10.0)\n",
    "\n",
    "        # ERB approx\n",
    "        erb = 24.7 + 0.108 * centres\n",
    "\n",
    "        self.log_centres = nn.Parameter(torch.log(torch.tensor(centres + 1.0, dtype=torch.float32)))\n",
    "        self.log_band = nn.Parameter(torch.log(torch.tensor(erb + 1.0, dtype=torch.float32)))\n",
    "\n",
    "        self.log_amp = nn.Parameter(torch.zeros(out_channels, dtype=torch.float32))\n",
    "\n",
    "        t = np.arange(kernel_size, dtype=np.float32) - (kernel_size - 1) / 2.0\n",
    "        self.register_buffer(\"t\", torch.tensor(t, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B,1,T)\n",
    "        returns: (B, out_channels, T')\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "\n",
    "        centres = torch.exp(self.log_centres).to(device) - 1.0\n",
    "        band = torch.exp(self.log_band).to(device) - 1.0\n",
    "        amp = torch.exp(self.log_amp).to(device)\n",
    "\n",
    "        centres = torch.clamp(centres, 20.0, self.max_freq - 1.0)\n",
    "        band = torch.clamp(band, 1.0, self.sample_rate / 4.0)\n",
    "\n",
    "        t = self.t.to(device)\n",
    "        kernels = []\n",
    "\n",
    "        for i in range(self.out_channels):\n",
    "            fc = centres[i]\n",
    "            b = band[i]\n",
    "            a = amp[i]\n",
    "\n",
    "            tp = t  # centered time vector\n",
    "\n",
    "            env = (tp.abs() / self.sample_rate) ** (self.n - 1)\n",
    "            env = env * torch.exp(-2.0 * math.pi * b * tp.abs() / self.sample_rate)\n",
    "            carrier = torch.cos(2.0 * math.pi * fc * tp / self.sample_rate)\n",
    "\n",
    "            g = a * env * carrier\n",
    "            g = g / (g.abs().sum() + 1e-8)\n",
    "\n",
    "            kernels.append(g)\n",
    "\n",
    "        kernels = torch.stack(kernels, dim=0).unsqueeze(1)\n",
    "        return F.conv1d(x, kernels.to(device), stride=1, padding=(self.kernel_size - 1) // 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.402828Z",
     "iopub.status.busy": "2025-11-25T05:39:06.402574Z",
     "iopub.status.idle": "2025-11-25T05:39:06.421502Z",
     "shell.execute_reply": "2025-11-25T05:39:06.420822Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.402805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Frontend_S\n",
    "# ----------------------------------------------------------------------\n",
    "class Frontend_S(nn.Module):\n",
    "    def __init__(self, device, sinc_kernel_size=128, sample_rate=16000):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---- Sinc layer (no parameters ‚Üí safe on any device) ----\n",
    "        self.sinc_layer = TDFilterbank(\n",
    "            in_channels=1,\n",
    "            out_channels=70,\n",
    "            kernel_size=sinc_kernel_size,\n",
    "            sample_rate=sample_rate,\n",
    "        )\n",
    "\n",
    "        # ---- BatchNorm that must live on the target device ----\n",
    "        self.bn = nn.BatchNorm2d(num_features=1).to(device)\n",
    "\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "\n",
    "        # ---- Conv blocks (they also contain BatchNorms) ----\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            Conv2DBlock_S(in_channels=1,  out_channels=32, is_first_block=True),\n",
    "            Conv2DBlock_S(in_channels=32, out_channels=32),\n",
    "            Conv2DBlock_S(in_channels=32, out_channels=64),\n",
    "            Conv2DBlock_S(in_channels=64, out_channels=64),\n",
    "        ).to(device)                     # <-- move the whole Sequential\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : [B, T]  (raw waveform)\n",
    "        x = x.unsqueeze(1)                     # [B,1,T]\n",
    "        x = self.sinc_layer(x)                 # [B,70,T']\n",
    "        x = x.unsqueeze(1)                     # [B,1,70,T']\n",
    "        x = F.max_pool2d(torch.abs(x), (3, 3)) # [B,1,F,T]\n",
    "        x = self.bn(x)\n",
    "        LFM = self.selu(x)\n",
    "\n",
    "        HFM = self.conv_blocks(LFM)            # [B,64,f,t]\n",
    "        return HFM\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Conv2DBlock_S\n",
    "# ----------------------------------------------------------------------\n",
    "class Conv2DBlock_S(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, is_first_block: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---- optional normaliser (BN+SELU) ----\n",
    "        self.normalizer = None\n",
    "        if not is_first_block:\n",
    "            self.normalizer = nn.Sequential(\n",
    "                nn.BatchNorm2d(in_channels),\n",
    "                nn.SELU(inplace=True),\n",
    "            )\n",
    "\n",
    "        # ---- two conv layers + BN+SELU ----\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(2, 5), padding=(1, 2)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(2, 3), padding=(0, 1)),\n",
    "        )\n",
    "\n",
    "        # ---- residual connection when channel count changes ----\n",
    "        self.downsampler = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsampler = nn.Conv2d(in_channels, out_channels,\n",
    "                                        kernel_size=(1, 3), padding=(0, 1))\n",
    "\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(1, 6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsampler is not None:\n",
    "            identity = self.downsampler(identity)\n",
    "\n",
    "        if self.normalizer is not None:\n",
    "            x = self.normalizer(x)\n",
    "\n",
    "        x = self.layers(x) + identity\n",
    "        x = self.pooling(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. PositionalAggregator1D\n",
    "# ----------------------------------------------------------------------\n",
    "class PositionalAggregator1D(nn.Module):\n",
    "    def __init__(self, max_C: int, max_ft: int, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.flattener = nn.Flatten(start_dim=-2, end_dim=-1)\n",
    "\n",
    "        # ----- sinusoidal positional encoding (no trainable params) -----\n",
    "        pos = torch.arange(1, max_ft - 1, device=device).float().unsqueeze(1)   # (L-2,1)\n",
    "        dim = torch.arange(0, max_C, step=2, device=device).float().unsqueeze(0)  # (1,D/2)\n",
    "\n",
    "        enc = torch.zeros(max_ft, max_C, device=device)\n",
    "        enc[1:-1, 0::2] = torch.sin(pos / (10000 ** (dim / max_C)))\n",
    "        enc[1:-1, 1::2] = torch.cos(pos / (10000 ** (dim / max_C)))\n",
    "        self.register_buffer('encoding', enc)   # stored on the correct device automatically\n",
    "\n",
    "    def forward(self, HFM):\n",
    "        \"\"\"\n",
    "        HFM : [B, C, f, t]\n",
    "        out : [B, f*t, C]  with added positional encoding\n",
    "        \"\"\"\n",
    "        B, C, f, t = HFM.shape\n",
    "        ft = f * t\n",
    "        out = self.flattener(HFM).transpose(1, 2)               # [B, f*t, C]\n",
    "        out = out + self.encoding[:ft, :C]                      # broadcast\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.423289Z",
     "iopub.status.busy": "2025-11-25T05:39:06.423059Z",
     "iopub.status.idle": "2025-11-25T05:39:06.437563Z",
     "shell.execute_reply": "2025-11-25T05:39:06.436811Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.423270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Rawformer_S(nn.Module):\n",
    "    def __init__(self, device, transformer_hidden=64, sample_rate: int = 16000):\n",
    "        super().__init__()\n",
    "        # ---- 1. give the front-end the device ----\n",
    "        self.front_end = Frontend_S(sinc_kernel_size=128,\n",
    "                                    sample_rate=sample_rate,\n",
    "                                    device=device)          # <-- add this\n",
    "\n",
    "        self.positional_embedding = PositionalAggregator1D(\n",
    "            max_C=64, max_ft=23*16, device=device)\n",
    "\n",
    "        self.classifier = RawformerClassifier(C=64, n_encoder=2, transformer_hidden=transformer_hidden)\n",
    "\n",
    "        # ---- 2. move *everything* to the target device in one go ----\n",
    "        self.to(device)                     # <-- important!\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.front_end(x)               # now on correct device\n",
    "        x = self.positional_embedding(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.438790Z",
     "iopub.status.busy": "2025-11-25T05:39:06.438533Z",
     "iopub.status.idle": "2025-11-25T05:39:06.453087Z",
     "shell.execute_reply": "2025-11-25T05:39:06.452417Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.438769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SequencePooling(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention-style weighted pooling over sequence.\n",
    "    Input: (B,S,C) -> Output: (B,C)\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,S,C)\n",
    "        w = self.linear(x)               # (B,S,1)\n",
    "        w = F.softmax(w.transpose(1, 2), dim=-1)  # (B,1,S)\n",
    "        out = torch.matmul(w, x)         # (B,1,C)\n",
    "        return out.squeeze(1)            # (B,C)\n",
    "\n",
    "\n",
    "class RawformerClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoders (N layers) + SeqPool + Linear + Sigmoid\n",
    "    Input: sequence (B,S,C)  Output: (B,) score in [0,1]\n",
    "    \"\"\"\n",
    "    def __init__(self, C: int, n_encoder: int, transformer_hidden: int):\n",
    "        super().__init__()\n",
    "        self.encoders = nn.Sequential(OrderedDict([\n",
    "            (f\"encoder{i}\", TransformerEncoderLayer(d_model=C, n_head=8, ffn_hidden=transformer_hidden))\n",
    "            for i in range(n_encoder)\n",
    "        ]))\n",
    "        self.seq_pool = SequencePooling(d_model=C)\n",
    "        self.fc = nn.Linear(C, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,S,C)\n",
    "        x = self.encoders(x)\n",
    "        x = self.seq_pool(x)\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x).squeeze(-1)   # (B,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.453948Z",
     "iopub.status.busy": "2025-11-25T05:39:06.453693Z",
     "iopub.status.idle": "2025-11-25T05:39:06.469810Z",
     "shell.execute_reply": "2025-11-25T05:39:06.469201Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.453931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_pad(batch):\n",
    "    # Here all items are same length already; just stack.\n",
    "    wavs, labels = zip(*batch)\n",
    "    wavs = torch.stack(wavs, dim=0)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return wavs, labels\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, preemph=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for wav, label in loader:\n",
    "        wav = wav.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        if preemph is not None:\n",
    "            wav = preemph(wav)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(wav)              # (B,)\n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * wav.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, preemph=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    for wav, label in loader:\n",
    "        wav = wav.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        if preemph is not None:\n",
    "            wav = preemph(wav)\n",
    "        pred = model(wav)\n",
    "        loss = criterion(pred, label)\n",
    "        total_loss += loss.item() * wav.size(0)\n",
    "        total_correct += ((pred > 0.5).float() == label).sum().item()\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = total_correct / len(loader.dataset)\n",
    "    return avg_loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.470899Z",
     "iopub.status.busy": "2025-11-25T05:39:06.470649Z",
     "iopub.status.idle": "2025-11-25T05:39:06.544045Z",
     "shell.execute_reply": "2025-11-25T05:39:06.543269Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.470875Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([2]) | values ~ (0.4646236002445221, 0.467530757188797)\n"
     ]
    }
   ],
   "source": [
    "# Build model and run a forward pass with dummy audio\n",
    "exp_cfg = ExpConfig()\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Rawformer_S(device=DEVICE, transformer_hidden=exp_cfg.transformer_hidden,\n",
    "                          sample_rate=exp_cfg.sample_rate)\n",
    "\n",
    "B = 2\n",
    "dummy_audio = torch.randn(B, exp_cfg.sample_rate * exp_cfg.train_duration_sec).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    out = model(dummy_audio)\n",
    "print(\"Model output shape:\", out.shape, \"| values ~\", (out.min().item(), out.max().item()))\n",
    "\n",
    "if HAS_TORCHINFO:\n",
    "    try:\n",
    "        summary(model, input_size=(B, exp_cfg.sample_rate * exp_cfg.train_duration_sec))\n",
    "    except Exception as e:\n",
    "        print(\"torchinfo summary error (safe to ignore):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.545010Z",
     "iopub.status.busy": "2025-11-25T05:39:06.544797Z",
     "iopub.status.idle": "2025-11-25T05:39:06.548428Z",
     "shell.execute_reply": "2025-11-25T05:39:06.547784Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.544976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torchaudio.set_audio_backend(\"ffmpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.549387Z",
     "iopub.status.busy": "2025-11-25T05:39:06.549113Z",
     "iopub.status.idle": "2025-11-25T05:39:06.559782Z",
     "shell.execute_reply": "2025-11-25T05:39:06.559257Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.549370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.562453Z",
     "iopub.status.busy": "2025-11-25T05:39:06.562096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loaded 25380 files from G:\\INTERSPEECH_26\\LA\\ASV19\\train\n",
      "üìÅ Loaded 24844 files from G:\\INTERSPEECH_26\\LA\\ASV19\\dev\n",
      "üìÅ Loaded 24844 files from G:\\INTERSPEECH_26\\LA\\ASV19\\dev\n",
      "üöÄ Starting training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29aa595f6824edcad5ebb5b24ba54a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564b971e29524a7c9b6e374ff7a7c95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 1 Summary:\n",
      "   Train Loss: 0.2370\n",
      "   Val Loss:   0.2458\n",
      "   Val EER:    6.91%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=6.91%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a51c224e5641fcb03f2222463a6259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06041a218a7407bab29d6883323cb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 2 Summary:\n",
      "   Train Loss: 0.0870\n",
      "   Val Loss:   0.0988\n",
      "   Val EER:    3.81%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=3.81%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7f7129ebcf467d94b0d7e34c7c9a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065752b6ebc249bd8dd9ab2b5efe74e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 3 Summary:\n",
      "   Train Loss: 0.0481\n",
      "   Val Loss:   0.0389\n",
      "   Val EER:    2.31%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=2.31%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34dc38a01494d4e8810187fdb0409f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe67f1ca02b4144a8bbe8280891c963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 4 Summary:\n",
      "   Train Loss: 0.0435\n",
      "   Val Loss:   0.0994\n",
      "   Val EER:    2.35%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae9fc3da68b4f83bed246543c62057d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25105e4253d474eaddf26a6f5539bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 5 Summary:\n",
      "   Train Loss: 0.0423\n",
      "   Val Loss:   0.0260\n",
      "   Val EER:    1.71%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=1.71%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c21a6cf7994795889c65163a8534da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668e68908b90477283dbef50e2e6fac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 6 Summary:\n",
      "   Train Loss: 0.0350\n",
      "   Val Loss:   0.0415\n",
      "   Val EER:    2.00%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e030262cfe409fb476f609480f4e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeecb6e2b42842e48eb265d02a56329d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 7 Summary:\n",
      "   Train Loss: 0.0319\n",
      "   Val Loss:   0.0244\n",
      "   Val EER:    1.69%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=1.69%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc412f5d7d64f4ea74298530898f641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8631520853140dd92540996886bd503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 8 Summary:\n",
      "   Train Loss: 0.0261\n",
      "   Val Loss:   0.0329\n",
      "   Val EER:    1.88%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9375048c824ec19413d723c3937a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7238b5f7c4ed4f65b26bf9d4953630bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 9 Summary:\n",
      "   Train Loss: 0.0228\n",
      "   Val Loss:   0.0609\n",
      "   Val EER:    2.05%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05a5df014e54c42bb3987facc17148e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4fddd5bc1845d098991616c290ce20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 10 Summary:\n",
      "   Train Loss: 0.0237\n",
      "   Val Loss:   0.0312\n",
      "   Val EER:    1.51%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=1.51%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cb3cd35c08413a8ba708e833e77169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5790ae657f7420b9e2a9fb66787a902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 11 Summary:\n",
      "   Train Loss: 0.0223\n",
      "   Val Loss:   0.0233\n",
      "   Val EER:    1.70%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd61c7d192c4f1996f0a1b8b83fb1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e6473efb44492a9aeccb81ad3fee42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 12 Summary:\n",
      "   Train Loss: 0.0256\n",
      "   Val Loss:   0.0437\n",
      "   Val EER:    2.23%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d994bac856943c6a6eefdd14aef4499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4315ceeaf2491da4946939c6461386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 13 Summary:\n",
      "   Train Loss: 0.0262\n",
      "   Val Loss:   0.0297\n",
      "   Val EER:    1.73%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd6fd3486a94fce8dbe34e718bbf160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ef5b321b6f41bc8c55e5233ae51ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 14 Summary:\n",
      "   Train Loss: 0.0308\n",
      "   Val Loss:   0.0530\n",
      "   Val EER:    1.52%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2368aecb95412ebf3ff9c48104c3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dc2226a14b4846ad49de37c7d5b170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 15 Summary:\n",
      "   Train Loss: 0.0193\n",
      "   Val Loss:   0.0182\n",
      "   Val EER:    1.10%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=1.10%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1882f071ed5b4bd2a5f244dfd13b2320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb86275da0fc49eb89c424bb4ee813ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 16 Summary:\n",
      "   Train Loss: 0.0187\n",
      "   Val Loss:   0.0198\n",
      "   Val EER:    1.26%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02619d1550ef40e8a6c2ea8cb8a18288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b67d4d2d00844978cf16e4588d1261d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 17 Summary:\n",
      "   Train Loss: 0.0205\n",
      "   Val Loss:   0.0180\n",
      "   Val EER:    1.37%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb356b264744eff9677086dbf3bf9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77a32f4bc8a4a5ea2c6e0c4b84ba726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 18 Summary:\n",
      "   Train Loss: 0.0228\n",
      "   Val Loss:   0.0237\n",
      "   Val EER:    1.69%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b54522769574a06a74c21e4edc5e843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c84c7af8c3b42e6a26953d937d0f617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 19 Summary:\n",
      "   Train Loss: 0.0173\n",
      "   Val Loss:   0.0167\n",
      "   Val EER:    1.22%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0c3440ef424b34b65f27c6ca72216f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90743abab9f4b4993cf99eef82f9188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 20 Summary:\n",
      "   Train Loss: 0.0155\n",
      "   Val Loss:   0.0261\n",
      "   Val EER:    1.73%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5c43bb10714c65861d8a87b84b8f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a318ebaee5b54fea9d00f058d39f7426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 21 Summary:\n",
      "   Train Loss: 0.0148\n",
      "   Val Loss:   0.0183\n",
      "   Val EER:    1.18%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7510445773aa4de2a99b09d5e8f08917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b2247147974fd19f93f8d031c72fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 22 Summary:\n",
      "   Train Loss: 0.0180\n",
      "   Val Loss:   0.0455\n",
      "   Val EER:    3.17%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e554f6cd11df438bbec0b67753840344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0475d6b69dc4729adae302784dbf6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 23 Summary:\n",
      "   Train Loss: 0.0151\n",
      "   Val Loss:   0.0194\n",
      "   Val EER:    1.24%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2358acd7b64bc6b258c5f5a698b0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49381633ecf84b96a6ac50e3d8835a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 24 Summary:\n",
      "   Train Loss: 0.0160\n",
      "   Val Loss:   0.0267\n",
      "   Val EER:    1.57%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ece64d04694b29a9e286761d37366d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe2f0281495452ab2a295f0c42d4309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 25 Summary:\n",
      "   Train Loss: 0.0232\n",
      "   Val Loss:   0.0180\n",
      "   Val EER:    1.26%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581a9c15769b4dd59d9fc77157b43bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c2e170dd314f33b541c2831fe0f757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 26 Summary:\n",
      "   Train Loss: 0.0179\n",
      "   Val Loss:   0.0160\n",
      "   Val EER:    1.22%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8251eac4b7e8480b80280cf4fa7776a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1971ce6213f14ed099929b4d3419fb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 27 Summary:\n",
      "   Train Loss: 0.0144\n",
      "   Val Loss:   0.0297\n",
      "   Val EER:    1.14%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87acfd6941bb4f2a9717a7e7cda977f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94de09441a834f21b2653c4695ffde5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 28 Summary:\n",
      "   Train Loss: 0.0146\n",
      "   Val Loss:   0.0195\n",
      "   Val EER:    1.37%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e158816d4bf448809ed917d22e10e3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7127e87552e940e4b1422c3ac554b5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 29 Summary:\n",
      "   Train Loss: 0.0189\n",
      "   Val Loss:   0.0214\n",
      "   Val EER:    1.13%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011add1d386e40a3b97f12729f541e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb50e1bd22845cf94fb2a2640d99012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 30 Summary:\n",
      "   Train Loss: 0.0221\n",
      "   Val Loss:   0.0463\n",
      "   Val EER:    2.51%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56a6eff423b4f6ea00b9ee27bc0264c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa815db402a14610877c9e913eeb20c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 31 Summary:\n",
      "   Train Loss: 0.0265\n",
      "   Val Loss:   0.0174\n",
      "   Val EER:    1.01%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=1.01%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4a13f80ad240a39c1771a7ad08bc7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f13365270d14ab7a8acb42275996fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 32 Summary:\n",
      "   Train Loss: 0.0161\n",
      "   Val Loss:   0.0792\n",
      "   Val EER:    1.79%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b92b5cdd754bbb963f24825958e1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c5b7245f62401da645ef54cabf1463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 33 Summary:\n",
      "   Train Loss: 0.0096\n",
      "   Val Loss:   0.0330\n",
      "   Val EER:    1.10%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6959415a3a4207b1cd698f64d2b5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6556928641c04382853023787505f6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 34 Summary:\n",
      "   Train Loss: 0.0094\n",
      "   Val Loss:   0.0077\n",
      "   Val EER:    0.59%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=0.59%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e26ea5fe67474dbddb69a3da9d8e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9efb6a69df94e239390d5f746ab6367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 35 Summary:\n",
      "   Train Loss: 0.0052\n",
      "   Val Loss:   0.0026\n",
      "   Val EER:    0.24%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=0.24%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1b9da6cc1a4fdbadb5f84f0718433e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d687b285c783412597611affde9b02f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 36 Summary:\n",
      "   Train Loss: 0.0176\n",
      "   Val Loss:   0.0088\n",
      "   Val EER:    0.57%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef396b2587640899ee2f8860db40110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2df8597eba4665bf239674d6183ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 37 Summary:\n",
      "   Train Loss: 0.0074\n",
      "   Val Loss:   0.0098\n",
      "   Val EER:    0.53%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62b33df756a48679822b9b67a2e1019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a053cfb09347eab211ce38a79f9902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 38 Summary:\n",
      "   Train Loss: 0.0055\n",
      "   Val Loss:   0.0019\n",
      "   Val EER:    0.16%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=0.16%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1126aa2b9379438bb040f8d6751a570d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bff5bc30be24e27a18ca2086475a9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 39 Summary:\n",
      "   Train Loss: 0.0084\n",
      "   Val Loss:   0.0062\n",
      "   Val EER:    0.31%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21818ae349d243a38cc17617b6ffea4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669ced71c5fe40799ac703d8047b0a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 40 Summary:\n",
      "   Train Loss: 0.0053\n",
      "   Val Loss:   0.0100\n",
      "   Val EER:    0.43%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09511322dd0b4431a2411dfb2088d89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de46c7cc0b37471cad815841929caa0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 41 Summary:\n",
      "   Train Loss: 0.0046\n",
      "   Val Loss:   0.0045\n",
      "   Val EER:    0.24%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6d77d7277f47649ca398ab2f4b1c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca48931d05f44c5a4b284eb7369bef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 42 Summary:\n",
      "   Train Loss: 0.0083\n",
      "   Val Loss:   0.0094\n",
      "   Val EER:    0.31%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56081d7dced4cfd945fd2d8fe73dc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23fefe821ba4b5f9e7fce89b70d4d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 43 Summary:\n",
      "   Train Loss: 0.0073\n",
      "   Val Loss:   0.0053\n",
      "   Val EER:    0.20%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d7162ec8254c71a6770230b0ab3edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9ecbeeafb841f2ad58cdde9182afa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 44 Summary:\n",
      "   Train Loss: 0.0033\n",
      "   Val Loss:   0.0323\n",
      "   Val EER:    0.55%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b858fa8e986c437db99a188898f0f2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38653d623ddd45e2a0113aa6684d1db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 45 Summary:\n",
      "   Train Loss: 0.0039\n",
      "   Val Loss:   0.0016\n",
      "   Val EER:    0.12%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=0.12%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffa58ca64a749b6baabe7dbf0022f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266802264b634fc48edc8ce79df287e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 46 Summary:\n",
      "   Train Loss: 0.0049\n",
      "   Val Loss:   0.0021\n",
      "   Val EER:    0.16%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae416caf41e433d9705dd5d5fefdb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b552f2f4c3ef4339b70ec02c2ecbd24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 47 Summary:\n",
      "   Train Loss: 0.0031\n",
      "   Val Loss:   0.0017\n",
      "   Val EER:    0.12%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=0.12%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe04696514f45988b69a7c2e3653bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec5151781734b4cae14dd87a3fef768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 48 Summary:\n",
      "   Train Loss: 0.0076\n",
      "   Val Loss:   0.0066\n",
      "   Val EER:    0.30%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c866d1f855874625901bafaf20939278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942d26c965e84c4a8f3cc99040a7b8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 49 Summary:\n",
      "   Train Loss: 0.0015\n",
      "   Val Loss:   0.0016\n",
      "   Val EER:    0.11%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=0.11%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\TDFilterbank_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b79035d92248bbbf3a24978172a6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21716daf0f142dba035132646afef1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 50 Summary:\n",
      "   Train Loss: 0.0284\n",
      "   Val Loss:   0.0209\n",
      "   Val EER:    0.55%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "üèÅ Starting final testing...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16948\\2467297305.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model = torch.load(save_path, map_location=DEVICE)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6012d85a07bb4643a2f36e1fd995e5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Final Test EER:  0.12%\n",
      "üìä Final min-tDCF: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SIMPLE DATASET\n",
    "# ============================================================\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "class ASVspoofFolderDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, sample_rate=16000, duration_sec=4):\n",
    "        self.root_dir = root_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration_sec = duration_sec\n",
    "        self.audio_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label_name, label_value in [(\"bonafide\", 1), (\"spoof\", 0)]:\n",
    "            class_dir = os.path.join(root_dir, label_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for file in os.listdir(class_dir):\n",
    "                    if file.endswith(\".flac\") or file.endswith(\".wav\"):\n",
    "                        self.audio_paths.append(os.path.join(class_dir, file))\n",
    "                        self.labels.append(label_value)\n",
    "\n",
    "        print(f\"üìÅ Loaded {len(self.audio_paths)} files from {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.audio_paths[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "        # --- Use soundfile for FLAC ---\n",
    "        if path.lower().endswith(\".flac\"):\n",
    "            wav_np, sr = sf.read(path)         # numpy array (T,) or (T, C)\n",
    "            if wav_np.ndim > 1:                # convert stereo ‚Üí mono\n",
    "                wav_np = wav_np.mean(axis=1)\n",
    "            wav = torch.tensor(wav_np, dtype=torch.float32).unsqueeze(0)  # [1, T]\n",
    "\n",
    "        # --- Use torchaudio for WAV ---\n",
    "        else:\n",
    "            wav, sr = torchaudio.load(path)\n",
    "\n",
    "        # --- Resample if needed ---\n",
    "        if sr != self.sample_rate:\n",
    "            wav = torchaudio.functional.resample(wav, sr, self.sample_rate)\n",
    "\n",
    "        # --- Crop/pad ---\n",
    "        num_samples = int(self.sample_rate * self.duration_sec)\n",
    "\n",
    "        if wav.size(1) > num_samples:\n",
    "            start = random.randint(0, wav.size(1) - num_samples)\n",
    "            wav = wav[:, start:start + num_samples]\n",
    "        elif wav.size(1) < num_samples:\n",
    "            wav = F.pad(wav, (0, num_samples - wav.size(1)))\n",
    "\n",
    "        return wav.squeeze(0), label\n",
    "\n",
    "# ============================================================\n",
    "# EER FUNCTION (FOR CM SYSTEM)\n",
    "# ============================================================\n",
    "\n",
    "def calculate_EER(labels, scores):\n",
    "    \"\"\"Equal Error Rate for Countermeasure system (bonafide=1, spoof=0).\"\"\"\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, scores, pos_label=1)\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    return eer\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# t-DCF FUNCTION (CM-only version using reference ASV parameters)\n",
    "# ============================================================\n",
    "\n",
    "def compute_tDCF(bonafide_score_cm, spoof_score_cm, Pfa_asv, Pmiss_asv, Pfa_spoof_asv, cost_model):\n",
    "    # 1. Compute CM miss/false-alarm rates for thresholds\n",
    "    cm_scores = np.concatenate([bonafide_score_cm, spoof_score_cm])\n",
    "    labels = np.concatenate([np.ones_like(bonafide_score_cm), np.zeros_like(spoof_score_cm)])\n",
    "    sorted_idx = np.argsort(cm_scores)[::-1]\n",
    "    sorted_labels = labels[sorted_idx]\n",
    "\n",
    "    tar = np.sum(sorted_labels)\n",
    "    non = len(sorted_labels) - tar\n",
    "\n",
    "    cm_miss = np.cumsum(sorted_labels == 1) / tar\n",
    "    cm_fa = np.cumsum(sorted_labels == 0) / non\n",
    "\n",
    "    # 2. Compute t-DCF per threshold\n",
    "    Cmiss, Cfa, Cfa_spoof = cost_model['Cmiss'], cost_model['Cfa'], cost_model['Cfa_spoof']\n",
    "    Ptar, Pnon, Pspoof = cost_model['Ptar'], cost_model['Pnon'], cost_model['Pspoof']\n",
    "\n",
    "    tDCF = (Cmiss * Ptar * Pmiss_asv * (1 - cm_miss) +\n",
    "            Cfa * Pnon * Pfa_asv * cm_fa +\n",
    "            Cfa_spoof * Pspoof * Pfa_spoof_asv * (1 - cm_miss)) / (\n",
    "            Cmiss * Ptar * Pmiss_asv + Cfa * Pnon * Pfa_asv)\n",
    "\n",
    "    tDCF_norm = tDCF / np.min(tDCF)\n",
    "    thresholds = cm_scores[sorted_idx]\n",
    "\n",
    "    return tDCF_norm, thresholds\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN + VALIDATE + TEST LOOP\n",
    "# ============================================================\n",
    "\n",
    "sys_cfg = SysConfig()\n",
    "exp_cfg = ExpConfig()\n",
    "\n",
    "train_ds = ASVspoofFolderDataset(sys_cfg.path_train, exp_cfg.sample_rate, exp_cfg.train_duration_sec)\n",
    "val_ds   = ASVspoofFolderDataset(sys_cfg.path_dev, exp_cfg.sample_rate, exp_cfg.test_duration_sec)\n",
    "test_ds  = ASVspoofFolderDataset(sys_cfg.path_test, exp_cfg.sample_rate, exp_cfg.test_duration_sec)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=exp_cfg.batch_size, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds, batch_size=exp_cfg.batch_size, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds, batch_size=exp_cfg.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# --- your modules ---\n",
    "pre = PreEmphasis(exp_cfg.pre_emphasis).to(DEVICE)\n",
    "model = Rawformer_S(device=DEVICE, transformer_hidden=exp_cfg.transformer_hidden, sample_rate=exp_cfg.sample_rate).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=exp_cfg.lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "best_val_eer = 1.0  # initialize high value\n",
    "\n",
    "print(\"üöÄ Starting training...\\n\")\n",
    "\n",
    "# Reference ASV parameters (official ASVspoof setup)\n",
    "Pfa_asv = 0.0005\n",
    "Pmiss_asv = 0.05\n",
    "Pmiss_spoof_asv = 0.95\n",
    "Pfa_spoof_asv = 1.0 - Pmiss_spoof_asv\n",
    "cost_model = {\n",
    "    'Ptar': 0.9801,\n",
    "    'Pnon': 0.0099,\n",
    "    'Pspoof': 0.0100,\n",
    "    'Cmiss': 1,\n",
    "    'Cfa': 10,\n",
    "    'Cfa_spoof': 10\n",
    "}\n",
    "\n",
    "for epoch in range(1, exp_cfg.epochs + 1):\n",
    "    # === TRAIN ===\n",
    "    model.train()\n",
    "    total_loss, total_samples = 0.0, 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{exp_cfg.epochs} [Train]\", leave=True)\n",
    "\n",
    "    for wav, label in pbar:\n",
    "        wav, label = wav.to(DEVICE), label.to(DEVICE)\n",
    "        wav = pre(wav)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        pred = model(wav).squeeze(-1)\n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        bs = wav.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_samples += bs\n",
    "        pbar.set_postfix(loss=f\"{total_loss / total_samples:.4f}\")\n",
    "\n",
    "    avg_train_loss = total_loss / total_samples\n",
    "\n",
    "    # === VALIDATE ===\n",
    "    model.eval()\n",
    "    val_loss, val_samples = 0.0, 0\n",
    "    all_scores, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=f\"Epoch {epoch}/{exp_cfg.epochs} [Val]\", leave=True)\n",
    "        for wav, label in pbar:\n",
    "            wav, label = wav.to(DEVICE), label.to(DEVICE)\n",
    "            wav = pre(wav)\n",
    "            pred = model(wav).squeeze(-1)\n",
    "            loss = criterion(pred, label)\n",
    "\n",
    "            bs = wav.size(0)\n",
    "            val_loss += loss.item() * bs\n",
    "            val_samples += bs\n",
    "\n",
    "            all_scores.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / val_samples\n",
    "    eer = calculate_EER(all_labels, all_scores)\n",
    "\n",
    "    # --- Compute t-DCF ---\n",
    "    bona_cm = np.array(all_scores)[np.array(all_labels) == 1]\n",
    "    spoof_cm = np.array(all_scores)[np.array(all_labels) == 0]\n",
    "    tDCF_curve, thr = compute_tDCF(bona_cm, spoof_cm, Pfa_asv, Pmiss_asv, Pfa_spoof_asv, cost_model)\n",
    "    min_tDCF = np.min(tDCF_curve)\n",
    "\n",
    "    print(f\"üßæ Epoch {epoch} Summary:\")\n",
    "    print(f\"   Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"   Val Loss:   {avg_val_loss:.4f}\")\n",
    "    print(f\"   Val EER:    {eer * 100:.2f}%\")\n",
    "    print(f\"   min-tDCF:   {min_tDCF:.4f}\")\n",
    "\n",
    "    # === SAVE BEST MODEL ===\n",
    "    if eer < best_val_eer:\n",
    "        best_val_eer = eer\n",
    "        torch.save(model, save_path)\n",
    "        print(f\"üíæ Saved new best model (EER={eer*100:.2f}%) to {save_path}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FINAL TEST PHASE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üèÅ Starting final testing...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load best model\n",
    "best_model = torch.load(save_path, map_location=DEVICE)\n",
    "best_model.eval()\n",
    "\n",
    "test_scores, test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(test_loader, desc=\"Testing\", leave=True)\n",
    "    for wav, label in pbar:\n",
    "        wav, label = wav.to(DEVICE), label.to(DEVICE)\n",
    "        wav = pre(wav)\n",
    "        pred = best_model(wav).squeeze(-1)\n",
    "        test_scores.extend(pred.cpu().numpy())\n",
    "        test_labels.extend(label.cpu().numpy())\n",
    "\n",
    "test_eer = calculate_EER(test_labels, test_scores)\n",
    "\n",
    "bona_cm = np.array(test_scores)[np.array(test_labels) == 1]\n",
    "spoof_cm = np.array(test_scores)[np.array(test_labels) == 0]\n",
    "tDCF_curve, thr = compute_tDCF(bona_cm, spoof_cm, Pfa_asv, Pmiss_asv, Pfa_spoof_asv, cost_model)\n",
    "min_tDCF = np.min(tDCF_curve)\n",
    "\n",
    "print(f\"üéØ Final Test EER:  {test_eer * 100:.2f}%\")\n",
    "print(f\"üìä Final min-tDCF: {min_tDCF:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL PARAMETER SUMMARY\n",
      "============================================================\n",
      "Trainable params         : 345,272\n",
      "Total params             : 345,272\n",
      "Model size (MiB)         : 1.32\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::exp encountered 2 time(s)\n",
      "Unsupported operator aten::sub encountered 78 time(s)\n",
      "Unsupported operator aten::mul encountered 640 time(s)\n",
      "Unsupported operator aten::add encountered 89 time(s)\n",
      "Unsupported operator aten::ones_like encountered 1 time(s)\n",
      "Unsupported operator aten::min encountered 2 time(s)\n",
      "Unsupported operator aten::linspace encountered 1 time(s)\n",
      "Unsupported operator aten::div encountered 356 time(s)\n",
      "Unsupported operator aten::sinc encountered 140 time(s)\n",
      "Unsupported operator aten::hamming_window encountered 70 time(s)\n",
      "Unsupported operator aten::abs encountered 71 time(s)\n",
      "Unsupported operator aten::sum encountered 70 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 5 time(s)\n",
      "Unsupported operator aten::selu_ encountered 8 time(s)\n",
      "Unsupported operator aten::softmax encountered 3 time(s)\n",
      "Unsupported operator aten::mean encountered 4 time(s)\n",
      "Unsupported operator aten::var encountered 4 time(s)\n",
      "Unsupported operator aten::sqrt encountered 4 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 1 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FLOPs / MACs (per forward pass)\n",
      "============================================================\n",
      "Input shape              : [1, 64000]\n",
      "MACs                     : 6.197 G\n",
      "FLOPs                    : 12.394 G\n",
      "============================================================\n",
      "\n",
      "Detailed layer-wise breakdown (torchinfo):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================================================================================================================================================================\n",
       "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "================================================================================================================================================================\n",
       "Rawformer_S                                                  [1, 64000]                [1]                       --                        --\n",
       "‚îú‚îÄFrontend_S: 1-1                                            [1, 64000]                [1, 64, 23, 16]           --                        --\n",
       "‚îÇ    ‚îî‚îÄTDFilterbank: 2-1                                     [1, 1, 64000]             [1, 70, 64000]            140                       --\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                                      [1, 1, 23, 21333]         [1, 1, 23, 21333]         2                         2\n",
       "‚îÇ    ‚îî‚îÄSELU: 2-3                                             [1, 1, 23, 21333]         [1, 1, 23, 21333]         --                        --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-4                                       [1, 1, 23, 21333]         [1, 64, 23, 16]           --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2DBlock_S: 3-1                               [1, 1, 23, 21333]         [1, 32, 23, 3555]         --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-1                                 [1, 1, 23, 21333]         [1, 32, 23, 21333]        128                       62,804,352\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-2                             [1, 1, 23, 21333]         [1, 32, 23, 21333]        6,592                     3,210,531,232\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 4-3                              [1, 32, 23, 21333]        [1, 32, 23, 3555]         --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2DBlock_S: 3-2                               [1, 32, 23, 3555]         [1, 32, 23, 592]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-4                             [1, 32, 23, 3555]         [1, 32, 23, 3555]         64                        64\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-5                             [1, 32, 23, 3555]         [1, 32, 23, 3555]         16,512                    1,381,387,744\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 4-6                              [1, 32, 23, 3555]         [1, 32, 23, 592]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2DBlock_S: 3-3                               [1, 32, 23, 592]          [1, 64, 23, 98]           --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-7                                 [1, 32, 23, 592]          [1, 64, 23, 592]          6,208                     84,528,128\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-8                             [1, 32, 23, 592]          [1, 32, 23, 592]          64                        64\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-9                             [1, 32, 23, 592]          [1, 64, 23, 592]          45,312                    627,387,520\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 4-10                             [1, 64, 23, 592]          [1, 64, 23, 98]           --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2DBlock_S: 3-4                               [1, 64, 23, 98]           [1, 64, 23, 16]           --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-11                            [1, 64, 23, 98]           [1, 64, 23, 98]           128                       128\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-12                            [1, 64, 23, 98]           [1, 64, 23, 98]           65,792                    152,027,136\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 4-13                             [1, 64, 23, 98]           [1, 64, 23, 16]           --                        --\n",
       "‚îú‚îÄPositionalAggregator1D: 1-2                                [1, 64, 23, 16]           [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îî‚îÄFlatten: 2-5                                          [1, 64, 23, 16]           [1, 64, 368]              --                        --\n",
       "‚îú‚îÄRawformerClassifier: 1-3                                   [1, 368, 64]              [1]                       --                        --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-6                                       [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerEncoderLayer: 3-5                     [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMultiHeadAttention: 4-14                    [1, 368, 64]              [1, 368, 64]              16,640                    16,640\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-15                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-16                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄFFN: 4-17                                   [1, 368, 64]              [1, 368, 64]              85,204                    85,204\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-18                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-19                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerEncoderLayer: 3-6                     [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMultiHeadAttention: 4-20                    [1, 368, 64]              [1, 368, 64]              16,640                    16,640\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-21                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-22                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄFFN: 4-23                                   [1, 368, 64]              [1, 368, 64]              85,204                    85,204\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-24                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-25                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "‚îÇ    ‚îî‚îÄSequencePooling: 2-7                                  [1, 368, 64]              [1, 64]                   --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-7                                      [1, 368, 64]              [1, 368, 1]               65                        65\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-8                                           [1, 64]                   [1, 1]                    65                        65\n",
       "================================================================================================================================================================\n",
       "Total params: 345,272\n",
       "Trainable params: 345,272\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.52\n",
       "================================================================================================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 681.89\n",
       "Params size (MB): 1.38\n",
       "Estimated Total Size (MB): 683.53\n",
       "================================================================================================================================================================"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "#  Model size & FLOPs (place this right after model creation)\n",
    "# --------------------------------------------------------------\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1. Parameter count (trainable + non-trainable) + size in MiB\n",
    "# --------------------------------------------------------------\n",
    "def print_model_params(model):\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total     = sum(p.numel() for p in model.parameters())\n",
    "    size_mb   = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024**2)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL PARAMETER SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Trainable params':<25}: {trainable:,}\")\n",
    "    print(f\"{'Total params'    :<25}: {total:,}\")\n",
    "    print(f\"{'Model size (MiB)':<25}: {size_mb:.2f}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "print_model_params(model)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2. FLOPs / MACs\n",
    "# --------------------------------------------------------------\n",
    "# We need a dummy waveform that matches the shape expected by the model.\n",
    "#   - Rawformer_S expects raw audio: (batch, time)\n",
    "#   - Use the maximum length defined in the config (or a typical 4-second clip)\n",
    "max_len_sec = getattr(exp_cfg, \"max_len_sec\", 4.0)          # fallback 4 s\n",
    "max_samples = int(exp_cfg.sample_rate * max_len_sec)\n",
    "\n",
    "dummy_wav = torch.randn(1, max_samples, device=DEVICE)     # (B, T)\n",
    "\n",
    "# Apply pre-emphasis if it is used in training/validation\n",
    "if pre is not None:\n",
    "    dummy_wav = pre(dummy_wav)\n",
    "\n",
    "# ---- fvcore (very accurate) ----\n",
    "flops = FlopCountAnalysis(model, dummy_wav)\n",
    "macs  = flops.total()                # MACs = multiply-adds\n",
    "flops_2 = macs * 2                   # FLOPs = 2 √ó MACs (standard convention)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FLOPs / MACs (per forward pass)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Input shape'   :<25}: {list(dummy_wav.shape)}\")\n",
    "print(f\"{'MACs'          :<25}: {macs/1e9:.3f} G\")\n",
    "print(f\"{'FLOPs'         :<25}: {flops_2/1e9:.3f} G\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# ---- torchinfo (nice table, optional) ----\n",
    "print(\"Detailed layer-wise breakdown (torchinfo):\")\n",
    "summary(model,\n",
    "        input_data=dummy_wav,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n",
    "        depth=4,\n",
    "        verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFLOPs per second of audio : 3.099\n"
     ]
    }
   ],
   "source": [
    "seconds = max_samples / exp_cfg.sample_rate\n",
    "print(f\"GFLOPs per second of audio : {flops_2/1e9/seconds:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8621024,
     "sourceId": 13570789,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "AA_MP_env",
   "language": "python",
   "name": "aa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
