{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.249141Z",
     "iopub.status.busy": "2025-11-25T05:39:06.248208Z",
     "iopub.status.idle": "2025-11-25T05:39:06.254138Z",
     "shell.execute_reply": "2025-11-25T05:39:06.253422Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.249113Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU count: 1\n",
      "[0] NVIDIA GeForce RTX 4090\n",
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU count:\", torch.cuda.device_count())\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"[{i}] {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.255498Z",
     "iopub.status.busy": "2025-11-25T05:39:06.255272Z",
     "iopub.status.idle": "2025-11-25T05:39:06.269640Z",
     "shell.execute_reply": "2025-11-25T05:39:06.268912Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.255482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Optional, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.270636Z",
     "iopub.status.busy": "2025-11-25T05:39:06.270399Z",
     "iopub.status.idle": "2025-11-25T05:39:06.283470Z",
     "shell.execute_reply": "2025-11-25T05:39:06.282660Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.270619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Optional (nice for shapes):\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    HAS_TORCHINFO = True\n",
    "except Exception:\n",
    "    HAS_TORCHINFO = False\n",
    "\n",
    "save_path = r\"C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\LearnableGammatone_best_cm_model.pth\"\n",
    "# ------------------ Configurable Paths ------------------ #\n",
    "class SysConfig:\n",
    "    \"\"\"\n",
    "    Folder-based dataset structure.\n",
    "    Each split (train/dev/test) contains two subfolders: bonafide and spoof.\n",
    "    \"\"\"\n",
    "    path_train =r\"G:\\INTERSPEECH_26\\LA\\ASV19\\train\"\n",
    "    path_dev   = r\"G:\\INTERSPEECH_26\\LA\\ASV19\\dev\"\n",
    "    path_test  =r\"G:\\INTERSPEECH_26\\LA\\ASV19\\dev\"\n",
    "\n",
    "\n",
    "# ------------------ Experiment Hyperparameters ------------------ #\n",
    "class ExpConfig:\n",
    "    # Audio processing\n",
    "    sample_rate = 16000\n",
    "    pre_emphasis = 0.97\n",
    "    train_duration_sec = 4\n",
    "    test_duration_sec = 4\n",
    "\n",
    "    # Model\n",
    "    transformer_hidden = 660\n",
    "\n",
    "    # Training hyperparameters\n",
    "    batch_size = 32\n",
    "    lr = 8*1e-4\n",
    "    epochs = 50  # increase as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.285135Z",
     "iopub.status.busy": "2025-11-25T05:39:06.284848Z",
     "iopub.status.idle": "2025-11-25T05:39:06.297266Z",
     "shell.execute_reply": "2025-11-25T05:39:06.296506Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.285118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch_audiomentations import (\n",
    "        Compose, AddColoredNoise, HighPassFilter, LowPassFilter, Gain\n",
    "    )\n",
    "    HAS_TA = True\n",
    "except Exception:\n",
    "    HAS_TA = False\n",
    "    Compose = AddColoredNoise = HighPassFilter = LowPassFilter = Gain = None\n",
    "\n",
    "class WaveformAugmentation(nn.Module):\n",
    "    def __init__(self, aug_list=('ACN', 'HPF', 'LPF', 'GAN'), sr=16000):\n",
    "        super().__init__()\n",
    "        self.sr = sr\n",
    "        if HAS_TA:\n",
    "            transforms = []\n",
    "            if 'ACN' in aug_list:\n",
    "                transforms.append(AddColoredNoise(10, 40, -2.0, 2.0, p=0.5))\n",
    "            if 'HPF' in aug_list:\n",
    "                transforms.append(HighPassFilter(20.0, 2400.0, p=0.5))\n",
    "            if 'LPF' in aug_list:\n",
    "                transforms.append(LowPassFilter(150.0, 7500.0, p=0.5))\n",
    "            if 'GAN' in aug_list:\n",
    "                transforms.append(Gain(-15.0, 5.0, p=0.5))\n",
    "            self.apply_augmentation = Compose(transforms) if transforms else None\n",
    "        else:\n",
    "            # No-op if torch_audiomentations isn't available\n",
    "            self.apply_augmentation = None\n",
    "\n",
    "    def forward(self, wav: torch.Tensor) -> torch.Tensor:\n",
    "        # wav: (B, T)\n",
    "        if self.apply_augmentation is None:\n",
    "            return wav\n",
    "        return self.apply_augmentation(wav.unsqueeze(1), self.sr).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.298208Z",
     "iopub.status.busy": "2025-11-25T05:39:06.298026Z",
     "iopub.status.idle": "2025-11-25T05:39:06.313209Z",
     "shell.execute_reply": "2025-11-25T05:39:06.312551Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.298194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PreEmphasis(nn.Module):\n",
    "    def __init__(self, pre_emphasis: float = 0.97):\n",
    "        super().__init__()\n",
    "        # Conv1D filter shape: (out_channels=1, in_channels=1, kernel_size=2)\n",
    "        filt = torch.tensor([[-pre_emphasis, 1.0]], dtype=torch.float32).unsqueeze(0)\n",
    "        self.register_buffer(\"filter\", filt)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, T)\n",
    "        x = x.unsqueeze(1)  # (B,1,T)\n",
    "        x = F.pad(x, (1, 0), mode=\"reflect\")\n",
    "        x = F.conv1d(x, self.filter)\n",
    "        return x.squeeze(1)  # (B,T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.367527Z",
     "iopub.status.busy": "2025-11-25T05:39:06.366858Z",
     "iopub.status.idle": "2025-11-25T05:39:06.383374Z",
     "shell.execute_reply": "2025-11-25T05:39:06.382605Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.367502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SincConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from AASIST. One input channel only.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def to_mel(hz): return 2595 * np.log10(1 + hz / 700)\n",
    "    @staticmethod\n",
    "    def to_hz(mel): return 700 * (10**(mel / 2595) - 1)\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1, stride=1, padding=0, dilation=1):\n",
    "        super().__init__()\n",
    "        if in_channels != 1:\n",
    "            raise ValueError(\"SincConv supports only one input channel.\")\n",
    "        self.out_channels = out_channels\n",
    "        self.sample_rate = sample_rate\n",
    "        self.kernel_size = kernel_size + (kernel_size % 2 == 0)\n",
    "\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        NFFT = 512\n",
    "        f = int(sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        fmel = self.to_mel(f)\n",
    "        filbandwidthsmel = np.linspace(fmel.min(), fmel.max(), out_channels + 1)\n",
    "        filbandwidthsf = self.to_hz(filbandwidthsmel)\n",
    "\n",
    "        self.hsupp = torch.arange(-(self.kernel_size - 1) / 2,\n",
    "                                  (self.kernel_size - 1) / 2 + 1)\n",
    "\n",
    "        band_pass = torch.zeros(out_channels, self.kernel_size)\n",
    "        for i in range(out_channels):\n",
    "            fmin, fmax = filbandwidthsf[i], filbandwidthsf[i + 1]\n",
    "            hHigh = (2 * fmax / sample_rate) * np.sinc(2 * fmax * self.hsupp / sample_rate)\n",
    "            hLow  = (2 * fmin / sample_rate) * np.sinc(2 * fmin * self.hsupp / sample_rate)\n",
    "            hideal = hHigh - hLow\n",
    "            band_pass[i, :] = torch.tensor(np.hamming(self.kernel_size)) * torch.tensor(hideal)\n",
    "        self.register_buffer(\"band_pass\", band_pass)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,1,T)\n",
    "        filt = self.band_pass.to(x.device).view(self.out_channels, 1, self.kernel_size)\n",
    "        return F.conv1d(x, filt, stride=self.stride, padding=self.padding, dilation=self.dilation, groups=1)\n",
    "\n",
    "class LearnableSincConv(nn.Module):\n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10**(mel / 2595) - 1)\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1,\n",
    "                 stride=1, padding=0, dilation=1, bias=False, min_low_hz=50, min_band_hz=50):\n",
    "        super().__init__()\n",
    "        if in_channels != 1:\n",
    "            raise ValueError(f\"SincConv only supports one input channel, got {in_channels}\")\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.min_low_hz = min_low_hz\n",
    "        self.min_band_hz = min_band_hz\n",
    "\n",
    "        # Mel-scale initialization\n",
    "        NFFT = 512\n",
    "        f = np.linspace(0, sample_rate / 2, int(NFFT / 2) + 1)\n",
    "        fmel = self.to_mel(f)\n",
    "        mel_points = np.linspace(fmel.min(), fmel.max(), out_channels + 1)\n",
    "        hz_points = self.to_hz(mel_points)\n",
    "\n",
    "        # Initialize learnable parameters for low cutoff and bandwidth\n",
    "        low_hz = hz_points[:-1]\n",
    "        band_hz = np.diff(hz_points)\n",
    "\n",
    "        self.low_hz_ = nn.Parameter(torch.tensor(low_hz, dtype=torch.float32))\n",
    "        self.band_hz_ = nn.Parameter(torch.tensor(band_hz, dtype=torch.float32))\n",
    "\n",
    "        # Time axis for filter generation\n",
    "        n = torch.arange(-(kernel_size - 1) / 2, (kernel_size - 1) / 2 + 1)\n",
    "        self.register_buffer('n', n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        n = self.n.to(device)\n",
    "\n",
    "        # Enforce positive frequency constraints\n",
    "        low = self.min_low_hz + torch.abs(self.low_hz_)\n",
    "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_), self.min_low_hz, self.sample_rate / 2 - 1)\n",
    "\n",
    "        band = (high - low)[:, None]\n",
    "        f_times_t_low = 2 * np.pi * low[:, None] * n / self.sample_rate\n",
    "        f_times_t_high = 2 * np.pi * high[:, None] * n / self.sample_rate\n",
    "\n",
    "        # Compute filters using sinc functions\n",
    "        sinc_high = torch.sin(f_times_t_high) / (n / self.sample_rate + 1e-8)\n",
    "        sinc_low = torch.sin(f_times_t_low) / (n / self.sample_rate + 1e-8)\n",
    "        filters = sinc_high - sinc_low\n",
    "\n",
    "        # Apply window (Hamming)\n",
    "        window = 0.54 - 0.46 * torch.cos(2 * np.pi * (torch.arange(self.kernel_size).to(device)) / self.kernel_size)\n",
    "        filters = filters * window\n",
    "\n",
    "        # Normalize\n",
    "        filters = filters / (2 * band)\n",
    "\n",
    "        filters = filters.view(self.out_channels, 1, self.kernel_size)\n",
    "        return F.conv1d(x, filters, stride=self.stride, padding=self.padding)\n",
    "\n",
    "class AdaptiveGaborConv(nn.Module):\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1):\n",
    "        super().__init__()\n",
    "        if in_channels != 1:\n",
    "            raise ValueError(\"GaborConv only supports 1 input channel\")\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1  # ensure odd kernel size\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        # Time support\n",
    "        self.t = torch.arange(-(kernel_size - 1) / 2, (kernel_size - 1) / 2 + 1, dtype=torch.float32) / sample_rate  # [kernel_size]\n",
    "\n",
    "        # Mel-scale initialization for center frequencies\n",
    "        NFFT = 512\n",
    "        f = np.linspace(0, sample_rate / 2, int(NFFT / 2) + 1)\n",
    "        mel = 2595 * np.log10(1 + f / 700)\n",
    "        mel_centers = np.linspace(mel.min(), mel.max(), out_channels)\n",
    "        hz_centers = 700 * (10 ** (mel_centers / 2595) - 1)\n",
    "        eta_init = hz_centers / sample_rate  # normalized center freqs [0‚Äì0.5]\n",
    "        self.eta = nn.Parameter(torch.tensor(eta_init, dtype=torch.float32))\n",
    "\n",
    "        # Adaptive bandwidths inversely proportional to frequency\n",
    "        base_sigma = (kernel_size / sample_rate) / 4  # base scale\n",
    "        sigma_init = base_sigma / (self.eta + 1e-4)   # inverse proportionality\n",
    "        sigma_init = torch.clamp(torch.tensor(sigma_init, dtype=torch.float32), 1e-4, 0.05)\n",
    "        self.sigma_scale = nn.Parameter(torch.ones(out_channels))  # learnable global scaling\n",
    "        self.register_buffer(\"sigma_init\", sigma_init)\n",
    "\n",
    "    def _create_filters(self, device):\n",
    "        t = self.t.to(device)                         # [kernel_size]\n",
    "        eta = torch.clamp(self.eta, 1e-4, 0.5)        # [out_channels]\n",
    "        sigma = (self.sigma_init.to(device) * self.sigma_scale).unsqueeze(1)  # [out_channels, 1]\n",
    "        eta = eta.unsqueeze(1)                        # [out_channels, 1]\n",
    "\n",
    "        # Gaussian window ‚Äî broadcast over time\n",
    "        gaussian = torch.exp(-t[None, :]**2 / (2 * sigma**2)) / (np.sqrt(2 * np.pi) * sigma)\n",
    "\n",
    "        # Cosine/sine modulations\n",
    "        cos_component = torch.cos(2 * np.pi * eta * t[None, :])\n",
    "        sin_component = torch.sin(2 * np.pi * eta * t[None, :])\n",
    "\n",
    "        filters_real = gaussian * cos_component\n",
    "        filters_imag = gaussian * sin_component\n",
    "\n",
    "        filters = torch.cat([filters_real, filters_imag], dim=0)  # [2*out_channels, kernel_size]\n",
    "        filters = filters / (filters.abs().max(dim=1, keepdim=True)[0] + 1e-8)\n",
    "        return filters\n",
    "\n",
    "    def forward(self, x):\n",
    "        filters = self._create_filters(x.device)\n",
    "        filters = filters.view(2 * self.out_channels, 1, self.kernel_size)\n",
    "        padding = self.kernel_size // 2\n",
    "        out = F.conv1d(x, filters, stride=1, padding=padding)\n",
    "        real, imag = out[:, :self.out_channels, :], out[:, self.out_channels:, :]\n",
    "        magnitude = torch.sqrt(real**2 + imag**2 + 1e-8)\n",
    "        return magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.384721Z",
     "iopub.status.busy": "2025-11-25T05:39:06.384504Z",
     "iopub.status.idle": "2025-11-25T05:39:06.401701Z",
     "shell.execute_reply": "2025-11-25T05:39:06.400961Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.384705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Nice-to-have (optional)\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    HAS_TORCHINFO = True\n",
    "except Exception:\n",
    "    HAS_TORCHINFO = False\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Expects Q,K,V: (B, H, S, D). Optional mask: (B,1,1,S) or broadcastable.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, Q, K, V, mask: Optional[torch.Tensor] = None):\n",
    "        assert Q.dim() == K.dim() == V.dim() == 4  # (B,H,S,D)\n",
    "        d_k = K.size(-1)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)  # (B,H,S_q,S_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "        attn = self.softmax(scores)\n",
    "        out = torch.matmul(attn, V)  # (B,H,S_q,D)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, n_head: int):\n",
    "        super().__init__()\n",
    "        assert d_model % n_head == 0, \"d_model must be divisible by n_head\"\n",
    "        self.n_head = n_head\n",
    "        self.d_head = d_model // n_head\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_model)\n",
    "        self.W_K = nn.Linear(d_model, d_model)\n",
    "        self.W_V = nn.Linear(d_model, d_model)\n",
    "        self.attn = ScaledDotProductAttention()\n",
    "        self.W_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def _split_heads(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,S,D) -> (B,H,S,Dh)\n",
    "        B, S, D = x.size()\n",
    "        x = x.view(B, S, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
    "        return x\n",
    "\n",
    "    def _merge_heads(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,H,S,Dh) -> (B,S,D)\n",
    "        B, H, S, Dh = x.size()\n",
    "        return x.permute(0, 2, 1, 3).contiguous().view(B, S, H * Dh)\n",
    "\n",
    "    def forward(self, Q, K, V, mask: Optional[torch.Tensor] = None):\n",
    "        assert Q.dim() == K.dim() == V.dim() == 3  # (B,S,D)\n",
    "        q = self._split_heads(self.W_Q(Q))\n",
    "        k = self._split_heads(self.W_K(K))\n",
    "        v = self._split_heads(self.W_V(V))\n",
    "        if mask is not None:\n",
    "            # make mask broadcastable to (B,H,S_q,S_k)\n",
    "            mask = mask.unsqueeze(1)\n",
    "        context = self.attn(q, k, v, mask=mask)\n",
    "        context = self._merge_heads(context)\n",
    "        return self.W_out(context)\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-12):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, unbiased=False, keepdim=True)\n",
    "        xhat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.gamma * xhat + self.beta\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, ffn_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Linear(ffn_hidden, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model=64, n_head=8, ffn_hidden=2048, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, n_head)\n",
    "        self.dropout1 = nn.Dropout(drop_prob)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.ffn = FFN(d_model, ffn_hidden, drop_prob)\n",
    "        self.dropout2 = nn.Dropout(drop_prob)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, attn_mask: Optional[torch.Tensor] = None):\n",
    "        # x: (B,S,D)\n",
    "        residual = x\n",
    "        x = self.attn(x, x, x, mask=attn_mask)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + residual)\n",
    "\n",
    "        residual = x\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + residual)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TD (Time-Domain) Filterbank and Learnable Gammatone Filterbank\n",
    "PyTorch implementations intended as drop-in replacements for the SincConv layer.\n",
    "\n",
    "Both modules accept (B,1,T) raw waveform and return (B, out_channels, T').\n",
    "They are made fully drop-in compatible with a SincConv-style constructor\n",
    "(i.e. accept `in_channels=1`, `out_channels=...`, `kernel_size=...`, `sample_rate=...`).\n",
    "\"\"\"\n",
    "\n",
    "from typing import Optional\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# -------------------- helpers --------------------\n",
    "\n",
    "def hz_to_mel(hz: np.ndarray) -> np.ndarray:\n",
    "    return 2595.0 * np.log10(1.0 + hz / 700.0)\n",
    "\n",
    "\n",
    "def mel_to_hz(mel: np.ndarray) -> np.ndarray:\n",
    "    return 700.0 * (10 ** (mel / 2595.0) - 1.0)\n",
    "\n",
    "\n",
    "def windowed_sinc_impulse(kernel_size: int, sr: int, fmin: float, fmax: float) -> np.ndarray:\n",
    "    \"\"\"Return a single band-pass windowed-sinc impulse response (numpy array).\n",
    "    kernel_size must be odd.\n",
    "    \"\"\"\n",
    "    assert kernel_size % 2 == 1, \"kernel_size should be odd\"\n",
    "    t = np.arange(-(kernel_size - 1) / 2.0, (kernel_size - 1) / 2.0 + 1.0)\n",
    "    h_high = (2 * fmax / sr) * np.sinc(2 * fmax * t / sr)\n",
    "    h_low = (2 * fmin / sr) * np.sinc(2 * fmin * t / sr)\n",
    "    hideal = h_high - h_low\n",
    "    w = np.hamming(kernel_size)\n",
    "    return hideal * w\n",
    "\n",
    "\n",
    "# -------------------- TDFilterbank --------------------\n",
    "\n",
    "class TDFilterbank(nn.Module):\n",
    "    \"\"\"Time-Domain Filterbank (drop-in replacement for SincConv).\n",
    "\n",
    "    Accepts `in_channels` argument for API compatibility but only supports mono input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 1,          # dummy for compatibility (ignored)\n",
    "                 out_channels: int = 70,\n",
    "                 kernel_size: int = 129,\n",
    "                 sample_rate: int = 16000,\n",
    "                 learnable: bool = True,\n",
    "                 learnable_f: bool = True,\n",
    "                 min_low_hz: float = 30.0,\n",
    "                 min_band_hz: float = 50.0,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.learnable = learnable\n",
    "        self.learnable_f = learnable_f\n",
    "\n",
    "        # mel-spaced boundaries (numpy)\n",
    "        NFFT = 512\n",
    "        f = int(sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        fmel = hz_to_mel(f)\n",
    "        mel_bins = np.linspace(fmel.min(), fmel.max(), out_channels + 1)\n",
    "        hz_bins = mel_to_hz(mel_bins)\n",
    "\n",
    "        fmins = hz_bins[:-1].copy()\n",
    "        fmaxs = hz_bins[1:].copy()\n",
    "\n",
    "        # ensure minimum band\n",
    "        fmins = np.maximum(fmins, min_low_hz)\n",
    "        fmaxs = np.maximum(fmaxs, fmins + min_band_hz)\n",
    "\n",
    "        # init kernels (numpy) shape (out_channels, kernel_size)\n",
    "        init_kernels = np.zeros((out_channels, kernel_size), dtype=np.float32)\n",
    "        for i in range(out_channels):\n",
    "            init_kernels[i, :] = windowed_sinc_impulse(kernel_size, sample_rate, fmins[i], fmaxs[i])\n",
    "\n",
    "        # normalize\n",
    "        init_kernels /= np.maximum(np.abs(init_kernels).sum(axis=1, keepdims=True), 1e-8)\n",
    "\n",
    "        # store initial kernels or params depending on mode\n",
    "        if not learnable:\n",
    "            # fixed kernel bank (register buffer for zero-parameter behavior)\n",
    "            self.register_buffer('kernels', torch.tensor(init_kernels, dtype=torch.float32).unsqueeze(1))\n",
    "            return\n",
    "\n",
    "        if learnable_f:\n",
    "            centres = (fmins + fmaxs) / 2.0\n",
    "            bws = (fmaxs - fmins)\n",
    "\n",
    "            self.log_centres = nn.Parameter(torch.log(torch.tensor(centres + 1.0, dtype=torch.float32)))\n",
    "            self.log_bws = nn.Parameter(torch.log(torch.tensor(bws + 1.0, dtype=torch.float32)))\n",
    "            self.register_buffer('kernel_window_ref', torch.tensor(init_kernels, dtype=torch.float32))\n",
    "        else:\n",
    "            # learn full kernels (Conv1d-like)\n",
    "            self.kernels_param = nn.Parameter(torch.tensor(init_kernels, dtype=torch.float32).unsqueeze(1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B,1,T)\n",
    "        returns: (B, out_channels, T')\n",
    "        \"\"\"\n",
    "        if not self.learnable:\n",
    "            return F.conv1d(x, self.kernels.to(x.device), stride=1, padding=(self.kernel_size - 1) // 2)\n",
    "\n",
    "        if self.learnable_f:\n",
    "            device = x.device\n",
    "            centres = torch.exp(self.log_centres).to(device) - 1.0\n",
    "            bws = torch.exp(self.log_bws).to(device) - 1.0\n",
    "\n",
    "            fmin = centres - 0.5 * bws\n",
    "            fmax = centres + 0.5 * bws\n",
    "\n",
    "            # clamp ranges safely using tensor ops (avoid mixing tensor/scalar in positional args)\n",
    "            max_freq_tensor = (self.sample_rate / 2.0) * torch.ones_like(fmax, device=device)\n",
    "            fmin = torch.clamp(fmin, min=1.0)\n",
    "            fmin = torch.min(fmin, max_freq_tensor - 2.0)\n",
    "            fmax = torch.max(fmax, fmin + 1.0)\n",
    "            fmax = torch.min(fmax, max_freq_tensor)\n",
    "\n",
    "            # time vector (device)\n",
    "            t = torch.linspace(\n",
    "                -(self.kernel_size - 1) / 2.0,\n",
    "                (self.kernel_size - 1) / 2.0,\n",
    "                steps=self.kernel_size,\n",
    "                device=device,\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "\n",
    "            kernels = []\n",
    "            # build each kernel on-device\n",
    "            for i in range(self.out_channels):\n",
    "                hi = (2.0 * fmax[i] / self.sample_rate) * torch.sinc(2.0 * fmax[i] * t / self.sample_rate)\n",
    "                lo = (2.0 * fmin[i] / self.sample_rate) * torch.sinc(2.0 * fmin[i] * t / self.sample_rate)\n",
    "\n",
    "                h = hi - lo\n",
    "                h = h * torch.hamming_window(self.kernel_size, periodic=False, device=device, dtype=torch.float32)\n",
    "                h = h / (h.abs().sum() + 1e-8)\n",
    "                kernels.append(h)\n",
    "\n",
    "            kernels = torch.stack(kernels, dim=0).unsqueeze(1)  # (out,1,k)\n",
    "            return F.conv1d(x, kernels, stride=1, padding=(self.kernel_size - 1) // 2)\n",
    "\n",
    "        # learn full kernels branch\n",
    "        return F.conv1d(x, self.kernels_param.to(x.device), stride=1, padding=(self.kernel_size - 1) // 2)\n",
    "\n",
    "\n",
    "# -------------------- Learnable Gammatone Filterbank --------------------\n",
    "\n",
    "class LearnableGammatone(nn.Module):\n",
    "    \"\"\"Learnable Gammatone Filterbank (drop-in compatible).\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 1,         # dummy for compatibility (ignored)\n",
    "                 out_channels: int = 70,\n",
    "                 kernel_size: int = 129,\n",
    "                 sample_rate: int = 16000,\n",
    "                 n: int = 4,\n",
    "                 min_freq: float = 30.0,\n",
    "                 max_freq: Optional[float] = None,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n = n\n",
    "        self.max_freq = max_freq or sample_rate / 2.0\n",
    "\n",
    "        # mel spaced centres (numpy)\n",
    "        NFFT = 512\n",
    "        f = int(sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        mel = hz_to_mel(f)\n",
    "        mel_bins = np.linspace(mel.min(), mel.max(), out_channels)\n",
    "        centres = mel_to_hz(mel_bins)\n",
    "        centres = np.clip(centres, min_freq, self.max_freq - 10.0)\n",
    "\n",
    "        # ERB approx\n",
    "        erb = 24.7 + 0.108 * centres\n",
    "\n",
    "        self.log_centres = nn.Parameter(torch.log(torch.tensor(centres + 1.0, dtype=torch.float32)))\n",
    "        self.log_band = nn.Parameter(torch.log(torch.tensor(erb + 1.0, dtype=torch.float32)))\n",
    "\n",
    "        self.log_amp = nn.Parameter(torch.zeros(out_channels, dtype=torch.float32))\n",
    "\n",
    "        t = np.arange(kernel_size, dtype=np.float32) - (kernel_size - 1) / 2.0\n",
    "        self.register_buffer(\"t\", torch.tensor(t, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B,1,T)\n",
    "        returns: (B, out_channels, T')\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "\n",
    "        centres = torch.exp(self.log_centres).to(device) - 1.0\n",
    "        band = torch.exp(self.log_band).to(device) - 1.0\n",
    "        amp = torch.exp(self.log_amp).to(device)\n",
    "\n",
    "        centres = torch.clamp(centres, 20.0, self.max_freq - 1.0)\n",
    "        band = torch.clamp(band, 1.0, self.sample_rate / 4.0)\n",
    "\n",
    "        t = self.t.to(device)\n",
    "        kernels = []\n",
    "\n",
    "        for i in range(self.out_channels):\n",
    "            fc = centres[i]\n",
    "            b = band[i]\n",
    "            a = amp[i]\n",
    "\n",
    "            tp = t  # centered time vector\n",
    "\n",
    "            env = (tp.abs() / self.sample_rate) ** (self.n - 1)\n",
    "            env = env * torch.exp(-2.0 * math.pi * b * tp.abs() / self.sample_rate)\n",
    "            carrier = torch.cos(2.0 * math.pi * fc * tp / self.sample_rate)\n",
    "\n",
    "            g = a * env * carrier\n",
    "            g = g / (g.abs().sum() + 1e-8)\n",
    "\n",
    "            kernels.append(g)\n",
    "\n",
    "        kernels = torch.stack(kernels, dim=0).unsqueeze(1)\n",
    "        return F.conv1d(x, kernels.to(device), stride=1, padding=(self.kernel_size - 1) // 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.402828Z",
     "iopub.status.busy": "2025-11-25T05:39:06.402574Z",
     "iopub.status.idle": "2025-11-25T05:39:06.421502Z",
     "shell.execute_reply": "2025-11-25T05:39:06.420822Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.402805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Frontend_S\n",
    "# ----------------------------------------------------------------------\n",
    "class Frontend_S(nn.Module):\n",
    "    def __init__(self, device, sinc_kernel_size=128, sample_rate=16000):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---- Sinc layer (no parameters ‚Üí safe on any device) ----\n",
    "        self.sinc_layer = LearnableGammatone(\n",
    "            in_channels=1,\n",
    "            out_channels=70,\n",
    "            kernel_size=sinc_kernel_size,\n",
    "            sample_rate=sample_rate,\n",
    "        )\n",
    "\n",
    "        # ---- BatchNorm that must live on the target device ----\n",
    "        self.bn = nn.BatchNorm2d(num_features=1).to(device)\n",
    "\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "\n",
    "        # ---- Conv blocks (they also contain BatchNorms) ----\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            Conv2DBlock_S(in_channels=1,  out_channels=32, is_first_block=True),\n",
    "            Conv2DBlock_S(in_channels=32, out_channels=32),\n",
    "            Conv2DBlock_S(in_channels=32, out_channels=64),\n",
    "            Conv2DBlock_S(in_channels=64, out_channels=64),\n",
    "        ).to(device)                     # <-- move the whole Sequential\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : [B, T]  (raw waveform)\n",
    "        x = x.unsqueeze(1)                     # [B,1,T]\n",
    "        x = self.sinc_layer(x)                 # [B,70,T']\n",
    "        x = x.unsqueeze(1)                     # [B,1,70,T']\n",
    "        x = F.max_pool2d(torch.abs(x), (3, 3)) # [B,1,F,T]\n",
    "        x = self.bn(x)\n",
    "        LFM = self.selu(x)\n",
    "\n",
    "        HFM = self.conv_blocks(LFM)            # [B,64,f,t]\n",
    "        return HFM\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Conv2DBlock_S\n",
    "# ----------------------------------------------------------------------\n",
    "class Conv2DBlock_S(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, is_first_block: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---- optional normaliser (BN+SELU) ----\n",
    "        self.normalizer = None\n",
    "        if not is_first_block:\n",
    "            self.normalizer = nn.Sequential(\n",
    "                nn.BatchNorm2d(in_channels),\n",
    "                nn.SELU(inplace=True),\n",
    "            )\n",
    "\n",
    "        # ---- two conv layers + BN+SELU ----\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(2, 5), padding=(1, 2)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(2, 3), padding=(0, 1)),\n",
    "        )\n",
    "\n",
    "        # ---- residual connection when channel count changes ----\n",
    "        self.downsampler = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsampler = nn.Conv2d(in_channels, out_channels,\n",
    "                                        kernel_size=(1, 3), padding=(0, 1))\n",
    "\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(1, 6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsampler is not None:\n",
    "            identity = self.downsampler(identity)\n",
    "\n",
    "        if self.normalizer is not None:\n",
    "            x = self.normalizer(x)\n",
    "\n",
    "        x = self.layers(x) + identity\n",
    "        x = self.pooling(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. PositionalAggregator1D\n",
    "# ----------------------------------------------------------------------\n",
    "class PositionalAggregator1D(nn.Module):\n",
    "    def __init__(self, max_C: int, max_ft: int, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.flattener = nn.Flatten(start_dim=-2, end_dim=-1)\n",
    "\n",
    "        # ----- sinusoidal positional encoding (no trainable params) -----\n",
    "        pos = torch.arange(1, max_ft - 1, device=device).float().unsqueeze(1)   # (L-2,1)\n",
    "        dim = torch.arange(0, max_C, step=2, device=device).float().unsqueeze(0)  # (1,D/2)\n",
    "\n",
    "        enc = torch.zeros(max_ft, max_C, device=device)\n",
    "        enc[1:-1, 0::2] = torch.sin(pos / (10000 ** (dim / max_C)))\n",
    "        enc[1:-1, 1::2] = torch.cos(pos / (10000 ** (dim / max_C)))\n",
    "        self.register_buffer('encoding', enc)   # stored on the correct device automatically\n",
    "\n",
    "    def forward(self, HFM):\n",
    "        \"\"\"\n",
    "        HFM : [B, C, f, t]\n",
    "        out : [B, f*t, C]  with added positional encoding\n",
    "        \"\"\"\n",
    "        B, C, f, t = HFM.shape\n",
    "        ft = f * t\n",
    "        out = self.flattener(HFM).transpose(1, 2)               # [B, f*t, C]\n",
    "        out = out + self.encoding[:ft, :C]                      # broadcast\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.423289Z",
     "iopub.status.busy": "2025-11-25T05:39:06.423059Z",
     "iopub.status.idle": "2025-11-25T05:39:06.437563Z",
     "shell.execute_reply": "2025-11-25T05:39:06.436811Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.423270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Rawformer_S(nn.Module):\n",
    "    def __init__(self, device, transformer_hidden=64, sample_rate: int = 16000):\n",
    "        super().__init__()\n",
    "        # ---- 1. give the front-end the device ----\n",
    "        self.front_end = Frontend_S(sinc_kernel_size=128,\n",
    "                                    sample_rate=sample_rate,\n",
    "                                    device=device)          # <-- add this\n",
    "\n",
    "        self.positional_embedding = PositionalAggregator1D(\n",
    "            max_C=64, max_ft=23*16, device=device)\n",
    "\n",
    "        self.classifier = RawformerClassifier(C=64, n_encoder=2, transformer_hidden=transformer_hidden)\n",
    "\n",
    "        # ---- 2. move *everything* to the target device in one go ----\n",
    "        self.to(device)                     # <-- important!\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.front_end(x)               # now on correct device\n",
    "        x = self.positional_embedding(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.438790Z",
     "iopub.status.busy": "2025-11-25T05:39:06.438533Z",
     "iopub.status.idle": "2025-11-25T05:39:06.453087Z",
     "shell.execute_reply": "2025-11-25T05:39:06.452417Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.438769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SequencePooling(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention-style weighted pooling over sequence.\n",
    "    Input: (B,S,C) -> Output: (B,C)\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,S,C)\n",
    "        w = self.linear(x)               # (B,S,1)\n",
    "        w = F.softmax(w.transpose(1, 2), dim=-1)  # (B,1,S)\n",
    "        out = torch.matmul(w, x)         # (B,1,C)\n",
    "        return out.squeeze(1)            # (B,C)\n",
    "\n",
    "\n",
    "class RawformerClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoders (N layers) + SeqPool + Linear + Sigmoid\n",
    "    Input: sequence (B,S,C)  Output: (B,) score in [0,1]\n",
    "    \"\"\"\n",
    "    def __init__(self, C: int, n_encoder: int, transformer_hidden: int):\n",
    "        super().__init__()\n",
    "        self.encoders = nn.Sequential(OrderedDict([\n",
    "            (f\"encoder{i}\", TransformerEncoderLayer(d_model=C, n_head=8, ffn_hidden=transformer_hidden))\n",
    "            for i in range(n_encoder)\n",
    "        ]))\n",
    "        self.seq_pool = SequencePooling(d_model=C)\n",
    "        self.fc = nn.Linear(C, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,S,C)\n",
    "        x = self.encoders(x)\n",
    "        x = self.seq_pool(x)\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x).squeeze(-1)   # (B,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.453948Z",
     "iopub.status.busy": "2025-11-25T05:39:06.453693Z",
     "iopub.status.idle": "2025-11-25T05:39:06.469810Z",
     "shell.execute_reply": "2025-11-25T05:39:06.469201Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.453931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_pad(batch):\n",
    "    # Here all items are same length already; just stack.\n",
    "    wavs, labels = zip(*batch)\n",
    "    wavs = torch.stack(wavs, dim=0)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return wavs, labels\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, preemph=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for wav, label in loader:\n",
    "        wav = wav.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        if preemph is not None:\n",
    "            wav = preemph(wav)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(wav)              # (B,)\n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * wav.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, preemph=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    for wav, label in loader:\n",
    "        wav = wav.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        if preemph is not None:\n",
    "            wav = preemph(wav)\n",
    "        pred = model(wav)\n",
    "        loss = criterion(pred, label)\n",
    "        total_loss += loss.item() * wav.size(0)\n",
    "        total_correct += ((pred > 0.5).float() == label).sum().item()\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = total_correct / len(loader.dataset)\n",
    "    return avg_loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.470899Z",
     "iopub.status.busy": "2025-11-25T05:39:06.470649Z",
     "iopub.status.idle": "2025-11-25T05:39:06.544045Z",
     "shell.execute_reply": "2025-11-25T05:39:06.543269Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.470875Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([2]) | values ~ (0.5365177392959595, 0.5377536416053772)\n"
     ]
    }
   ],
   "source": [
    "# Build model and run a forward pass with dummy audio\n",
    "exp_cfg = ExpConfig()\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Rawformer_S(device=DEVICE, transformer_hidden=exp_cfg.transformer_hidden,\n",
    "                          sample_rate=exp_cfg.sample_rate)\n",
    "\n",
    "B = 2\n",
    "dummy_audio = torch.randn(B, exp_cfg.sample_rate * exp_cfg.train_duration_sec).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    out = model(dummy_audio)\n",
    "print(\"Model output shape:\", out.shape, \"| values ~\", (out.min().item(), out.max().item()))\n",
    "\n",
    "if HAS_TORCHINFO:\n",
    "    try:\n",
    "        summary(model, input_size=(B, exp_cfg.sample_rate * exp_cfg.train_duration_sec))\n",
    "    except Exception as e:\n",
    "        print(\"torchinfo summary error (safe to ignore):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.545010Z",
     "iopub.status.busy": "2025-11-25T05:39:06.544797Z",
     "iopub.status.idle": "2025-11-25T05:39:06.548428Z",
     "shell.execute_reply": "2025-11-25T05:39:06.547784Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.544976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torchaudio.set_audio_backend(\"ffmpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.549387Z",
     "iopub.status.busy": "2025-11-25T05:39:06.549113Z",
     "iopub.status.idle": "2025-11-25T05:39:06.559782Z",
     "shell.execute_reply": "2025-11-25T05:39:06.559257Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.549370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.562453Z",
     "iopub.status.busy": "2025-11-25T05:39:06.562096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loaded 25380 files from G:\\INTERSPEECH_26\\LA\\ASV19\\train\n",
      "üìÅ Loaded 24844 files from G:\\INTERSPEECH_26\\LA\\ASV19\\dev\n",
      "üìÅ Loaded 24844 files from G:\\INTERSPEECH_26\\LA\\ASV19\\dev\n",
      "üöÄ Starting training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6f0550d82142a7b6787509f72feb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5740b240824472cb73f1e8bea3091c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 1 Summary:\n",
      "   Train Loss: 0.2490\n",
      "   Val Loss:   0.3054\n",
      "   Val EER:    17.46%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=17.46%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\LearnableGammatone_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f9e29503f5470a91c768df31c1d682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26be62c654fc4a7ebb965bcddd7ff3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 2 Summary:\n",
      "   Train Loss: 0.0938\n",
      "   Val Loss:   0.0867\n",
      "   Val EER:    5.22%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=5.22%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\LearnableGammatone_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150c537102e64fdf96f5c8c67dd81e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6c9d19104d4953a9605a8244ba2ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 3 Summary:\n",
      "   Train Loss: 0.0630\n",
      "   Val Loss:   0.1821\n",
      "   Val EER:    5.69%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6628b967e8d49eca0d8144744730bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf8325adcdb46729395524e1d79b0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 4 Summary:\n",
      "   Train Loss: 0.0541\n",
      "   Val Loss:   0.3511\n",
      "   Val EER:    4.75%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=4.75%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\LearnableGammatone_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ab2fbe28dd429581118d49db655101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059429d88ef448748ce2a67c46aaf6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 5 Summary:\n",
      "   Train Loss: 0.0461\n",
      "   Val Loss:   0.2787\n",
      "   Val EER:    8.66%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a36622d85b401f845106cbdaa76b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bccfe0ba2be4ed2917efa295c875e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 6 Summary:\n",
      "   Train Loss: 0.0460\n",
      "   Val Loss:   0.0957\n",
      "   Val EER:    3.26%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=3.26%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\LearnableGammatone_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96477d54daf94e8d9c56dbd1a8a506f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c323a509334cf09c4516dfaec7ac50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 7 Summary:\n",
      "   Train Loss: 0.0412\n",
      "   Val Loss:   0.6872\n",
      "   Val EER:    16.37%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280a6a78c4c1490bace3d6178e8be15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7401c9aa86e34ca6a0a3b44afeaa8498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 8 Summary:\n",
      "   Train Loss: 0.0432\n",
      "   Val Loss:   0.0941\n",
      "   Val EER:    3.06%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=3.06%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\LearnableGammatone_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10050fa51e374509a7261d4ecd1d9a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a5e4680e794782b057bd881961cc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 9 Summary:\n",
      "   Train Loss: 0.0423\n",
      "   Val Loss:   0.0358\n",
      "   Val EER:    2.33%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=2.33%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\LearnableGammatone_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ccfb6788574d8c9ba0cfe0981b1d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057a1acc383d47e09c103456178a9d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 10 Summary:\n",
      "   Train Loss: 0.0316\n",
      "   Val Loss:   0.0690\n",
      "   Val EER:    2.83%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9fc8e33ef841b5a3dbf3d29ed8a13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c3ba2c9057495aa277990d7de16983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 11 Summary:\n",
      "   Train Loss: 0.0336\n",
      "   Val Loss:   0.1027\n",
      "   Val EER:    2.67%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663c3b6333654b1aa00b082617e60c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26f96b6ed5840859c392474aece875b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 12 Summary:\n",
      "   Train Loss: 0.0267\n",
      "   Val Loss:   0.0523\n",
      "   Val EER:    2.86%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849c1ad076b84e0d9541001de6dcdd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb082bf3f034981b376c6c52057c164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 13 Summary:\n",
      "   Train Loss: 0.0427\n",
      "   Val Loss:   0.0448\n",
      "   Val EER:    1.73%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=1.73%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\LearnableGammatone_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369eaf9309fe4f62ba0be1abf68f35f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725fb8408aa04d8e998594c3d74463e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 14 Summary:\n",
      "   Train Loss: 0.0308\n",
      "   Val Loss:   0.0405\n",
      "   Val EER:    1.88%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b78e91a9bf4ffebd9f4270a33034e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a7eaab14904e0784b341bc6f7e668e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 15 Summary:\n",
      "   Train Loss: 0.0341\n",
      "   Val Loss:   0.0324\n",
      "   Val EER:    2.27%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a9a0aa49c947c3ad365e7319de9125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f971cf73ff6e4091952179b25b6437f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 16 Summary:\n",
      "   Train Loss: 0.0329\n",
      "   Val Loss:   0.0376\n",
      "   Val EER:    2.12%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bff8e716494ecda67ba9b43f40abf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839a867c143844ad81f6fe3faae13525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 17 Summary:\n",
      "   Train Loss: 0.0301\n",
      "   Val Loss:   0.0435\n",
      "   Val EER:    2.39%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027f2abf74c840f7b98dbcce65b51353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9979b92bd0e44f2a738b0be2ac88f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 18 Summary:\n",
      "   Train Loss: 0.0461\n",
      "   Val Loss:   0.0426\n",
      "   Val EER:    2.16%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45ddf45b41b4c76ae8d9bd35a371ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4edfe5e08244fb8d74932516c37b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 19 Summary:\n",
      "   Train Loss: 0.0313\n",
      "   Val Loss:   0.0775\n",
      "   Val EER:    3.31%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9e4f0c74b84dd49a7f81282ab7ab3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22601550dd8e44b08ae0c79666ac613f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 20 Summary:\n",
      "   Train Loss: 0.0493\n",
      "   Val Loss:   0.0471\n",
      "   Val EER:    2.59%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f351006e227245a99d5890b38b24170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75823e8844942b9adc576a0efa75803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 21 Summary:\n",
      "   Train Loss: 0.0326\n",
      "   Val Loss:   0.0411\n",
      "   Val EER:    2.83%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb0273353cd4d21bc0a8bca4af179e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1748b967174e47a3807c0691d5a94bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 22 Summary:\n",
      "   Train Loss: 0.0285\n",
      "   Val Loss:   0.0494\n",
      "   Val EER:    2.47%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881816f5e95149edb535b2a901950ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8edee578ba847c4a1b6d01f3dd58d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 23 Summary:\n",
      "   Train Loss: 0.0312\n",
      "   Val Loss:   0.0303\n",
      "   Val EER:    2.24%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f1b9cf8cc145a2af0b27ee843a8542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92069219410c42c6afee9a19beb6e54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 24 Summary:\n",
      "   Train Loss: 0.0334\n",
      "   Val Loss:   0.0334\n",
      "   Val EER:    1.88%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e03ec9165f04f4daca766244c33ea44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79d69f19f434c239b4a0c989e971ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 25 Summary:\n",
      "   Train Loss: 0.0297\n",
      "   Val Loss:   0.0402\n",
      "   Val EER:    2.51%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57e20262741439b90822a61dcb9aab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd90a6d82c2d47c5bb5101704d1fe953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 26 Summary:\n",
      "   Train Loss: 0.0302\n",
      "   Val Loss:   0.0337\n",
      "   Val EER:    2.12%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccad0645a2a41e7a59686a9ba3e197d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3743e9eae44eca9d59faa9e10c40f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 27 Summary:\n",
      "   Train Loss: 0.0332\n",
      "   Val Loss:   0.1361\n",
      "   Val EER:    2.75%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e9f50827ef48f58b95b9f804e5912f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394f39efa0df4662957b89e18964a839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 28 Summary:\n",
      "   Train Loss: 0.0250\n",
      "   Val Loss:   0.0272\n",
      "   Val EER:    1.85%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2d637a7ad647d684358b9af1326f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c760c6fc6d7489fba702c55e74b8a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 29 Summary:\n",
      "   Train Loss: 0.0367\n",
      "   Val Loss:   0.0352\n",
      "   Val EER:    2.12%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707ad75738d04091a5742eb107d7f91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17f26dedc1f498e96e986a7cc17be9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 30 Summary:\n",
      "   Train Loss: 0.0254\n",
      "   Val Loss:   0.0261\n",
      "   Val EER:    1.83%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffb89795fdd44e2b3fa1d3bae8828a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143a57264a394a15b14bdf0f30830721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 31 Summary:\n",
      "   Train Loss: 0.0240\n",
      "   Val Loss:   0.0464\n",
      "   Val EER:    2.79%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98feb85227a7443a9c5377b43372defd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc27ce616ee4eaca3e3d2f6ccca2ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 32 Summary:\n",
      "   Train Loss: 0.0310\n",
      "   Val Loss:   0.1346\n",
      "   Val EER:    2.39%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66430cb723ac4785a2264feb02f5aa26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c5357897bb4994928d3849d14a1c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 33 Summary:\n",
      "   Train Loss: 0.0355\n",
      "   Val Loss:   0.0317\n",
      "   Val EER:    2.28%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa40c8a440e441db252bd30d13cd9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f621e8c74742dd9bd3a33aa5cae469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 34 Summary:\n",
      "   Train Loss: 0.0233\n",
      "   Val Loss:   0.0299\n",
      "   Val EER:    1.79%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcb52fa1e3c430e89b701b659365bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82547369ae084944b350906f3c7ac106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 35 Summary:\n",
      "   Train Loss: 0.0218\n",
      "   Val Loss:   0.0335\n",
      "   Val EER:    2.16%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bfc7f59ac448b99e2ece0c5b47fae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6450ccc0b96f42c9b092cc2d16e0c845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 36 Summary:\n",
      "   Train Loss: 0.0298\n",
      "   Val Loss:   0.1101\n",
      "   Val EER:    2.79%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c052d1827eff434eb2086545f9693067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b694b41413f4bfca21c182d93a92713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 37 Summary:\n",
      "   Train Loss: 0.0557\n",
      "   Val Loss:   0.0572\n",
      "   Val EER:    2.91%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325d559a957f4029a7e8dfab641c59ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0137ebd56d994b27b76c3eecb8536d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 38 Summary:\n",
      "   Train Loss: 0.0327\n",
      "   Val Loss:   0.0354\n",
      "   Val EER:    2.16%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f20efc4a3c4a66b7da7edc3ee94013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a5664e865f426eaaedc33a7935ee09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 39 Summary:\n",
      "   Train Loss: 0.0222\n",
      "   Val Loss:   0.0367\n",
      "   Val EER:    1.73%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75bc684269b4054b6ea94b71a71b7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b97c24c1a3415987bddc6701ca8795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 40 Summary:\n",
      "   Train Loss: 0.0274\n",
      "   Val Loss:   0.0332\n",
      "   Val EER:    1.83%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472743e2710647bf94661739695969e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785bf9a9dba44aa28026a73ae2ce97d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 41 Summary:\n",
      "   Train Loss: 0.0331\n",
      "   Val Loss:   0.0385\n",
      "   Val EER:    2.22%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdc5f8b5d504c02a66f60da2ab56d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069f599a717547f0bb2498d1911f2184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 42 Summary:\n",
      "   Train Loss: 0.0265\n",
      "   Val Loss:   0.0464\n",
      "   Val EER:    3.41%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538aee6d85b14bbc9552e186291278f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca46172d4284a7e9c4a2a51c56068f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 43 Summary:\n",
      "   Train Loss: 0.0316\n",
      "   Val Loss:   0.0292\n",
      "   Val EER:    1.93%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b25d369fd547d9bcc4267a09d8f4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e133a0c1dc741eabd11128a5528ba5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 44 Summary:\n",
      "   Train Loss: 0.0308\n",
      "   Val Loss:   0.0480\n",
      "   Val EER:    3.22%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8303418b9494d6ead754439790c5cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd627c12ddb416fa60ea89ee1fd29c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 45 Summary:\n",
      "   Train Loss: 0.0287\n",
      "   Val Loss:   0.0362\n",
      "   Val EER:    2.12%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4f6babc15f4e0b8a00307fe4d5c078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be028a97375141ab953193084f6ec3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 46 Summary:\n",
      "   Train Loss: 0.0321\n",
      "   Val Loss:   0.0724\n",
      "   Val EER:    4.11%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48f9a6f199d46408c9349b435585994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad6aa0d938040ca8cbbb25cfdd6f121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 47 Summary:\n",
      "   Train Loss: 0.0295\n",
      "   Val Loss:   0.0273\n",
      "   Val EER:    1.73%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccec03db0da4705a5e0841cd6bd27cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4f8338666c4739a61c640ce1b9998c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 48 Summary:\n",
      "   Train Loss: 0.0194\n",
      "   Val Loss:   0.0321\n",
      "   Val EER:    2.00%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e0515e7f0941d08ee6e8999aca99c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8149326078f847d5ab87317684e95d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 49 Summary:\n",
      "   Train Loss: 0.0229\n",
      "   Val Loss:   0.0361\n",
      "   Val EER:    1.60%\n",
      "   min-tDCF:   1.0000\n",
      "üíæ Saved new best model (EER=1.60%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\LearnableGammatone_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44371856a47a456e98ee909996f73bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fb24bf04b544bc86f8829175d1889f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Epoch 50 Summary:\n",
      "   Train Loss: 0.0239\n",
      "   Val Loss:   0.0303\n",
      "   Val EER:    1.81%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "üèÅ Starting final testing...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12056\\2467297305.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model = torch.load(save_path, map_location=DEVICE)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd05213e4e3448e815ff0d84114c31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Final Test EER:  1.52%\n",
      "üìä Final min-tDCF: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SIMPLE DATASET\n",
    "# ============================================================\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "class ASVspoofFolderDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, sample_rate=16000, duration_sec=4):\n",
    "        self.root_dir = root_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration_sec = duration_sec\n",
    "        self.audio_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label_name, label_value in [(\"bonafide\", 1), (\"spoof\", 0)]:\n",
    "            class_dir = os.path.join(root_dir, label_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for file in os.listdir(class_dir):\n",
    "                    if file.endswith(\".flac\") or file.endswith(\".wav\"):\n",
    "                        self.audio_paths.append(os.path.join(class_dir, file))\n",
    "                        self.labels.append(label_value)\n",
    "\n",
    "        print(f\"üìÅ Loaded {len(self.audio_paths)} files from {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.audio_paths[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "        # --- Use soundfile for FLAC ---\n",
    "        if path.lower().endswith(\".flac\"):\n",
    "            wav_np, sr = sf.read(path)         # numpy array (T,) or (T, C)\n",
    "            if wav_np.ndim > 1:                # convert stereo ‚Üí mono\n",
    "                wav_np = wav_np.mean(axis=1)\n",
    "            wav = torch.tensor(wav_np, dtype=torch.float32).unsqueeze(0)  # [1, T]\n",
    "\n",
    "        # --- Use torchaudio for WAV ---\n",
    "        else:\n",
    "            wav, sr = torchaudio.load(path)\n",
    "\n",
    "        # --- Resample if needed ---\n",
    "        if sr != self.sample_rate:\n",
    "            wav = torchaudio.functional.resample(wav, sr, self.sample_rate)\n",
    "\n",
    "        # --- Crop/pad ---\n",
    "        num_samples = int(self.sample_rate * self.duration_sec)\n",
    "\n",
    "        if wav.size(1) > num_samples:\n",
    "            start = random.randint(0, wav.size(1) - num_samples)\n",
    "            wav = wav[:, start:start + num_samples]\n",
    "        elif wav.size(1) < num_samples:\n",
    "            wav = F.pad(wav, (0, num_samples - wav.size(1)))\n",
    "\n",
    "        return wav.squeeze(0), label\n",
    "\n",
    "# ============================================================\n",
    "# EER FUNCTION (FOR CM SYSTEM)\n",
    "# ============================================================\n",
    "\n",
    "def calculate_EER(labels, scores):\n",
    "    \"\"\"Equal Error Rate for Countermeasure system (bonafide=1, spoof=0).\"\"\"\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, scores, pos_label=1)\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    return eer\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# t-DCF FUNCTION (CM-only version using reference ASV parameters)\n",
    "# ============================================================\n",
    "\n",
    "def compute_tDCF(bonafide_score_cm, spoof_score_cm, Pfa_asv, Pmiss_asv, Pfa_spoof_asv, cost_model):\n",
    "    # 1. Compute CM miss/false-alarm rates for thresholds\n",
    "    cm_scores = np.concatenate([bonafide_score_cm, spoof_score_cm])\n",
    "    labels = np.concatenate([np.ones_like(bonafide_score_cm), np.zeros_like(spoof_score_cm)])\n",
    "    sorted_idx = np.argsort(cm_scores)[::-1]\n",
    "    sorted_labels = labels[sorted_idx]\n",
    "\n",
    "    tar = np.sum(sorted_labels)\n",
    "    non = len(sorted_labels) - tar\n",
    "\n",
    "    cm_miss = np.cumsum(sorted_labels == 1) / tar\n",
    "    cm_fa = np.cumsum(sorted_labels == 0) / non\n",
    "\n",
    "    # 2. Compute t-DCF per threshold\n",
    "    Cmiss, Cfa, Cfa_spoof = cost_model['Cmiss'], cost_model['Cfa'], cost_model['Cfa_spoof']\n",
    "    Ptar, Pnon, Pspoof = cost_model['Ptar'], cost_model['Pnon'], cost_model['Pspoof']\n",
    "\n",
    "    tDCF = (Cmiss * Ptar * Pmiss_asv * (1 - cm_miss) +\n",
    "            Cfa * Pnon * Pfa_asv * cm_fa +\n",
    "            Cfa_spoof * Pspoof * Pfa_spoof_asv * (1 - cm_miss)) / (\n",
    "            Cmiss * Ptar * Pmiss_asv + Cfa * Pnon * Pfa_asv)\n",
    "\n",
    "    tDCF_norm = tDCF / np.min(tDCF)\n",
    "    thresholds = cm_scores[sorted_idx]\n",
    "\n",
    "    return tDCF_norm, thresholds\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN + VALIDATE + TEST LOOP\n",
    "# ============================================================\n",
    "\n",
    "sys_cfg = SysConfig()\n",
    "exp_cfg = ExpConfig()\n",
    "\n",
    "train_ds = ASVspoofFolderDataset(sys_cfg.path_train, exp_cfg.sample_rate, exp_cfg.train_duration_sec)\n",
    "val_ds   = ASVspoofFolderDataset(sys_cfg.path_dev, exp_cfg.sample_rate, exp_cfg.test_duration_sec)\n",
    "test_ds  = ASVspoofFolderDataset(sys_cfg.path_test, exp_cfg.sample_rate, exp_cfg.test_duration_sec)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=exp_cfg.batch_size, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds, batch_size=exp_cfg.batch_size, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds, batch_size=exp_cfg.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# --- your modules ---\n",
    "pre = PreEmphasis(exp_cfg.pre_emphasis).to(DEVICE)\n",
    "model = Rawformer_S(device=DEVICE, transformer_hidden=exp_cfg.transformer_hidden, sample_rate=exp_cfg.sample_rate).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=exp_cfg.lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "best_val_eer = 1.0  # initialize high value\n",
    "\n",
    "print(\"üöÄ Starting training...\\n\")\n",
    "\n",
    "# Reference ASV parameters (official ASVspoof setup)\n",
    "Pfa_asv = 0.0005\n",
    "Pmiss_asv = 0.05\n",
    "Pmiss_spoof_asv = 0.95\n",
    "Pfa_spoof_asv = 1.0 - Pmiss_spoof_asv\n",
    "cost_model = {\n",
    "    'Ptar': 0.9801,\n",
    "    'Pnon': 0.0099,\n",
    "    'Pspoof': 0.0100,\n",
    "    'Cmiss': 1,\n",
    "    'Cfa': 10,\n",
    "    'Cfa_spoof': 10\n",
    "}\n",
    "\n",
    "for epoch in range(1, exp_cfg.epochs + 1):\n",
    "    # === TRAIN ===\n",
    "    model.train()\n",
    "    total_loss, total_samples = 0.0, 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{exp_cfg.epochs} [Train]\", leave=True)\n",
    "\n",
    "    for wav, label in pbar:\n",
    "        wav, label = wav.to(DEVICE), label.to(DEVICE)\n",
    "        wav = pre(wav)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        pred = model(wav).squeeze(-1)\n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        bs = wav.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_samples += bs\n",
    "        pbar.set_postfix(loss=f\"{total_loss / total_samples:.4f}\")\n",
    "\n",
    "    avg_train_loss = total_loss / total_samples\n",
    "\n",
    "    # === VALIDATE ===\n",
    "    model.eval()\n",
    "    val_loss, val_samples = 0.0, 0\n",
    "    all_scores, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=f\"Epoch {epoch}/{exp_cfg.epochs} [Val]\", leave=True)\n",
    "        for wav, label in pbar:\n",
    "            wav, label = wav.to(DEVICE), label.to(DEVICE)\n",
    "            wav = pre(wav)\n",
    "            pred = model(wav).squeeze(-1)\n",
    "            loss = criterion(pred, label)\n",
    "\n",
    "            bs = wav.size(0)\n",
    "            val_loss += loss.item() * bs\n",
    "            val_samples += bs\n",
    "\n",
    "            all_scores.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / val_samples\n",
    "    eer = calculate_EER(all_labels, all_scores)\n",
    "\n",
    "    # --- Compute t-DCF ---\n",
    "    bona_cm = np.array(all_scores)[np.array(all_labels) == 1]\n",
    "    spoof_cm = np.array(all_scores)[np.array(all_labels) == 0]\n",
    "    tDCF_curve, thr = compute_tDCF(bona_cm, spoof_cm, Pfa_asv, Pmiss_asv, Pfa_spoof_asv, cost_model)\n",
    "    min_tDCF = np.min(tDCF_curve)\n",
    "\n",
    "    print(f\"üßæ Epoch {epoch} Summary:\")\n",
    "    print(f\"   Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"   Val Loss:   {avg_val_loss:.4f}\")\n",
    "    print(f\"   Val EER:    {eer * 100:.2f}%\")\n",
    "    print(f\"   min-tDCF:   {min_tDCF:.4f}\")\n",
    "\n",
    "    # === SAVE BEST MODEL ===\n",
    "    if eer < best_val_eer:\n",
    "        best_val_eer = eer\n",
    "        torch.save(model, save_path)\n",
    "        print(f\"üíæ Saved new best model (EER={eer*100:.2f}%) to {save_path}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FINAL TEST PHASE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üèÅ Starting final testing...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load best model\n",
    "best_model = torch.load(save_path, map_location=DEVICE)\n",
    "best_model.eval()\n",
    "\n",
    "test_scores, test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(test_loader, desc=\"Testing\", leave=True)\n",
    "    for wav, label in pbar:\n",
    "        wav, label = wav.to(DEVICE), label.to(DEVICE)\n",
    "        wav = pre(wav)\n",
    "        pred = best_model(wav).squeeze(-1)\n",
    "        test_scores.extend(pred.cpu().numpy())\n",
    "        test_labels.extend(label.cpu().numpy())\n",
    "\n",
    "test_eer = calculate_EER(test_labels, test_scores)\n",
    "\n",
    "bona_cm = np.array(test_scores)[np.array(test_labels) == 1]\n",
    "spoof_cm = np.array(test_scores)[np.array(test_labels) == 0]\n",
    "tDCF_curve, thr = compute_tDCF(bona_cm, spoof_cm, Pfa_asv, Pmiss_asv, Pfa_spoof_asv, cost_model)\n",
    "min_tDCF = np.min(tDCF_curve)\n",
    "\n",
    "print(f\"üéØ Final Test EER:  {test_eer * 100:.2f}%\")\n",
    "print(f\"üìä Final min-tDCF: {min_tDCF:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL PARAMETER SUMMARY\n",
      "============================================================\n",
      "Trainable params         : 345,342\n",
      "Total params             : 345,342\n",
      "Model size (MiB)         : 1.32\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::exp encountered 73 time(s)\n",
      "Unsupported operator aten::sub encountered 6 time(s)\n",
      "Unsupported operator aten::abs encountered 211 time(s)\n",
      "Unsupported operator aten::div encountered 286 time(s)\n",
      "Unsupported operator aten::pow encountered 70 time(s)\n",
      "Unsupported operator aten::mul encountered 497 time(s)\n",
      "Unsupported operator aten::cos encountered 70 time(s)\n",
      "Unsupported operator aten::sum encountered 70 time(s)\n",
      "Unsupported operator aten::add encountered 87 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 5 time(s)\n",
      "Unsupported operator aten::selu_ encountered 8 time(s)\n",
      "Unsupported operator aten::softmax encountered 3 time(s)\n",
      "Unsupported operator aten::mean encountered 4 time(s)\n",
      "Unsupported operator aten::var encountered 4 time(s)\n",
      "Unsupported operator aten::sqrt encountered 4 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 1 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FLOPs / MACs (per forward pass)\n",
      "============================================================\n",
      "Input shape              : [1, 64000]\n",
      "MACs                     : 6.197 G\n",
      "FLOPs                    : 12.394 G\n",
      "============================================================\n",
      "\n",
      "Detailed layer-wise breakdown (torchinfo):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================================================================================================================================================================\n",
       "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "================================================================================================================================================================\n",
       "Rawformer_S                                                  [1, 64000]                [1]                       --                        --\n",
       "‚îú‚îÄFrontend_S: 1-1                                            [1, 64000]                [1, 64, 23, 16]           --                        --\n",
       "‚îÇ    ‚îî‚îÄLearnableGammatone: 2-1                               [1, 1, 64000]             [1, 70, 64000]            210                       --\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                                      [1, 1, 23, 21333]         [1, 1, 23, 21333]         2                         2\n",
       "‚îÇ    ‚îî‚îÄSELU: 2-3                                             [1, 1, 23, 21333]         [1, 1, 23, 21333]         --                        --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-4                                       [1, 1, 23, 21333]         [1, 64, 23, 16]           --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2DBlock_S: 3-1                               [1, 1, 23, 21333]         [1, 32, 23, 3555]         --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-1                                 [1, 1, 23, 21333]         [1, 32, 23, 21333]        128                       62,804,352\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-2                             [1, 1, 23, 21333]         [1, 32, 23, 21333]        6,592                     3,210,531,232\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 4-3                              [1, 32, 23, 21333]        [1, 32, 23, 3555]         --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2DBlock_S: 3-2                               [1, 32, 23, 3555]         [1, 32, 23, 592]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-4                             [1, 32, 23, 3555]         [1, 32, 23, 3555]         64                        64\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-5                             [1, 32, 23, 3555]         [1, 32, 23, 3555]         16,512                    1,381,387,744\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 4-6                              [1, 32, 23, 3555]         [1, 32, 23, 592]          --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2DBlock_S: 3-3                               [1, 32, 23, 592]          [1, 64, 23, 98]           --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 4-7                                 [1, 32, 23, 592]          [1, 64, 23, 592]          6,208                     84,528,128\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-8                             [1, 32, 23, 592]          [1, 32, 23, 592]          64                        64\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-9                             [1, 32, 23, 592]          [1, 64, 23, 592]          45,312                    627,387,520\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 4-10                             [1, 64, 23, 592]          [1, 64, 23, 98]           --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2DBlock_S: 3-4                               [1, 64, 23, 98]           [1, 64, 23, 16]           --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-11                            [1, 64, 23, 98]           [1, 64, 23, 98]           128                       128\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 4-12                            [1, 64, 23, 98]           [1, 64, 23, 98]           65,792                    152,027,136\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool2d: 4-13                             [1, 64, 23, 98]           [1, 64, 23, 16]           --                        --\n",
       "‚îú‚îÄPositionalAggregator1D: 1-2                                [1, 64, 23, 16]           [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îî‚îÄFlatten: 2-5                                          [1, 64, 23, 16]           [1, 64, 368]              --                        --\n",
       "‚îú‚îÄRawformerClassifier: 1-3                                   [1, 368, 64]              [1]                       --                        --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-6                                       [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerEncoderLayer: 3-5                     [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMultiHeadAttention: 4-14                    [1, 368, 64]              [1, 368, 64]              16,640                    16,640\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-15                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-16                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄFFN: 4-17                                   [1, 368, 64]              [1, 368, 64]              85,204                    85,204\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-18                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-19                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄTransformerEncoderLayer: 3-6                     [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄMultiHeadAttention: 4-20                    [1, 368, 64]              [1, 368, 64]              16,640                    16,640\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-21                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-22                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄFFN: 4-23                                   [1, 368, 64]              [1, 368, 64]              85,204                    85,204\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 4-24                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 4-25                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "‚îÇ    ‚îî‚îÄSequencePooling: 2-7                                  [1, 368, 64]              [1, 64]                   --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLinear: 3-7                                      [1, 368, 64]              [1, 368, 1]               65                        65\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-8                                           [1, 64]                   [1, 1]                    65                        65\n",
       "================================================================================================================================================================\n",
       "Total params: 345,342\n",
       "Trainable params: 345,342\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.52\n",
       "================================================================================================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 681.89\n",
       "Params size (MB): 1.38\n",
       "Estimated Total Size (MB): 683.53\n",
       "================================================================================================================================================================"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "#  Model size & FLOPs (place this right after model creation)\n",
    "# --------------------------------------------------------------\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1. Parameter count (trainable + non-trainable) + size in MiB\n",
    "# --------------------------------------------------------------\n",
    "def print_model_params(model):\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total     = sum(p.numel() for p in model.parameters())\n",
    "    size_mb   = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024**2)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL PARAMETER SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Trainable params':<25}: {trainable:,}\")\n",
    "    print(f\"{'Total params'    :<25}: {total:,}\")\n",
    "    print(f\"{'Model size (MiB)':<25}: {size_mb:.2f}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "print_model_params(model)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2. FLOPs / MACs\n",
    "# --------------------------------------------------------------\n",
    "# We need a dummy waveform that matches the shape expected by the model.\n",
    "#   - Rawformer_S expects raw audio: (batch, time)\n",
    "#   - Use the maximum length defined in the config (or a typical 4-second clip)\n",
    "max_len_sec = getattr(exp_cfg, \"max_len_sec\", 4.0)          # fallback 4 s\n",
    "max_samples = int(exp_cfg.sample_rate * max_len_sec)\n",
    "\n",
    "dummy_wav = torch.randn(1, max_samples, device=DEVICE)     # (B, T)\n",
    "\n",
    "# Apply pre-emphasis if it is used in training/validation\n",
    "if pre is not None:\n",
    "    dummy_wav = pre(dummy_wav)\n",
    "\n",
    "# ---- fvcore (very accurate) ----\n",
    "flops = FlopCountAnalysis(model, dummy_wav)\n",
    "macs  = flops.total()                # MACs = multiply-adds\n",
    "flops_2 = macs * 2                   # FLOPs = 2 √ó MACs (standard convention)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FLOPs / MACs (per forward pass)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Input shape'   :<25}: {list(dummy_wav.shape)}\")\n",
    "print(f\"{'MACs'          :<25}: {macs/1e9:.3f} G\")\n",
    "print(f\"{'FLOPs'         :<25}: {flops_2/1e9:.3f} G\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# ---- torchinfo (nice table, optional) ----\n",
    "print(\"Detailed layer-wise breakdown (torchinfo):\")\n",
    "summary(model,\n",
    "        input_data=dummy_wav,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n",
    "        depth=4,\n",
    "        verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFLOPs per second of audio : 3.099\n"
     ]
    }
   ],
   "source": [
    "seconds = max_samples / exp_cfg.sample_rate\n",
    "print(f\"GFLOPs per second of audio : {flops_2/1e9/seconds:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8621024,
     "sourceId": 13570789,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "AA_MP_env",
   "language": "python",
   "name": "aa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
