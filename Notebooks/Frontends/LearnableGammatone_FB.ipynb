{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.249141Z",
     "iopub.status.busy": "2025-11-25T05:39:06.248208Z",
     "iopub.status.idle": "2025-11-25T05:39:06.254138Z",
     "shell.execute_reply": "2025-11-25T05:39:06.253422Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.249113Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU count: 1\n",
      "[0] NVIDIA GeForce RTX 4090\n",
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU count:\", torch.cuda.device_count())\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"[{i}] {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.255498Z",
     "iopub.status.busy": "2025-11-25T05:39:06.255272Z",
     "iopub.status.idle": "2025-11-25T05:39:06.269640Z",
     "shell.execute_reply": "2025-11-25T05:39:06.268912Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.255482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Optional, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.270636Z",
     "iopub.status.busy": "2025-11-25T05:39:06.270399Z",
     "iopub.status.idle": "2025-11-25T05:39:06.283470Z",
     "shell.execute_reply": "2025-11-25T05:39:06.282660Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.270619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Optional (nice for shapes):\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    HAS_TORCHINFO = True\n",
    "except Exception:\n",
    "    HAS_TORCHINFO = False\n",
    "\n",
    "save_path = r\"C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\wavelet_best_cm_model.pth\"\n",
    "# ------------------ Configurable Paths ------------------ #\n",
    "class SysConfig:\n",
    "    \"\"\"\n",
    "    Folder-based dataset structure.\n",
    "    Each split (train/dev/test) contains two subfolders: bonafide and spoof.\n",
    "    \"\"\"\n",
    "    path_train =r\"G:\\INTERSPEECH_26\\LA\\ASV19\\train\"\n",
    "    path_dev   = r\"G:\\INTERSPEECH_26\\LA\\ASV19\\dev\"\n",
    "    path_test  =r\"G:\\INTERSPEECH_26\\LA\\ASV19\\dev\"\n",
    "\n",
    "\n",
    "# ------------------ Experiment Hyperparameters ------------------ #\n",
    "class ExpConfig:\n",
    "    # Audio processing\n",
    "    sample_rate = 16000\n",
    "    pre_emphasis = 0.97\n",
    "    train_duration_sec = 4\n",
    "    test_duration_sec = 4\n",
    "\n",
    "    # Model\n",
    "    transformer_hidden = 660\n",
    "\n",
    "    # Training hyperparameters\n",
    "    batch_size = 32\n",
    "    lr = 8*1e-4\n",
    "    epochs = 50  # increase as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.285135Z",
     "iopub.status.busy": "2025-11-25T05:39:06.284848Z",
     "iopub.status.idle": "2025-11-25T05:39:06.297266Z",
     "shell.execute_reply": "2025-11-25T05:39:06.296506Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.285118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch_audiomentations import (\n",
    "        Compose, AddColoredNoise, HighPassFilter, LowPassFilter, Gain\n",
    "    )\n",
    "    HAS_TA = True\n",
    "except Exception:\n",
    "    HAS_TA = False\n",
    "    Compose = AddColoredNoise = HighPassFilter = LowPassFilter = Gain = None\n",
    "\n",
    "class WaveformAugmentation(nn.Module):\n",
    "    def __init__(self, aug_list=('ACN', 'HPF', 'LPF', 'GAN'), sr=16000):\n",
    "        super().__init__()\n",
    "        self.sr = sr\n",
    "        if HAS_TA:\n",
    "            transforms = []\n",
    "            if 'ACN' in aug_list:\n",
    "                transforms.append(AddColoredNoise(10, 40, -2.0, 2.0, p=0.5))\n",
    "            if 'HPF' in aug_list:\n",
    "                transforms.append(HighPassFilter(20.0, 2400.0, p=0.5))\n",
    "            if 'LPF' in aug_list:\n",
    "                transforms.append(LowPassFilter(150.0, 7500.0, p=0.5))\n",
    "            if 'GAN' in aug_list:\n",
    "                transforms.append(Gain(-15.0, 5.0, p=0.5))\n",
    "            self.apply_augmentation = Compose(transforms) if transforms else None\n",
    "        else:\n",
    "            # No-op if torch_audiomentations isn't available\n",
    "            self.apply_augmentation = None\n",
    "\n",
    "    def forward(self, wav: torch.Tensor) -> torch.Tensor:\n",
    "        # wav: (B, T)\n",
    "        if self.apply_augmentation is None:\n",
    "            return wav\n",
    "        return self.apply_augmentation(wav.unsqueeze(1), self.sr).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.298208Z",
     "iopub.status.busy": "2025-11-25T05:39:06.298026Z",
     "iopub.status.idle": "2025-11-25T05:39:06.313209Z",
     "shell.execute_reply": "2025-11-25T05:39:06.312551Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.298194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PreEmphasis(nn.Module):\n",
    "    def __init__(self, pre_emphasis: float = 0.97):\n",
    "        super().__init__()\n",
    "        # Conv1D filter shape: (out_channels=1, in_channels=1, kernel_size=2)\n",
    "        filt = torch.tensor([[-pre_emphasis, 1.0]], dtype=torch.float32).unsqueeze(0)\n",
    "        self.register_buffer(\"filter\", filt)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, T)\n",
    "        x = x.unsqueeze(1)  # (B,1,T)\n",
    "        x = F.pad(x, (1, 0), mode=\"reflect\")\n",
    "        x = F.conv1d(x, self.filter)\n",
    "        return x.squeeze(1)  # (B,T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.367527Z",
     "iopub.status.busy": "2025-11-25T05:39:06.366858Z",
     "iopub.status.idle": "2025-11-25T05:39:06.383374Z",
     "shell.execute_reply": "2025-11-25T05:39:06.382605Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.367502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SincConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from AASIST. One input channel only.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def to_mel(hz): return 2595 * np.log10(1 + hz / 700)\n",
    "    @staticmethod\n",
    "    def to_hz(mel): return 700 * (10**(mel / 2595) - 1)\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1, stride=1, padding=0, dilation=1):\n",
    "        super().__init__()\n",
    "        if in_channels != 1:\n",
    "            raise ValueError(\"SincConv supports only one input channel.\")\n",
    "        self.out_channels = out_channels\n",
    "        self.sample_rate = sample_rate\n",
    "        self.kernel_size = kernel_size + (kernel_size % 2 == 0)\n",
    "\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        NFFT = 512\n",
    "        f = int(sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        fmel = self.to_mel(f)\n",
    "        filbandwidthsmel = np.linspace(fmel.min(), fmel.max(), out_channels + 1)\n",
    "        filbandwidthsf = self.to_hz(filbandwidthsmel)\n",
    "\n",
    "        self.hsupp = torch.arange(-(self.kernel_size - 1) / 2,\n",
    "                                  (self.kernel_size - 1) / 2 + 1)\n",
    "\n",
    "        band_pass = torch.zeros(out_channels, self.kernel_size)\n",
    "        for i in range(out_channels):\n",
    "            fmin, fmax = filbandwidthsf[i], filbandwidthsf[i + 1]\n",
    "            hHigh = (2 * fmax / sample_rate) * np.sinc(2 * fmax * self.hsupp / sample_rate)\n",
    "            hLow  = (2 * fmin / sample_rate) * np.sinc(2 * fmin * self.hsupp / sample_rate)\n",
    "            hideal = hHigh - hLow\n",
    "            band_pass[i, :] = torch.tensor(np.hamming(self.kernel_size)) * torch.tensor(hideal)\n",
    "        self.register_buffer(\"band_pass\", band_pass)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,1,T)\n",
    "        filt = self.band_pass.to(x.device).view(self.out_channels, 1, self.kernel_size)\n",
    "        return F.conv1d(x, filt, stride=self.stride, padding=self.padding, dilation=self.dilation, groups=1)\n",
    "\n",
    "class LearnableSincConv(nn.Module):\n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10**(mel / 2595) - 1)\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1,\n",
    "                 stride=1, padding=0, dilation=1, bias=False, min_low_hz=50, min_band_hz=50):\n",
    "        super().__init__()\n",
    "        if in_channels != 1:\n",
    "            raise ValueError(f\"SincConv only supports one input channel, got {in_channels}\")\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.min_low_hz = min_low_hz\n",
    "        self.min_band_hz = min_band_hz\n",
    "\n",
    "        # Mel-scale initialization\n",
    "        NFFT = 512\n",
    "        f = np.linspace(0, sample_rate / 2, int(NFFT / 2) + 1)\n",
    "        fmel = self.to_mel(f)\n",
    "        mel_points = np.linspace(fmel.min(), fmel.max(), out_channels + 1)\n",
    "        hz_points = self.to_hz(mel_points)\n",
    "\n",
    "        # Initialize learnable parameters for low cutoff and bandwidth\n",
    "        low_hz = hz_points[:-1]\n",
    "        band_hz = np.diff(hz_points)\n",
    "\n",
    "        self.low_hz_ = nn.Parameter(torch.tensor(low_hz, dtype=torch.float32))\n",
    "        self.band_hz_ = nn.Parameter(torch.tensor(band_hz, dtype=torch.float32))\n",
    "\n",
    "        # Time axis for filter generation\n",
    "        n = torch.arange(-(kernel_size - 1) / 2, (kernel_size - 1) / 2 + 1)\n",
    "        self.register_buffer('n', n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        n = self.n.to(device)\n",
    "\n",
    "        # Enforce positive frequency constraints\n",
    "        low = self.min_low_hz + torch.abs(self.low_hz_)\n",
    "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_), self.min_low_hz, self.sample_rate / 2 - 1)\n",
    "\n",
    "        band = (high - low)[:, None]\n",
    "        f_times_t_low = 2 * np.pi * low[:, None] * n / self.sample_rate\n",
    "        f_times_t_high = 2 * np.pi * high[:, None] * n / self.sample_rate\n",
    "\n",
    "        # Compute filters using sinc functions\n",
    "        sinc_high = torch.sin(f_times_t_high) / (n / self.sample_rate + 1e-8)\n",
    "        sinc_low = torch.sin(f_times_t_low) / (n / self.sample_rate + 1e-8)\n",
    "        filters = sinc_high - sinc_low\n",
    "\n",
    "        # Apply window (Hamming)\n",
    "        window = 0.54 - 0.46 * torch.cos(2 * np.pi * (torch.arange(self.kernel_size).to(device)) / self.kernel_size)\n",
    "        filters = filters * window\n",
    "\n",
    "        # Normalize\n",
    "        filters = filters / (2 * band)\n",
    "\n",
    "        filters = filters.view(self.out_channels, 1, self.kernel_size)\n",
    "        return F.conv1d(x, filters, stride=self.stride, padding=self.padding)\n",
    "\n",
    "class AdaptiveGaborConv(nn.Module):\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1):\n",
    "        super().__init__()\n",
    "        if in_channels != 1:\n",
    "            raise ValueError(\"GaborConv only supports 1 input channel\")\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1  # ensure odd kernel size\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        # Time support\n",
    "        self.t = torch.arange(-(kernel_size - 1) / 2, (kernel_size - 1) / 2 + 1, dtype=torch.float32) / sample_rate  # [kernel_size]\n",
    "\n",
    "        # Mel-scale initialization for center frequencies\n",
    "        NFFT = 512\n",
    "        f = np.linspace(0, sample_rate / 2, int(NFFT / 2) + 1)\n",
    "        mel = 2595 * np.log10(1 + f / 700)\n",
    "        mel_centers = np.linspace(mel.min(), mel.max(), out_channels)\n",
    "        hz_centers = 700 * (10 ** (mel_centers / 2595) - 1)\n",
    "        eta_init = hz_centers / sample_rate  # normalized center freqs [0–0.5]\n",
    "        self.eta = nn.Parameter(torch.tensor(eta_init, dtype=torch.float32))\n",
    "\n",
    "        # Adaptive bandwidths inversely proportional to frequency\n",
    "        base_sigma = (kernel_size / sample_rate) / 4  # base scale\n",
    "        sigma_init = base_sigma / (self.eta + 1e-4)   # inverse proportionality\n",
    "        sigma_init = torch.clamp(torch.tensor(sigma_init, dtype=torch.float32), 1e-4, 0.05)\n",
    "        self.sigma_scale = nn.Parameter(torch.ones(out_channels))  # learnable global scaling\n",
    "        self.register_buffer(\"sigma_init\", sigma_init)\n",
    "\n",
    "    def _create_filters(self, device):\n",
    "        t = self.t.to(device)                         # [kernel_size]\n",
    "        eta = torch.clamp(self.eta, 1e-4, 0.5)        # [out_channels]\n",
    "        sigma = (self.sigma_init.to(device) * self.sigma_scale).unsqueeze(1)  # [out_channels, 1]\n",
    "        eta = eta.unsqueeze(1)                        # [out_channels, 1]\n",
    "\n",
    "        # Gaussian window — broadcast over time\n",
    "        gaussian = torch.exp(-t[None, :]**2 / (2 * sigma**2)) / (np.sqrt(2 * np.pi) * sigma)\n",
    "\n",
    "        # Cosine/sine modulations\n",
    "        cos_component = torch.cos(2 * np.pi * eta * t[None, :])\n",
    "        sin_component = torch.sin(2 * np.pi * eta * t[None, :])\n",
    "\n",
    "        filters_real = gaussian * cos_component\n",
    "        filters_imag = gaussian * sin_component\n",
    "\n",
    "        filters = torch.cat([filters_real, filters_imag], dim=0)  # [2*out_channels, kernel_size]\n",
    "        filters = filters / (filters.abs().max(dim=1, keepdim=True)[0] + 1e-8)\n",
    "        return filters\n",
    "\n",
    "    def forward(self, x):\n",
    "        filters = self._create_filters(x.device)\n",
    "        filters = filters.view(2 * self.out_channels, 1, self.kernel_size)\n",
    "        padding = self.kernel_size // 2\n",
    "        out = F.conv1d(x, filters, stride=1, padding=padding)\n",
    "        real, imag = out[:, :self.out_channels, :], out[:, self.out_channels:, :]\n",
    "        magnitude = torch.sqrt(real**2 + imag**2 + 1e-8)\n",
    "        return magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.384721Z",
     "iopub.status.busy": "2025-11-25T05:39:06.384504Z",
     "iopub.status.idle": "2025-11-25T05:39:06.401701Z",
     "shell.execute_reply": "2025-11-25T05:39:06.400961Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.384705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Nice-to-have (optional)\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    HAS_TORCHINFO = True\n",
    "except Exception:\n",
    "    HAS_TORCHINFO = False\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Expects Q,K,V: (B, H, S, D). Optional mask: (B,1,1,S) or broadcastable.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, Q, K, V, mask: Optional[torch.Tensor] = None):\n",
    "        assert Q.dim() == K.dim() == V.dim() == 4  # (B,H,S,D)\n",
    "        d_k = K.size(-1)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)  # (B,H,S_q,S_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "        attn = self.softmax(scores)\n",
    "        out = torch.matmul(attn, V)  # (B,H,S_q,D)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, n_head: int):\n",
    "        super().__init__()\n",
    "        assert d_model % n_head == 0, \"d_model must be divisible by n_head\"\n",
    "        self.n_head = n_head\n",
    "        self.d_head = d_model // n_head\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_model)\n",
    "        self.W_K = nn.Linear(d_model, d_model)\n",
    "        self.W_V = nn.Linear(d_model, d_model)\n",
    "        self.attn = ScaledDotProductAttention()\n",
    "        self.W_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def _split_heads(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,S,D) -> (B,H,S,Dh)\n",
    "        B, S, D = x.size()\n",
    "        x = x.view(B, S, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
    "        return x\n",
    "\n",
    "    def _merge_heads(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,H,S,Dh) -> (B,S,D)\n",
    "        B, H, S, Dh = x.size()\n",
    "        return x.permute(0, 2, 1, 3).contiguous().view(B, S, H * Dh)\n",
    "\n",
    "    def forward(self, Q, K, V, mask: Optional[torch.Tensor] = None):\n",
    "        assert Q.dim() == K.dim() == V.dim() == 3  # (B,S,D)\n",
    "        q = self._split_heads(self.W_Q(Q))\n",
    "        k = self._split_heads(self.W_K(K))\n",
    "        v = self._split_heads(self.W_V(V))\n",
    "        if mask is not None:\n",
    "            # make mask broadcastable to (B,H,S_q,S_k)\n",
    "            mask = mask.unsqueeze(1)\n",
    "        context = self.attn(q, k, v, mask=mask)\n",
    "        context = self._merge_heads(context)\n",
    "        return self.W_out(context)\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-12):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, unbiased=False, keepdim=True)\n",
    "        xhat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.gamma * xhat + self.beta\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, ffn_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Linear(ffn_hidden, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model=64, n_head=8, ffn_hidden=2048, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, n_head)\n",
    "        self.dropout1 = nn.Dropout(drop_prob)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.ffn = FFN(d_model, ffn_hidden, drop_prob)\n",
    "        self.dropout2 = nn.Dropout(drop_prob)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, attn_mask: Optional[torch.Tensor] = None):\n",
    "        # x: (B,S,D)\n",
    "        residual = x\n",
    "        x = self.attn(x, x, x, mask=attn_mask)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + residual)\n",
    "\n",
    "        residual = x\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + residual)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TD (Time-Domain) Filterbank and Learnable Gammatone Filterbank\n",
    "PyTorch implementations intended as drop-in replacements for the SincConv layer.\n",
    "\n",
    "Both modules accept (B,1,T) raw waveform and return (B, out_channels, T').\n",
    "They are made fully drop-in compatible with a SincConv-style constructor\n",
    "(i.e. accept `in_channels=1`, `out_channels=...`, `kernel_size=...`, `sample_rate=...`).\n",
    "\"\"\"\n",
    "\n",
    "from typing import Optional\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# -------------------- helpers --------------------\n",
    "\n",
    "def hz_to_mel(hz: np.ndarray) -> np.ndarray:\n",
    "    return 2595.0 * np.log10(1.0 + hz / 700.0)\n",
    "\n",
    "\n",
    "def mel_to_hz(mel: np.ndarray) -> np.ndarray:\n",
    "    return 700.0 * (10 ** (mel / 2595.0) - 1.0)\n",
    "\n",
    "\n",
    "def windowed_sinc_impulse(kernel_size: int, sr: int, fmin: float, fmax: float) -> np.ndarray:\n",
    "    \"\"\"Return a single band-pass windowed-sinc impulse response (numpy array).\n",
    "    kernel_size must be odd.\n",
    "    \"\"\"\n",
    "    assert kernel_size % 2 == 1, \"kernel_size should be odd\"\n",
    "    t = np.arange(-(kernel_size - 1) / 2.0, (kernel_size - 1) / 2.0 + 1.0)\n",
    "    h_high = (2 * fmax / sr) * np.sinc(2 * fmax * t / sr)\n",
    "    h_low = (2 * fmin / sr) * np.sinc(2 * fmin * t / sr)\n",
    "    hideal = h_high - h_low\n",
    "    w = np.hamming(kernel_size)\n",
    "    return hideal * w\n",
    "\n",
    "\n",
    "# -------------------- TDFilterbank --------------------\n",
    "\n",
    "class TDFilterbank(nn.Module):\n",
    "    \"\"\"Time-Domain Filterbank (drop-in replacement for SincConv).\n",
    "\n",
    "    Accepts `in_channels` argument for API compatibility but only supports mono input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 1,          # dummy for compatibility (ignored)\n",
    "                 out_channels: int = 70,\n",
    "                 kernel_size: int = 129,\n",
    "                 sample_rate: int = 16000,\n",
    "                 learnable: bool = True,\n",
    "                 learnable_f: bool = True,\n",
    "                 min_low_hz: float = 30.0,\n",
    "                 min_band_hz: float = 50.0,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.learnable = learnable\n",
    "        self.learnable_f = learnable_f\n",
    "\n",
    "        # mel-spaced boundaries (numpy)\n",
    "        NFFT = 512\n",
    "        f = int(sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        fmel = hz_to_mel(f)\n",
    "        mel_bins = np.linspace(fmel.min(), fmel.max(), out_channels + 1)\n",
    "        hz_bins = mel_to_hz(mel_bins)\n",
    "\n",
    "        fmins = hz_bins[:-1].copy()\n",
    "        fmaxs = hz_bins[1:].copy()\n",
    "\n",
    "        # ensure minimum band\n",
    "        fmins = np.maximum(fmins, min_low_hz)\n",
    "        fmaxs = np.maximum(fmaxs, fmins + min_band_hz)\n",
    "\n",
    "        # init kernels (numpy) shape (out_channels, kernel_size)\n",
    "        init_kernels = np.zeros((out_channels, kernel_size), dtype=np.float32)\n",
    "        for i in range(out_channels):\n",
    "            init_kernels[i, :] = windowed_sinc_impulse(kernel_size, sample_rate, fmins[i], fmaxs[i])\n",
    "\n",
    "        # normalize\n",
    "        init_kernels /= np.maximum(np.abs(init_kernels).sum(axis=1, keepdims=True), 1e-8)\n",
    "\n",
    "        # store initial kernels or params depending on mode\n",
    "        if not learnable:\n",
    "            # fixed kernel bank (register buffer for zero-parameter behavior)\n",
    "            self.register_buffer('kernels', torch.tensor(init_kernels, dtype=torch.float32).unsqueeze(1))\n",
    "            return\n",
    "\n",
    "        if learnable_f:\n",
    "            centres = (fmins + fmaxs) / 2.0\n",
    "            bws = (fmaxs - fmins)\n",
    "\n",
    "            self.log_centres = nn.Parameter(torch.log(torch.tensor(centres + 1.0, dtype=torch.float32)))\n",
    "            self.log_bws = nn.Parameter(torch.log(torch.tensor(bws + 1.0, dtype=torch.float32)))\n",
    "            self.register_buffer('kernel_window_ref', torch.tensor(init_kernels, dtype=torch.float32))\n",
    "        else:\n",
    "            # learn full kernels (Conv1d-like)\n",
    "            self.kernels_param = nn.Parameter(torch.tensor(init_kernels, dtype=torch.float32).unsqueeze(1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B,1,T)\n",
    "        returns: (B, out_channels, T')\n",
    "        \"\"\"\n",
    "        if not self.learnable:\n",
    "            return F.conv1d(x, self.kernels.to(x.device), stride=1, padding=(self.kernel_size - 1) // 2)\n",
    "\n",
    "        if self.learnable_f:\n",
    "            device = x.device\n",
    "            centres = torch.exp(self.log_centres).to(device) - 1.0\n",
    "            bws = torch.exp(self.log_bws).to(device) - 1.0\n",
    "\n",
    "            fmin = centres - 0.5 * bws\n",
    "            fmax = centres + 0.5 * bws\n",
    "\n",
    "            # clamp ranges safely using tensor ops (avoid mixing tensor/scalar in positional args)\n",
    "            max_freq_tensor = (self.sample_rate / 2.0) * torch.ones_like(fmax, device=device)\n",
    "            fmin = torch.clamp(fmin, min=1.0)\n",
    "            fmin = torch.min(fmin, max_freq_tensor - 2.0)\n",
    "            fmax = torch.max(fmax, fmin + 1.0)\n",
    "            fmax = torch.min(fmax, max_freq_tensor)\n",
    "\n",
    "            # time vector (device)\n",
    "            t = torch.linspace(\n",
    "                -(self.kernel_size - 1) / 2.0,\n",
    "                (self.kernel_size - 1) / 2.0,\n",
    "                steps=self.kernel_size,\n",
    "                device=device,\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "\n",
    "            kernels = []\n",
    "            # build each kernel on-device\n",
    "            for i in range(self.out_channels):\n",
    "                hi = (2.0 * fmax[i] / self.sample_rate) * torch.sinc(2.0 * fmax[i] * t / self.sample_rate)\n",
    "                lo = (2.0 * fmin[i] / self.sample_rate) * torch.sinc(2.0 * fmin[i] * t / self.sample_rate)\n",
    "\n",
    "                h = hi - lo\n",
    "                h = h * torch.hamming_window(self.kernel_size, periodic=False, device=device, dtype=torch.float32)\n",
    "                h = h / (h.abs().sum() + 1e-8)\n",
    "                kernels.append(h)\n",
    "\n",
    "            kernels = torch.stack(kernels, dim=0).unsqueeze(1)  # (out,1,k)\n",
    "            return F.conv1d(x, kernels, stride=1, padding=(self.kernel_size - 1) // 2)\n",
    "\n",
    "        # learn full kernels branch\n",
    "        return F.conv1d(x, self.kernels_param.to(x.device), stride=1, padding=(self.kernel_size - 1) // 2)\n",
    "\n",
    "\n",
    "# -------------------- Learnable Gammatone Filterbank --------------------\n",
    "\n",
    "class LearnableGammatone(nn.Module):\n",
    "    \"\"\"Learnable Gammatone Filterbank (drop-in compatible).\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 1,         # dummy for compatibility (ignored)\n",
    "                 out_channels: int = 70,\n",
    "                 kernel_size: int = 129,\n",
    "                 sample_rate: int = 16000,\n",
    "                 n: int = 4,\n",
    "                 min_freq: float = 30.0,\n",
    "                 max_freq: Optional[float] = None,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n = n\n",
    "        self.max_freq = max_freq or sample_rate / 2.0\n",
    "\n",
    "        # mel spaced centres (numpy)\n",
    "        NFFT = 512\n",
    "        f = int(sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        mel = hz_to_mel(f)\n",
    "        mel_bins = np.linspace(mel.min(), mel.max(), out_channels)\n",
    "        centres = mel_to_hz(mel_bins)\n",
    "        centres = np.clip(centres, min_freq, self.max_freq - 10.0)\n",
    "\n",
    "        # ERB approx\n",
    "        erb = 24.7 + 0.108 * centres\n",
    "\n",
    "        self.log_centres = nn.Parameter(torch.log(torch.tensor(centres + 1.0, dtype=torch.float32)))\n",
    "        self.log_band = nn.Parameter(torch.log(torch.tensor(erb + 1.0, dtype=torch.float32)))\n",
    "\n",
    "        self.log_amp = nn.Parameter(torch.zeros(out_channels, dtype=torch.float32))\n",
    "\n",
    "        t = np.arange(kernel_size, dtype=np.float32) - (kernel_size - 1) / 2.0\n",
    "        self.register_buffer(\"t\", torch.tensor(t, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B,1,T)\n",
    "        returns: (B, out_channels, T')\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "\n",
    "        centres = torch.exp(self.log_centres).to(device) - 1.0\n",
    "        band = torch.exp(self.log_band).to(device) - 1.0\n",
    "        amp = torch.exp(self.log_amp).to(device)\n",
    "\n",
    "        centres = torch.clamp(centres, 20.0, self.max_freq - 1.0)\n",
    "        band = torch.clamp(band, 1.0, self.sample_rate / 4.0)\n",
    "\n",
    "        t = self.t.to(device)\n",
    "        kernels = []\n",
    "\n",
    "        for i in range(self.out_channels):\n",
    "            fc = centres[i]\n",
    "            b = band[i]\n",
    "            a = amp[i]\n",
    "\n",
    "            tp = t  # centered time vector\n",
    "\n",
    "            env = (tp.abs() / self.sample_rate) ** (self.n - 1)\n",
    "            env = env * torch.exp(-2.0 * math.pi * b * tp.abs() / self.sample_rate)\n",
    "            carrier = torch.cos(2.0 * math.pi * fc * tp / self.sample_rate)\n",
    "\n",
    "            g = a * env * carrier\n",
    "            g = g / (g.abs().sum() + 1e-8)\n",
    "\n",
    "            kernels.append(g)\n",
    "\n",
    "        kernels = torch.stack(kernels, dim=0).unsqueeze(1)\n",
    "        return F.conv1d(x, kernels.to(device), stride=1, padding=(self.kernel_size - 1) // 2)\n",
    "\n",
    "\"\"\"\n",
    "WTConv — Learnable Wavelet Filterbank\n",
    "--------------------------------------\n",
    "\n",
    "A drop-in front-end like SincConv, TDFilterbank, and LearnableGammatone, but\n",
    "using complex Morlet wavelets.\n",
    "\n",
    "Features:\n",
    "- Complex-valued wavelets (real + imaginary)\n",
    "- Learnable center-frequency, bandwidth(gamma), and complex phase\n",
    "- Output is magnitude sqrt(real^2 + imag^2)\n",
    "- Accepts (B,1,T) raw waveform\n",
    "- Returns (B,out_channels,T')\n",
    "\n",
    "Reference wavelet:\n",
    "    ψ(t) = exp(-t^2 / (2σ^2)) * exp(j 2π f_c t)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "class WTConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 1,\n",
    "                 out_channels: int = 70,\n",
    "                 kernel_size: int = 129,\n",
    "                 sample_rate: int = 16000,\n",
    "                 min_freq: float = 30.0,\n",
    "                 max_freq: float = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.max_freq = max_freq or (sample_rate / 2)\n",
    "\n",
    "        # -------- mel-spaced frequency initialization --------\n",
    "        NFFT = 512\n",
    "        f = np.linspace(0, sample_rate / 2, NFFT // 2 + 1)\n",
    "        mel = 2595 * np.log10(1 + f / 700)\n",
    "        mel_bins = np.linspace(mel.min(), mel.max(), out_channels)\n",
    "        centres = 700 * (10**(mel_bins / 2595) - 1)\n",
    "        centres = np.clip(centres, min_freq, self.max_freq - 10)\n",
    "\n",
    "        # bandwidth initialization (similar to ERB)\n",
    "        erb = 24.7 + 0.108 * centres\n",
    "\n",
    "        # parameters (log space for stability)\n",
    "        self.log_centres = nn.Parameter(torch.log(torch.tensor(centres + 1.0, dtype=torch.float32)))\n",
    "        self.log_band = nn.Parameter(torch.log(torch.tensor(erb + 1.0, dtype=torch.float32)))\n",
    "\n",
    "        # learnable phase (complex)\n",
    "        self.phase = nn.Parameter(torch.zeros(out_channels))\n",
    "\n",
    "        # centered time vector\n",
    "        t = np.arange(kernel_size, dtype=np.float32) - (kernel_size - 1) / 2\n",
    "        self.register_buffer(\"t\", torch.tensor(t, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: (B,1,T)\n",
    "        returns: (B,out_channels,T')\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "\n",
    "        # get params\n",
    "        fc = torch.exp(self.log_centres).to(device) - 1.0\n",
    "        bw = torch.exp(self.log_band).to(device) - 1.0\n",
    "        phase = self.phase.to(device)\n",
    "\n",
    "        fc = torch.clamp(fc, 20.0, self.max_freq - 1.0)\n",
    "        bw = torch.clamp(bw, 1.0, self.sample_rate / 4)\n",
    "\n",
    "        # time vector on device\n",
    "        t = self.t.to(device)\n",
    "\n",
    "        # Build wavelets\n",
    "        real_kernels = []\n",
    "        imag_kernels = []\n",
    "\n",
    "        for i in range(self.out_channels):\n",
    "            fci = fc[i]\n",
    "            bwi = bw[i]\n",
    "            ph = phase[i]\n",
    "\n",
    "            # Gaussian envelope\n",
    "            # sigma controls time spread: σ ≈ sample_rate/(2π*bw)\n",
    "            sigma = self.sample_rate / (2 * math.pi * bwi)\n",
    "            env = torch.exp(-t**2 / (2 * sigma**2))\n",
    "\n",
    "            # complex carrier\n",
    "            carrier_real = torch.cos(2 * math.pi * fci * t / self.sample_rate + ph)\n",
    "            carrier_imag = torch.sin(2 * math.pi * fci * t / self.sample_rate + ph)\n",
    "\n",
    "            # final Morlet wavelet kernel\n",
    "            real = env * carrier_real\n",
    "            imag = env * carrier_imag\n",
    "\n",
    "            # normalize\n",
    "            real = real / (real.abs().sum() + 1e-8)\n",
    "            imag = imag / (imag.abs().sum() + 1e-8)\n",
    "\n",
    "            real_kernels.append(real)\n",
    "            imag_kernels.append(imag)\n",
    "\n",
    "        real_kernels = torch.stack(real_kernels, dim=0).unsqueeze(1)  # (out,1,k)\n",
    "        imag_kernels = torch.stack(imag_kernels, dim=0).unsqueeze(1)\n",
    "\n",
    "        # Convolve real + imaginary parts\n",
    "        real_out = F.conv1d(x, real_kernels, stride=1, padding=(self.kernel_size - 1)//2)\n",
    "        imag_out = F.conv1d(x, imag_kernels, stride=1, padding=(self.kernel_size - 1)//2)\n",
    "\n",
    "        # Output magnitude of the analytic wavelet\n",
    "        out = torch.sqrt(real_out**2 + imag_out**2 + 1e-8)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.402828Z",
     "iopub.status.busy": "2025-11-25T05:39:06.402574Z",
     "iopub.status.idle": "2025-11-25T05:39:06.421502Z",
     "shell.execute_reply": "2025-11-25T05:39:06.420822Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.402805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Frontend_S\n",
    "# ----------------------------------------------------------------------\n",
    "class Frontend_S(nn.Module):\n",
    "    def __init__(self, device, sinc_kernel_size=128, sample_rate=16000):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---- Sinc layer (no parameters → safe on any device) ----\n",
    "        self.sinc_layer = WTConv(\n",
    "            in_channels=1,\n",
    "            out_channels=70,\n",
    "            kernel_size=sinc_kernel_size,\n",
    "            sample_rate=sample_rate,\n",
    "        )\n",
    "\n",
    "        # ---- BatchNorm that must live on the target device ----\n",
    "        self.bn = nn.BatchNorm2d(num_features=1).to(device)\n",
    "\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "\n",
    "        # ---- Conv blocks (they also contain BatchNorms) ----\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            Conv2DBlock_S(in_channels=1,  out_channels=32, is_first_block=True),\n",
    "            Conv2DBlock_S(in_channels=32, out_channels=32),\n",
    "            Conv2DBlock_S(in_channels=32, out_channels=64),\n",
    "            Conv2DBlock_S(in_channels=64, out_channels=64),\n",
    "        ).to(device)                     # <-- move the whole Sequential\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : [B, T]  (raw waveform)\n",
    "        x = x.unsqueeze(1)                     # [B,1,T]\n",
    "        x = self.sinc_layer(x)                 # [B,70,T']\n",
    "        x = x.unsqueeze(1)                     # [B,1,70,T']\n",
    "        x = F.max_pool2d(torch.abs(x), (3, 3)) # [B,1,F,T]\n",
    "        x = self.bn(x)\n",
    "        LFM = self.selu(x)\n",
    "\n",
    "        HFM = self.conv_blocks(LFM)            # [B,64,f,t]\n",
    "        return HFM\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Conv2DBlock_S\n",
    "# ----------------------------------------------------------------------\n",
    "class Conv2DBlock_S(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, is_first_block: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---- optional normaliser (BN+SELU) ----\n",
    "        self.normalizer = None\n",
    "        if not is_first_block:\n",
    "            self.normalizer = nn.Sequential(\n",
    "                nn.BatchNorm2d(in_channels),\n",
    "                nn.SELU(inplace=True),\n",
    "            )\n",
    "\n",
    "        # ---- two conv layers + BN+SELU ----\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(2, 5), padding=(1, 2)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SELU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(2, 3), padding=(0, 1)),\n",
    "        )\n",
    "\n",
    "        # ---- residual connection when channel count changes ----\n",
    "        self.downsampler = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsampler = nn.Conv2d(in_channels, out_channels,\n",
    "                                        kernel_size=(1, 3), padding=(0, 1))\n",
    "\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(1, 6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsampler is not None:\n",
    "            identity = self.downsampler(identity)\n",
    "\n",
    "        if self.normalizer is not None:\n",
    "            x = self.normalizer(x)\n",
    "\n",
    "        x = self.layers(x) + identity\n",
    "        x = self.pooling(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. PositionalAggregator1D\n",
    "# ----------------------------------------------------------------------\n",
    "class PositionalAggregator1D(nn.Module):\n",
    "    def __init__(self, max_C: int, max_ft: int, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.flattener = nn.Flatten(start_dim=-2, end_dim=-1)\n",
    "\n",
    "        # ----- sinusoidal positional encoding (no trainable params) -----\n",
    "        pos = torch.arange(1, max_ft - 1, device=device).float().unsqueeze(1)   # (L-2,1)\n",
    "        dim = torch.arange(0, max_C, step=2, device=device).float().unsqueeze(0)  # (1,D/2)\n",
    "\n",
    "        enc = torch.zeros(max_ft, max_C, device=device)\n",
    "        enc[1:-1, 0::2] = torch.sin(pos / (10000 ** (dim / max_C)))\n",
    "        enc[1:-1, 1::2] = torch.cos(pos / (10000 ** (dim / max_C)))\n",
    "        self.register_buffer('encoding', enc)   # stored on the correct device automatically\n",
    "\n",
    "    def forward(self, HFM):\n",
    "        \"\"\"\n",
    "        HFM : [B, C, f, t]\n",
    "        out : [B, f*t, C]  with added positional encoding\n",
    "        \"\"\"\n",
    "        B, C, f, t = HFM.shape\n",
    "        ft = f * t\n",
    "        out = self.flattener(HFM).transpose(1, 2)               # [B, f*t, C]\n",
    "        out = out + self.encoding[:ft, :C]                      # broadcast\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.423289Z",
     "iopub.status.busy": "2025-11-25T05:39:06.423059Z",
     "iopub.status.idle": "2025-11-25T05:39:06.437563Z",
     "shell.execute_reply": "2025-11-25T05:39:06.436811Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.423270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Rawformer_S(nn.Module):\n",
    "    def __init__(self, device, transformer_hidden=64, sample_rate: int = 16000):\n",
    "        super().__init__()\n",
    "        # ---- 1. give the front-end the device ----\n",
    "        self.front_end = Frontend_S(sinc_kernel_size=128,\n",
    "                                    sample_rate=sample_rate,\n",
    "                                    device=device)          # <-- add this\n",
    "\n",
    "        self.positional_embedding = PositionalAggregator1D(\n",
    "            max_C=64, max_ft=23*16, device=device)\n",
    "\n",
    "        self.classifier = RawformerClassifier(C=64, n_encoder=2, transformer_hidden=transformer_hidden)\n",
    "\n",
    "        # ---- 2. move *everything* to the target device in one go ----\n",
    "        self.to(device)                     # <-- important!\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.front_end(x)               # now on correct device\n",
    "        x = self.positional_embedding(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.438790Z",
     "iopub.status.busy": "2025-11-25T05:39:06.438533Z",
     "iopub.status.idle": "2025-11-25T05:39:06.453087Z",
     "shell.execute_reply": "2025-11-25T05:39:06.452417Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.438769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SequencePooling(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention-style weighted pooling over sequence.\n",
    "    Input: (B,S,C) -> Output: (B,C)\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,S,C)\n",
    "        w = self.linear(x)               # (B,S,1)\n",
    "        w = F.softmax(w.transpose(1, 2), dim=-1)  # (B,1,S)\n",
    "        out = torch.matmul(w, x)         # (B,1,C)\n",
    "        return out.squeeze(1)            # (B,C)\n",
    "\n",
    "\n",
    "class RawformerClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoders (N layers) + SeqPool + Linear + Sigmoid\n",
    "    Input: sequence (B,S,C)  Output: (B,) score in [0,1]\n",
    "    \"\"\"\n",
    "    def __init__(self, C: int, n_encoder: int, transformer_hidden: int):\n",
    "        super().__init__()\n",
    "        self.encoders = nn.Sequential(OrderedDict([\n",
    "            (f\"encoder{i}\", TransformerEncoderLayer(d_model=C, n_head=8, ffn_hidden=transformer_hidden))\n",
    "            for i in range(n_encoder)\n",
    "        ]))\n",
    "        self.seq_pool = SequencePooling(d_model=C)\n",
    "        self.fc = nn.Linear(C, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,S,C)\n",
    "        x = self.encoders(x)\n",
    "        x = self.seq_pool(x)\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x).squeeze(-1)   # (B,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.453948Z",
     "iopub.status.busy": "2025-11-25T05:39:06.453693Z",
     "iopub.status.idle": "2025-11-25T05:39:06.469810Z",
     "shell.execute_reply": "2025-11-25T05:39:06.469201Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.453931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_pad(batch):\n",
    "    # Here all items are same length already; just stack.\n",
    "    wavs, labels = zip(*batch)\n",
    "    wavs = torch.stack(wavs, dim=0)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return wavs, labels\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, preemph=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for wav, label in loader:\n",
    "        wav = wav.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        if preemph is not None:\n",
    "            wav = preemph(wav)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(wav)              # (B,)\n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * wav.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, preemph=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    for wav, label in loader:\n",
    "        wav = wav.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        if preemph is not None:\n",
    "            wav = preemph(wav)\n",
    "        pred = model(wav)\n",
    "        loss = criterion(pred, label)\n",
    "        total_loss += loss.item() * wav.size(0)\n",
    "        total_correct += ((pred > 0.5).float() == label).sum().item()\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = total_correct / len(loader.dataset)\n",
    "    return avg_loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.470899Z",
     "iopub.status.busy": "2025-11-25T05:39:06.470649Z",
     "iopub.status.idle": "2025-11-25T05:39:06.544045Z",
     "shell.execute_reply": "2025-11-25T05:39:06.543269Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.470875Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([2]) | values ~ (0.4270656406879425, 0.42748376727104187)\n"
     ]
    }
   ],
   "source": [
    "# Build model and run a forward pass with dummy audio\n",
    "exp_cfg = ExpConfig()\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Rawformer_S(device=DEVICE, transformer_hidden=exp_cfg.transformer_hidden,\n",
    "                          sample_rate=exp_cfg.sample_rate)\n",
    "\n",
    "B = 2\n",
    "dummy_audio = torch.randn(B, exp_cfg.sample_rate * exp_cfg.train_duration_sec).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    out = model(dummy_audio)\n",
    "print(\"Model output shape:\", out.shape, \"| values ~\", (out.min().item(), out.max().item()))\n",
    "\n",
    "if HAS_TORCHINFO:\n",
    "    try:\n",
    "        summary(model, input_size=(B, exp_cfg.sample_rate * exp_cfg.train_duration_sec))\n",
    "    except Exception as e:\n",
    "        print(\"torchinfo summary error (safe to ignore):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.545010Z",
     "iopub.status.busy": "2025-11-25T05:39:06.544797Z",
     "iopub.status.idle": "2025-11-25T05:39:06.548428Z",
     "shell.execute_reply": "2025-11-25T05:39:06.547784Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.544976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torchaudio.set_audio_backend(\"ffmpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.549387Z",
     "iopub.status.busy": "2025-11-25T05:39:06.549113Z",
     "iopub.status.idle": "2025-11-25T05:39:06.559782Z",
     "shell.execute_reply": "2025-11-25T05:39:06.559257Z",
     "shell.execute_reply.started": "2025-11-25T05:39:06.549370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.562453Z",
     "iopub.status.busy": "2025-11-25T05:39:06.562096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Loaded 25380 files from G:\\INTERSPEECH_26\\LA\\ASV19\\train\n",
      "📁 Loaded 24844 files from G:\\INTERSPEECH_26\\LA\\ASV19\\dev\n",
      "📁 Loaded 24844 files from G:\\INTERSPEECH_26\\LA\\ASV19\\dev\n",
      "🚀 Starting training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c460c9d50c024c63a716806e053dec2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfabe2ef28e44a78529af30d1f17b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 1 Summary:\n",
      "   Train Loss: 0.2397\n",
      "   Val Loss:   0.1300\n",
      "   Val EER:    9.11%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=9.11%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\wavelet_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459419f68392498a987de93a2884bd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e59472f808540c7866ed5bd7ec6d3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 2 Summary:\n",
      "   Train Loss: 0.0865\n",
      "   Val Loss:   0.0634\n",
      "   Val EER:    4.19%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=4.19%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\wavelet_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6f9a40c2744201aecca8dbcb9efbeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afb8a3c42ec434ba6cf277351dd6cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 3 Summary:\n",
      "   Train Loss: 0.0506\n",
      "   Val Loss:   0.0592\n",
      "   Val EER:    4.52%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40bd6327b0c4ac596fbebd23357224c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac872655daa4e28a5ca988d9705e796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 4 Summary:\n",
      "   Train Loss: 0.0457\n",
      "   Val Loss:   0.0415\n",
      "   Val EER:    2.83%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=2.83%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\wavelet_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5a82953d5a446fab9ff749bf74ac23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6e708bc4ef474399d5dc0facdf9a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 5 Summary:\n",
      "   Train Loss: 0.0403\n",
      "   Val Loss:   0.0611\n",
      "   Val EER:    2.42%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=2.42%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\wavelet_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b0bed2653348c183205820444e69c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5768522ca51461a8e6a71af3b498d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 6 Summary:\n",
      "   Train Loss: 0.0415\n",
      "   Val Loss:   0.0507\n",
      "   Val EER:    2.47%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282b99bb85504100abcc1e17cbdac949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30af6a7d7b6c44ef87b9eddf074db03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 7 Summary:\n",
      "   Train Loss: 0.0306\n",
      "   Val Loss:   0.0323\n",
      "   Val EER:    2.42%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=2.42%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\wavelet_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33746dcbb6ac454ca5133e7e8f7c284a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5f5a852b1f4a7b974116b8914a2f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 8 Summary:\n",
      "   Train Loss: 0.0463\n",
      "   Val Loss:   0.1520\n",
      "   Val EER:    3.65%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4196f1ee0e444041ad1d3047e4781e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf124321585243289c88cebfdc60fd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 9 Summary:\n",
      "   Train Loss: 0.0458\n",
      "   Val Loss:   0.0310\n",
      "   Val EER:    2.35%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=2.35%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\wavelet_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1503efd44aae4e0a87a864e511b6ceee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2418bb10c8754d2e94cef62fd01aa78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 10 Summary:\n",
      "   Train Loss: 0.0307\n",
      "   Val Loss:   0.1649\n",
      "   Val EER:    4.32%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df599d45402f418ca4a3168cf7b51179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0acefd4c16c44bb95dceea2a3a6281d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 11 Summary:\n",
      "   Train Loss: 0.0346\n",
      "   Val Loss:   0.6340\n",
      "   Val EER:    3.58%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0b1b6287084160aec94fe9309b3f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df03978da4f34b30b941a2e192f12b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 12 Summary:\n",
      "   Train Loss: 0.0434\n",
      "   Val Loss:   0.0433\n",
      "   Val EER:    2.50%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0535397f8073463dbde6684cbe5657e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128cada3fb13401fb71ccb746b370989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 13 Summary:\n",
      "   Train Loss: 0.0319\n",
      "   Val Loss:   0.0266\n",
      "   Val EER:    2.00%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=2.00%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\wavelet_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f63fd1b970148e99f0b2e640fe9ddc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e427d3a7aa4046a5cca300a8e00efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 14 Summary:\n",
      "   Train Loss: 0.0262\n",
      "   Val Loss:   0.0512\n",
      "   Val EER:    3.31%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2e58b50b924cd8b49c228378e6a88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53de6577a320410f8369fc465299c75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 15 Summary:\n",
      "   Train Loss: 0.0258\n",
      "   Val Loss:   0.0614\n",
      "   Val EER:    3.96%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bdea513624427fbd62c69a55e9481b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bc30594dbf48029457677c192f7938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 16 Summary:\n",
      "   Train Loss: 0.0318\n",
      "   Val Loss:   0.0407\n",
      "   Val EER:    2.50%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12a590a5db24304b2873262ec91bb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aaf0e926d294fccaa42e28286ae3398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 17 Summary:\n",
      "   Train Loss: 0.0425\n",
      "   Val Loss:   0.0426\n",
      "   Val EER:    2.24%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b94f78920140dca7c47be7a4e6ddac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8117d7c0b694ac1aa4129cd98a88161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 18 Summary:\n",
      "   Train Loss: 0.0237\n",
      "   Val Loss:   0.0225\n",
      "   Val EER:    1.65%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=1.65%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\wavelet_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b699870ac414825b26f72228bbd8b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708fd543c39344eb948d8328f12fa142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 19 Summary:\n",
      "   Train Loss: 0.0248\n",
      "   Val Loss:   0.0232\n",
      "   Val EER:    1.41%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=1.41%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\wavelet_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec57839afbde44d689f2e76e5f99e326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9177b26a74d34486b5c17953a1428050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 20 Summary:\n",
      "   Train Loss: 0.0277\n",
      "   Val Loss:   0.0303\n",
      "   Val EER:    2.12%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6443aeeed4214f3786ba86e21adb1223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1747f04012c4837b80806525a021578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 21 Summary:\n",
      "   Train Loss: 0.0234\n",
      "   Val Loss:   0.0340\n",
      "   Val EER:    2.15%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503c31370d964bf69692861ed4b15efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28546814dbd4a6e9b82367fa4d3ea95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 22 Summary:\n",
      "   Train Loss: 0.0239\n",
      "   Val Loss:   0.0840\n",
      "   Val EER:    2.47%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ff34dd02ff4a0b9b2aae051563cdf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac22f605d7dd40d58b680877975e3a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 23 Summary:\n",
      "   Train Loss: 0.0337\n",
      "   Val Loss:   0.0870\n",
      "   Val EER:    3.45%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78973d4b31a480481492a145e555aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d2caa8e39e44308530199191aec168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 24 Summary:\n",
      "   Train Loss: 0.0193\n",
      "   Val Loss:   0.0603\n",
      "   Val EER:    3.89%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498269ff1b504b7e854c90a17e86f80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1650b6d9c06845c5886754deb07b6b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 25 Summary:\n",
      "   Train Loss: 0.0213\n",
      "   Val Loss:   0.0208\n",
      "   Val EER:    1.53%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d728b5804f349138e746c549a81b8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e80ade84b864605aef8524d8103f722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 26 Summary:\n",
      "   Train Loss: 0.0202\n",
      "   Val Loss:   0.1818\n",
      "   Val EER:    3.77%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81c11e90a77457ea573d9000873f5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5874045ea250424384ce0587d53fd83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 27 Summary:\n",
      "   Train Loss: 0.0206\n",
      "   Val Loss:   0.0373\n",
      "   Val EER:    1.53%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3403ca4c194afe9ed7ffa7b23df25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd923259e7994536bf7147ebbde02922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 28 Summary:\n",
      "   Train Loss: 0.0227\n",
      "   Val Loss:   0.0386\n",
      "   Val EER:    3.15%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea839abc0414cc281e68a256f9e0d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcc3be99f60484e89bd89aa0adacab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 29 Summary:\n",
      "   Train Loss: 0.0218\n",
      "   Val Loss:   0.0344\n",
      "   Val EER:    2.08%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73c369c61ab4877bad3b81b135ced84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6be675621a84528b3717a9234d43a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 30 Summary:\n",
      "   Train Loss: 0.0190\n",
      "   Val Loss:   0.0248\n",
      "   Val EER:    1.61%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104c25496e994157b8df0bf89351744f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cfd66813ef4e0b833c21cacf590ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 31 Summary:\n",
      "   Train Loss: 0.0225\n",
      "   Val Loss:   0.0627\n",
      "   Val EER:    2.75%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7145aeb1c177431ab8988d7b147cc910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc528327ed447b1a3f70068a8b43831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 32 Summary:\n",
      "   Train Loss: 0.0217\n",
      "   Val Loss:   0.0573\n",
      "   Val EER:    2.95%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6c5ae5323247fd95d63ba753f83e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2001c6fabf304dc992a577c53cd567cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 33 Summary:\n",
      "   Train Loss: 0.0172\n",
      "   Val Loss:   0.0296\n",
      "   Val EER:    1.95%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1731a7dc17d4b458d81598ee4341419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435423b6bd1b4dfd9c032fdf0383f8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 34 Summary:\n",
      "   Train Loss: 0.0205\n",
      "   Val Loss:   0.0253\n",
      "   Val EER:    1.41%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=1.41%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\wavelet_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cf3bd84b6c405da6dc55fba8c63d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5349a4e5c6b44d30a710ddcf0f2962aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 35 Summary:\n",
      "   Train Loss: 0.0174\n",
      "   Val Loss:   0.0784\n",
      "   Val EER:    3.92%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36021978167d4229a8efdc603820ef78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba4d405653d4ae19b21d81d09181080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 36 Summary:\n",
      "   Train Loss: 0.0215\n",
      "   Val Loss:   0.0553\n",
      "   Val EER:    3.04%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb29d7278da14160b805df48fb48a96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7427d63e6e74e51af39036570ce2ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 37 Summary:\n",
      "   Train Loss: 0.0224\n",
      "   Val Loss:   0.0245\n",
      "   Val EER:    1.79%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141d6755d7114ecab72557c392a5f4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fb705262144c3ba76c345b7c1d5b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 38 Summary:\n",
      "   Train Loss: 0.0215\n",
      "   Val Loss:   0.1329\n",
      "   Val EER:    4.40%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8387ab6a4f3e455e9e41612016c81c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3658c6a7cfae40d89120ae35cf826273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 39 Summary:\n",
      "   Train Loss: 0.0267\n",
      "   Val Loss:   0.0286\n",
      "   Val EER:    1.93%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa31345858e3494f99916ac8d24e9981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c451592f43426b966433c2586d0fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 40 Summary:\n",
      "   Train Loss: 0.0142\n",
      "   Val Loss:   0.0204\n",
      "   Val EER:    1.42%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7664d68b4d40e9bb82dc6897576459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5c12f7820d4e5aacb993f8c3c0c57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 41 Summary:\n",
      "   Train Loss: 0.0135\n",
      "   Val Loss:   0.0267\n",
      "   Val EER:    1.75%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579b63f02d37419a89c196985cd8d0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24ffb03f30745f7968058fb73e92c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 42 Summary:\n",
      "   Train Loss: 0.0171\n",
      "   Val Loss:   0.0209\n",
      "   Val EER:    1.14%\n",
      "   min-tDCF:   1.0000\n",
      "💾 Saved new best model (EER=1.14%) to C:\\Users\\Admin\\Desktop\\Test Folder Arth Shah\\wavelet_best_cm_model.pth\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f789203be24198b430f8f2a66b1412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4797ef4539554b9f9f01d68cde07b479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 43 Summary:\n",
      "   Train Loss: 0.0272\n",
      "   Val Loss:   0.0322\n",
      "   Val EER:    2.28%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b10f8c591c4ee9a57ec6f57137e53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387d7785326b4c7f9ce4af0aeecd1ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 44 Summary:\n",
      "   Train Loss: 0.0228\n",
      "   Val Loss:   0.0324\n",
      "   Val EER:    1.96%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d67e0f6b304fbaab5935d8daa1e116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6425c96f28489d923950298ce34524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 45 Summary:\n",
      "   Train Loss: 0.0204\n",
      "   Val Loss:   0.1113\n",
      "   Val EER:    4.51%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c018a5fbfde41dea5a046ebeec787d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bff4e1538824cac92ab6d434d411122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 46 Summary:\n",
      "   Train Loss: 0.0158\n",
      "   Val Loss:   0.0256\n",
      "   Val EER:    1.61%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282f8607fc4a43fbb38ed1fb4366ab87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8db9587c06c4620b1ce7c11c9fccbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 47 Summary:\n",
      "   Train Loss: 0.0201\n",
      "   Val Loss:   0.0277\n",
      "   Val EER:    1.65%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12b9a9d51cf4d0ca5c1e55c5ec5bc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d022b127f04f8985cfbd82d6623885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 48 Summary:\n",
      "   Train Loss: 0.0141\n",
      "   Val Loss:   0.0278\n",
      "   Val EER:    1.84%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41b45d9b83942b2a42b6afb79b30994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4da81818dab44abb2aa59c81e3613ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 49 Summary:\n",
      "   Train Loss: 0.0166\n",
      "   Val Loss:   0.0299\n",
      "   Val EER:    2.24%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af70553f72d445f4b56b909b3a6f1043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50 [Train]:   0%|          | 0/794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1b6274f3554269ba8213e11f2b26f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50 [Val]:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Epoch 50 Summary:\n",
      "   Train Loss: 0.0175\n",
      "   Val Loss:   0.0619\n",
      "   Val EER:    4.16%\n",
      "   min-tDCF:   1.0000\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "🏁 Starting final testing...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12056\\2467297305.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model = torch.load(save_path, map_location=DEVICE)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6439453ea0844b8a81340317ee1a2c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Final Test EER:  1.18%\n",
      "📊 Final min-tDCF: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SIMPLE DATASET\n",
    "# ============================================================\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "class ASVspoofFolderDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, sample_rate=16000, duration_sec=4):\n",
    "        self.root_dir = root_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration_sec = duration_sec\n",
    "        self.audio_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label_name, label_value in [(\"bonafide\", 1), (\"spoof\", 0)]:\n",
    "            class_dir = os.path.join(root_dir, label_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for file in os.listdir(class_dir):\n",
    "                    if file.endswith(\".flac\") or file.endswith(\".wav\"):\n",
    "                        self.audio_paths.append(os.path.join(class_dir, file))\n",
    "                        self.labels.append(label_value)\n",
    "\n",
    "        print(f\"📁 Loaded {len(self.audio_paths)} files from {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.audio_paths[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "        # --- Use soundfile for FLAC ---\n",
    "        if path.lower().endswith(\".flac\"):\n",
    "            wav_np, sr = sf.read(path)         # numpy array (T,) or (T, C)\n",
    "            if wav_np.ndim > 1:                # convert stereo → mono\n",
    "                wav_np = wav_np.mean(axis=1)\n",
    "            wav = torch.tensor(wav_np, dtype=torch.float32).unsqueeze(0)  # [1, T]\n",
    "\n",
    "        # --- Use torchaudio for WAV ---\n",
    "        else:\n",
    "            wav, sr = torchaudio.load(path)\n",
    "\n",
    "        # --- Resample if needed ---\n",
    "        if sr != self.sample_rate:\n",
    "            wav = torchaudio.functional.resample(wav, sr, self.sample_rate)\n",
    "\n",
    "        # --- Crop/pad ---\n",
    "        num_samples = int(self.sample_rate * self.duration_sec)\n",
    "\n",
    "        if wav.size(1) > num_samples:\n",
    "            start = random.randint(0, wav.size(1) - num_samples)\n",
    "            wav = wav[:, start:start + num_samples]\n",
    "        elif wav.size(1) < num_samples:\n",
    "            wav = F.pad(wav, (0, num_samples - wav.size(1)))\n",
    "\n",
    "        return wav.squeeze(0), label\n",
    "\n",
    "# ============================================================\n",
    "# EER FUNCTION (FOR CM SYSTEM)\n",
    "# ============================================================\n",
    "\n",
    "def calculate_EER(labels, scores):\n",
    "    \"\"\"Equal Error Rate for Countermeasure system (bonafide=1, spoof=0).\"\"\"\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, scores, pos_label=1)\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    return eer\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# t-DCF FUNCTION (CM-only version using reference ASV parameters)\n",
    "# ============================================================\n",
    "\n",
    "def compute_tDCF(bonafide_score_cm, spoof_score_cm, Pfa_asv, Pmiss_asv, Pfa_spoof_asv, cost_model):\n",
    "    # 1. Compute CM miss/false-alarm rates for thresholds\n",
    "    cm_scores = np.concatenate([bonafide_score_cm, spoof_score_cm])\n",
    "    labels = np.concatenate([np.ones_like(bonafide_score_cm), np.zeros_like(spoof_score_cm)])\n",
    "    sorted_idx = np.argsort(cm_scores)[::-1]\n",
    "    sorted_labels = labels[sorted_idx]\n",
    "\n",
    "    tar = np.sum(sorted_labels)\n",
    "    non = len(sorted_labels) - tar\n",
    "\n",
    "    cm_miss = np.cumsum(sorted_labels == 1) / tar\n",
    "    cm_fa = np.cumsum(sorted_labels == 0) / non\n",
    "\n",
    "    # 2. Compute t-DCF per threshold\n",
    "    Cmiss, Cfa, Cfa_spoof = cost_model['Cmiss'], cost_model['Cfa'], cost_model['Cfa_spoof']\n",
    "    Ptar, Pnon, Pspoof = cost_model['Ptar'], cost_model['Pnon'], cost_model['Pspoof']\n",
    "\n",
    "    tDCF = (Cmiss * Ptar * Pmiss_asv * (1 - cm_miss) +\n",
    "            Cfa * Pnon * Pfa_asv * cm_fa +\n",
    "            Cfa_spoof * Pspoof * Pfa_spoof_asv * (1 - cm_miss)) / (\n",
    "            Cmiss * Ptar * Pmiss_asv + Cfa * Pnon * Pfa_asv)\n",
    "\n",
    "    tDCF_norm = tDCF / np.min(tDCF)\n",
    "    thresholds = cm_scores[sorted_idx]\n",
    "\n",
    "    return tDCF_norm, thresholds\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN + VALIDATE + TEST LOOP\n",
    "# ============================================================\n",
    "\n",
    "sys_cfg = SysConfig()\n",
    "exp_cfg = ExpConfig()\n",
    "\n",
    "train_ds = ASVspoofFolderDataset(sys_cfg.path_train, exp_cfg.sample_rate, exp_cfg.train_duration_sec)\n",
    "val_ds   = ASVspoofFolderDataset(sys_cfg.path_dev, exp_cfg.sample_rate, exp_cfg.test_duration_sec)\n",
    "test_ds  = ASVspoofFolderDataset(sys_cfg.path_test, exp_cfg.sample_rate, exp_cfg.test_duration_sec)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=exp_cfg.batch_size, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds, batch_size=exp_cfg.batch_size, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds, batch_size=exp_cfg.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# --- your modules ---\n",
    "pre = PreEmphasis(exp_cfg.pre_emphasis).to(DEVICE)\n",
    "model = Rawformer_S(device=DEVICE, transformer_hidden=exp_cfg.transformer_hidden, sample_rate=exp_cfg.sample_rate).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=exp_cfg.lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "best_val_eer = 1.0  # initialize high value\n",
    "\n",
    "print(\"🚀 Starting training...\\n\")\n",
    "\n",
    "# Reference ASV parameters (official ASVspoof setup)\n",
    "Pfa_asv = 0.0005\n",
    "Pmiss_asv = 0.05\n",
    "Pmiss_spoof_asv = 0.95\n",
    "Pfa_spoof_asv = 1.0 - Pmiss_spoof_asv\n",
    "cost_model = {\n",
    "    'Ptar': 0.9801,\n",
    "    'Pnon': 0.0099,\n",
    "    'Pspoof': 0.0100,\n",
    "    'Cmiss': 1,\n",
    "    'Cfa': 10,\n",
    "    'Cfa_spoof': 10\n",
    "}\n",
    "\n",
    "for epoch in range(1, exp_cfg.epochs + 1):\n",
    "    # === TRAIN ===\n",
    "    model.train()\n",
    "    total_loss, total_samples = 0.0, 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{exp_cfg.epochs} [Train]\", leave=True)\n",
    "\n",
    "    for wav, label in pbar:\n",
    "        wav, label = wav.to(DEVICE), label.to(DEVICE)\n",
    "        wav = pre(wav)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        pred = model(wav).squeeze(-1)\n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        bs = wav.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_samples += bs\n",
    "        pbar.set_postfix(loss=f\"{total_loss / total_samples:.4f}\")\n",
    "\n",
    "    avg_train_loss = total_loss / total_samples\n",
    "\n",
    "    # === VALIDATE ===\n",
    "    model.eval()\n",
    "    val_loss, val_samples = 0.0, 0\n",
    "    all_scores, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=f\"Epoch {epoch}/{exp_cfg.epochs} [Val]\", leave=True)\n",
    "        for wav, label in pbar:\n",
    "            wav, label = wav.to(DEVICE), label.to(DEVICE)\n",
    "            wav = pre(wav)\n",
    "            pred = model(wav).squeeze(-1)\n",
    "            loss = criterion(pred, label)\n",
    "\n",
    "            bs = wav.size(0)\n",
    "            val_loss += loss.item() * bs\n",
    "            val_samples += bs\n",
    "\n",
    "            all_scores.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / val_samples\n",
    "    eer = calculate_EER(all_labels, all_scores)\n",
    "\n",
    "    # --- Compute t-DCF ---\n",
    "    bona_cm = np.array(all_scores)[np.array(all_labels) == 1]\n",
    "    spoof_cm = np.array(all_scores)[np.array(all_labels) == 0]\n",
    "    tDCF_curve, thr = compute_tDCF(bona_cm, spoof_cm, Pfa_asv, Pmiss_asv, Pfa_spoof_asv, cost_model)\n",
    "    min_tDCF = np.min(tDCF_curve)\n",
    "\n",
    "    print(f\"🧾 Epoch {epoch} Summary:\")\n",
    "    print(f\"   Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"   Val Loss:   {avg_val_loss:.4f}\")\n",
    "    print(f\"   Val EER:    {eer * 100:.2f}%\")\n",
    "    print(f\"   min-tDCF:   {min_tDCF:.4f}\")\n",
    "\n",
    "    # === SAVE BEST MODEL ===\n",
    "    if eer < best_val_eer:\n",
    "        best_val_eer = eer\n",
    "        torch.save(model, save_path)\n",
    "        print(f\"💾 Saved new best model (EER={eer*100:.2f}%) to {save_path}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FINAL TEST PHASE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🏁 Starting final testing...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load best model\n",
    "best_model = torch.load(save_path, map_location=DEVICE)\n",
    "best_model.eval()\n",
    "\n",
    "test_scores, test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(test_loader, desc=\"Testing\", leave=True)\n",
    "    for wav, label in pbar:\n",
    "        wav, label = wav.to(DEVICE), label.to(DEVICE)\n",
    "        wav = pre(wav)\n",
    "        pred = best_model(wav).squeeze(-1)\n",
    "        test_scores.extend(pred.cpu().numpy())\n",
    "        test_labels.extend(label.cpu().numpy())\n",
    "\n",
    "test_eer = calculate_EER(test_labels, test_scores)\n",
    "\n",
    "bona_cm = np.array(test_scores)[np.array(test_labels) == 1]\n",
    "spoof_cm = np.array(test_scores)[np.array(test_labels) == 0]\n",
    "tDCF_curve, thr = compute_tDCF(bona_cm, spoof_cm, Pfa_asv, Pmiss_asv, Pfa_spoof_asv, cost_model)\n",
    "min_tDCF = np.min(tDCF_curve)\n",
    "\n",
    "print(f\"🎯 Final Test EER:  {test_eer * 100:.2f}%\")\n",
    "print(f\"📊 Final min-tDCF: {min_tDCF:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL PARAMETER SUMMARY\n",
      "============================================================\n",
      "Trainable params         : 345,342\n",
      "Total params             : 345,342\n",
      "Model size (MiB)         : 1.32\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::exp encountered 72 time(s)\n",
      "Unsupported operator aten::sub encountered 6 time(s)\n",
      "Unsupported operator aten::mul encountered 637 time(s)\n",
      "Unsupported operator aten::reciprocal encountered 70 time(s)\n",
      "Unsupported operator aten::pow encountered 142 time(s)\n",
      "Unsupported operator aten::neg encountered 70 time(s)\n",
      "Unsupported operator aten::div encountered 356 time(s)\n",
      "Unsupported operator aten::add encountered 299 time(s)\n",
      "Unsupported operator aten::cos encountered 70 time(s)\n",
      "Unsupported operator aten::sin encountered 70 time(s)\n",
      "Unsupported operator aten::abs encountered 141 time(s)\n",
      "Unsupported operator aten::sum encountered 140 time(s)\n",
      "Unsupported operator aten::sqrt encountered 5 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 5 time(s)\n",
      "Unsupported operator aten::selu_ encountered 8 time(s)\n",
      "Unsupported operator aten::softmax encountered 3 time(s)\n",
      "Unsupported operator aten::mean encountered 4 time(s)\n",
      "Unsupported operator aten::var encountered 4 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 1 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FLOPs / MACs (per forward pass)\n",
      "============================================================\n",
      "Input shape              : [1, 64000]\n",
      "MACs                     : 6.775 G\n",
      "FLOPs                    : 13.550 G\n",
      "============================================================\n",
      "\n",
      "Detailed layer-wise breakdown (torchinfo):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================================================================================================================================================================\n",
       "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "================================================================================================================================================================\n",
       "Rawformer_S                                                  [1, 64000]                [1]                       --                        --\n",
       "├─Frontend_S: 1-1                                            [1, 64000]                [1, 64, 23, 16]           --                        --\n",
       "│    └─WTConv: 2-1                                           [1, 1, 64000]             [1, 70, 64000]            210                       --\n",
       "│    └─BatchNorm2d: 2-2                                      [1, 1, 23, 21333]         [1, 1, 23, 21333]         2                         2\n",
       "│    └─SELU: 2-3                                             [1, 1, 23, 21333]         [1, 1, 23, 21333]         --                        --\n",
       "│    └─Sequential: 2-4                                       [1, 1, 23, 21333]         [1, 64, 23, 16]           --                        --\n",
       "│    │    └─Conv2DBlock_S: 3-1                               [1, 1, 23, 21333]         [1, 32, 23, 3555]         --                        --\n",
       "│    │    │    └─Conv2d: 4-1                                 [1, 1, 23, 21333]         [1, 32, 23, 21333]        128                       62,804,352\n",
       "│    │    │    └─Sequential: 4-2                             [1, 1, 23, 21333]         [1, 32, 23, 21333]        6,592                     3,210,531,232\n",
       "│    │    │    └─MaxPool2d: 4-3                              [1, 32, 23, 21333]        [1, 32, 23, 3555]         --                        --\n",
       "│    │    └─Conv2DBlock_S: 3-2                               [1, 32, 23, 3555]         [1, 32, 23, 592]          --                        --\n",
       "│    │    │    └─Sequential: 4-4                             [1, 32, 23, 3555]         [1, 32, 23, 3555]         64                        64\n",
       "│    │    │    └─Sequential: 4-5                             [1, 32, 23, 3555]         [1, 32, 23, 3555]         16,512                    1,381,387,744\n",
       "│    │    │    └─MaxPool2d: 4-6                              [1, 32, 23, 3555]         [1, 32, 23, 592]          --                        --\n",
       "│    │    └─Conv2DBlock_S: 3-3                               [1, 32, 23, 592]          [1, 64, 23, 98]           --                        --\n",
       "│    │    │    └─Conv2d: 4-7                                 [1, 32, 23, 592]          [1, 64, 23, 592]          6,208                     84,528,128\n",
       "│    │    │    └─Sequential: 4-8                             [1, 32, 23, 592]          [1, 32, 23, 592]          64                        64\n",
       "│    │    │    └─Sequential: 4-9                             [1, 32, 23, 592]          [1, 64, 23, 592]          45,312                    627,387,520\n",
       "│    │    │    └─MaxPool2d: 4-10                             [1, 64, 23, 592]          [1, 64, 23, 98]           --                        --\n",
       "│    │    └─Conv2DBlock_S: 3-4                               [1, 64, 23, 98]           [1, 64, 23, 16]           --                        --\n",
       "│    │    │    └─Sequential: 4-11                            [1, 64, 23, 98]           [1, 64, 23, 98]           128                       128\n",
       "│    │    │    └─Sequential: 4-12                            [1, 64, 23, 98]           [1, 64, 23, 98]           65,792                    152,027,136\n",
       "│    │    │    └─MaxPool2d: 4-13                             [1, 64, 23, 98]           [1, 64, 23, 16]           --                        --\n",
       "├─PositionalAggregator1D: 1-2                                [1, 64, 23, 16]           [1, 368, 64]              --                        --\n",
       "│    └─Flatten: 2-5                                          [1, 64, 23, 16]           [1, 64, 368]              --                        --\n",
       "├─RawformerClassifier: 1-3                                   [1, 368, 64]              [1]                       --                        --\n",
       "│    └─Sequential: 2-6                                       [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    └─TransformerEncoderLayer: 3-5                     [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    │    └─MultiHeadAttention: 4-14                    [1, 368, 64]              [1, 368, 64]              16,640                    16,640\n",
       "│    │    │    └─Dropout: 4-15                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    │    └─LayerNorm: 4-16                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "│    │    │    └─FFN: 4-17                                   [1, 368, 64]              [1, 368, 64]              85,204                    85,204\n",
       "│    │    │    └─Dropout: 4-18                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    │    └─LayerNorm: 4-19                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "│    │    └─TransformerEncoderLayer: 3-6                     [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    │    └─MultiHeadAttention: 4-20                    [1, 368, 64]              [1, 368, 64]              16,640                    16,640\n",
       "│    │    │    └─Dropout: 4-21                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    │    └─LayerNorm: 4-22                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "│    │    │    └─FFN: 4-23                                   [1, 368, 64]              [1, 368, 64]              85,204                    85,204\n",
       "│    │    │    └─Dropout: 4-24                               [1, 368, 64]              [1, 368, 64]              --                        --\n",
       "│    │    │    └─LayerNorm: 4-25                             [1, 368, 64]              [1, 368, 64]              128                       --\n",
       "│    └─SequencePooling: 2-7                                  [1, 368, 64]              [1, 64]                   --                        --\n",
       "│    │    └─Linear: 3-7                                      [1, 368, 64]              [1, 368, 1]               65                        65\n",
       "│    └─Linear: 2-8                                           [1, 64]                   [1, 1]                    65                        65\n",
       "================================================================================================================================================================\n",
       "Total params: 345,342\n",
       "Trainable params: 345,342\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.52\n",
       "================================================================================================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 681.89\n",
       "Params size (MB): 1.38\n",
       "Estimated Total Size (MB): 683.53\n",
       "================================================================================================================================================================"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "#  Model size & FLOPs (place this right after model creation)\n",
    "# --------------------------------------------------------------\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1. Parameter count (trainable + non-trainable) + size in MiB\n",
    "# --------------------------------------------------------------\n",
    "def print_model_params(model):\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total     = sum(p.numel() for p in model.parameters())\n",
    "    size_mb   = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024**2)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL PARAMETER SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Trainable params':<25}: {trainable:,}\")\n",
    "    print(f\"{'Total params'    :<25}: {total:,}\")\n",
    "    print(f\"{'Model size (MiB)':<25}: {size_mb:.2f}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "print_model_params(model)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2. FLOPs / MACs\n",
    "# --------------------------------------------------------------\n",
    "# We need a dummy waveform that matches the shape expected by the model.\n",
    "#   - Rawformer_S expects raw audio: (batch, time)\n",
    "#   - Use the maximum length defined in the config (or a typical 4-second clip)\n",
    "max_len_sec = getattr(exp_cfg, \"max_len_sec\", 4.0)          # fallback 4 s\n",
    "max_samples = int(exp_cfg.sample_rate * max_len_sec)\n",
    "\n",
    "dummy_wav = torch.randn(1, max_samples, device=DEVICE)     # (B, T)\n",
    "\n",
    "# Apply pre-emphasis if it is used in training/validation\n",
    "if pre is not None:\n",
    "    dummy_wav = pre(dummy_wav)\n",
    "\n",
    "# ---- fvcore (very accurate) ----\n",
    "flops = FlopCountAnalysis(model, dummy_wav)\n",
    "macs  = flops.total()                # MACs = multiply-adds\n",
    "flops_2 = macs * 2                   # FLOPs = 2 × MACs (standard convention)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FLOPs / MACs (per forward pass)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Input shape'   :<25}: {list(dummy_wav.shape)}\")\n",
    "print(f\"{'MACs'          :<25}: {macs/1e9:.3f} G\")\n",
    "print(f\"{'FLOPs'         :<25}: {flops_2/1e9:.3f} G\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# ---- torchinfo (nice table, optional) ----\n",
    "print(\"Detailed layer-wise breakdown (torchinfo):\")\n",
    "summary(model,\n",
    "        input_data=dummy_wav,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n",
    "        depth=4,\n",
    "        verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFLOPs per second of audio : 3.388\n"
     ]
    }
   ],
   "source": [
    "seconds = max_samples / exp_cfg.sample_rate\n",
    "print(f\"GFLOPs per second of audio : {flops_2/1e9/seconds:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8621024,
     "sourceId": 13570789,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "AA_MP_env",
   "language": "python",
   "name": "aa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
